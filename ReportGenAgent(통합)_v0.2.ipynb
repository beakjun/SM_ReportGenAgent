{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "074e14c7-629b-4963-a662-b6f4944e07a8",
   "metadata": {},
   "source": [
    "# 모듈 불러오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23775e48",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "\n",
    "from langchain_community.tools import QuerySQLDatabaseTool\n",
    "from langchain_community.utilities import SQLDatabase\n",
    "from langchain.chains import create_sql_query_chain\n",
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain.prompts import ChatPromptTemplate\n",
    "from langchain.schema.runnable import RunnableLambda, RunnablePassthrough\n",
    "from langchain_community.tools.tavily_search import TavilyAnswer, TavilySearchResults\n",
    "from langsmith import Client\n",
    "\n",
    "from BK.db import DB\n",
    "import re\n",
    "\n",
    "from langchain_community.embeddings import HuggingFaceEmbeddings\n",
    "from langchain_community.vectorstores import Chroma\n",
    "from operator import itemgetter\n",
    "from langchain.schema import Document\n",
    "from typing import List, Literal, Any\n",
    "\n",
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "from langchain.prompts import ChatPromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.pydantic_v1 import BaseModel, Field\n",
    "\n",
    "from langchain.agents import create_react_agent,AgentExecutor\n",
    "\n",
    "from typing import Annotated\n",
    "from datetime import datetime \n",
    "from operator import add"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60a85ad1",
   "metadata": {},
   "source": [
    "# 필요 환경정의 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4093fca9",
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv('.env')\n",
    "\n",
    "# llm\n",
    "llm = ChatGoogleGenerativeAI(model='gemini-2.5-flash', temperature=0)\n",
    "llm_chat = ChatGoogleGenerativeAI(model='gemini-2.5-flash', temperature=0.2)\n",
    "\n",
    "# 랭스미스\n",
    "client = Client()\n",
    "# DB\n",
    "db = SQLDatabase.from_uri('postgresql://postgres:postgres@10.10.50.155:1108/postgres', schema=\"doosan\")\n",
    "\n",
    "# 벡터 DB\n",
    "from langchain_community.embeddings import HuggingFaceEmbeddings\n",
    "embedding_model_name = \"nlpai-lab/KoE5\"\n",
    "embedding = HuggingFaceEmbeddings(\n",
    "    model_name=embedding_model_name,\n",
    "    model_kwargs={\n",
    "        \"device\": \"cpu\",\n",
    "        # \"trust_remote_code\": True,  # 모델에 따라 필요할 수 있음\n",
    "    },\n",
    "    # encode_kwargs={\"normalize_embeddings\": True},  # 코사인 유사도 안정화 (버전에 따라 지원)\n",
    ")\n",
    "\n",
    "vectorstore = Chroma(\n",
    "    persist_directory='./chroma_reports_db',\n",
    "    embedding_function=embedding,\n",
    "    collection_name=\"reports_ko2\" \n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2c56716-267f-45fa-9d23-0cf1c947bfca",
   "metadata": {},
   "source": [
    "# Tools"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cab98db",
   "metadata": {},
   "source": [
    "## DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f774b5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# DataLoader\n",
    "class DataLoader(object):\n",
    "    def __init__(self, db:SQLDatabase = db):\n",
    "        self.llm = ChatGoogleGenerativeAI(model='gemini-2.5-flash', temperature=0)\n",
    "        self.db = db\n",
    "        self.write_query = create_sql_query_chain(llm, db)\n",
    "        self.execute_query = QuerySQLDatabaseTool(db=db)\n",
    "        self.chain = RunnableLambda(self.__create_prompt) | self.write_query | RunnableLambda(self.__clean_answer) |RunnableLambda(self._execute_query)\n",
    "\n",
    "    def __create_prompt(self, question:str):\n",
    "        question = question['question']\n",
    "        prompt = f\"\"\"당신은 SQL 쿼리 전문가입니다. 사용자의 요청을 SQL 쿼리로 변환하는 임무를 맡습니다. \n",
    "        주어진 input을 활용하여 툴을 호출한 후 나오는 DB정보를 활용해 SELECT문을 써서 PostgreSQL로 정의하시오.\n",
    "        쿼리 작성 규칙:\n",
    "        - 주어진 정보를 깊게 생각하여 쿼리를 생성하여라.\n",
    "        - tool을 있는 그대로(축약금지, 꾸며내기 금지) 활용해 참조한 DB정보를 바탕으로 불러온 DB정보안에 들어있는 컬럼명을 반드시 참조해서 SQL문 작성.\n",
    "        - 모든 컬럼명에는 \"\"로 감싸주며, as를 통해서 alias 하더라도 \"\"를 사용할 것.\n",
    "        - Select외 나머지 DDL 사용 금지.\n",
    "        - 최종 출력은 SQL 쿼리만 출력.\n",
    "        - 지표별 리그 내 순위 생성이 명시된 콘텐츠에서만 순위 생성 시 반드시 아래와 같은 규칙을 따라줘:\n",
    "            * 논리적 순서: 먼저 해당 시즌 데이터만 필터링하고, 그 안에서 모든 팀의 각 지표에 대한 순위를 계산해줘. 마지막으로 내가 원하는 특정 팀의 데이터만 필터링해서 보여줘.\n",
    "            * 포함할 컬럼: \"팀 명\", \"시즌\"을 제외한 지표들의 값.\n",
    "        - tool을 호출하지 않고는 절대 판단하지 말 것.\n",
    "        - Schema정보를 반드시 참조하여 테이블명을 완성시킬 것.\n",
    "        - 소수점이 긴 경우, numeric 타입으로 변환 후 둘째 자리까지 반올림한다.\n",
    "        - 쿼리는 ```을 사용하지 않고 작성한다.(쿼리가 길어서 ```를 사용해야 할 때는 '''로 대체해서 사용한다.)\n",
    "        답변할 때는 SQLQuery:와 같은 문구를 제외하고 순수 SQL 쿼리만 답변한다.\n",
    "    \n",
    "        사용자 요청:\n",
    "        {question}\n",
    "        \"\"\"\n",
    "        return {'question':prompt}\n",
    "\n",
    "    def _execute_query(self, query):\n",
    "        rdb = DB('pg', 'postgres')\n",
    "        data = rdb.read_table(query)\n",
    "        return data\n",
    "\n",
    "    def invoke(self, query:dict):\n",
    "        return self.chain.invoke({'question':query})\n",
    "\n",
    "    def ainoke(self, query:dict):\n",
    "        return self.chain.ainvoke({'question':query})\n",
    "    \n",
    "    def __clean_answer(self, query):\n",
    "        clean_query = re.sub('SQLQuery: {0,1}', '', query)\n",
    "        clean_query = re.sub('^sql|sql', '', clean_query)\n",
    "        clean_query = re.sub('```', \"'''\", clean_query)\n",
    "        return clean_query.strip()\n",
    "        \n",
    "\n",
    "    def __str__(self):\n",
    "        return f'{self.__class__.__name__}'\n",
    "\n",
    "    def __repr__(self):\n",
    "        return f'{self.__class__.__name__}'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c48ec3e1",
   "metadata": {},
   "source": [
    "## DataAnalyst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5e051f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataAnalyst(object):\n",
    "    def __init__(self, db:SQLDatabase = db):\n",
    "        self.llm = ChatGoogleGenerativeAI(model='gemini-2.5-flash')\n",
    "        self.prompt = self.__create_prompt()\n",
    "        self.data_loader_chain = DataLoader(db).chain\n",
    "        self.chain = RunnablePassthrough.assign(data= self.data_loader_chain) | self.prompt | llm | StrOutputParser()\n",
    "\n",
    "    def __create_prompt(self):\n",
    "        template = \"\"\"\n",
    "                    당신은 데이터 분석 전문가입니다. 사용자에게 요청에 따라 데이터를 해석하고 분석하는 임무를 맡습니다. \n",
    "                \n",
    "                    데이터 해석 규칙:\n",
    "                    - 사용자 요청과 주어진 데이터만 활용해서 해석을 합니다.\n",
    "                    - 다만 주어진 데이터로 새로운 변수를 만들어 해석할 여지가 있으면 새로운 변수를 만들어서 해석을 해야합니다.\n",
    "                    - 데이터는 사용자 요청과 관련있는 데이터입니다.\n",
    "                    \n",
    "                    사용자 요청: \n",
    "                    {question}\n",
    "                    \n",
    "                    데이터:\n",
    "                    {data}\n",
    "                \"\"\" \n",
    "        prompt = ChatPromptTemplate.from_template(template)\n",
    "        return prompt\n",
    "\n",
    "    def invoke(self, query:dict):\n",
    "        return self.chain.invoke({'question':query})\n",
    "\n",
    "    def ainoke(self, query:dict):\n",
    "        return self.chain.ainvoke({'question':query})\n",
    "    \n",
    "    def __str__(self):\n",
    "        return f'{self.__class__.__name__}'\n",
    "\n",
    "    def __repr__(self):\n",
    "        return f'{self.__class__.__name__}'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34808a72",
   "metadata": {},
   "source": [
    "## BI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "103c42dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BI(object):\n",
    "    def __init__(self, db:SQLDatabase = db):\n",
    "        self.llm = ChatGoogleGenerativeAI(model='gemini-2.5-flash')\n",
    "        self.prompt = self.__create_prompt()\n",
    "        self.data_loader_chain = DataLoader(db).chain\n",
    "        self.chain = RunnablePassthrough.assign(data= self.data_loader_chain) | self.prompt | llm | StrOutputParser() | RunnableLambda(self.__clean_answer)\n",
    "\n",
    "    def __create_prompt(self):\n",
    "        template = \"\"\"당신은 Python Matplotlib 시각화 전문가입니다. \n",
    "        사용자 요청과 주어진 데이터 그리고 아래 시각화 유형을 참고하여 해당 데이터에 맞는 시각화 유형을 깊게 생각하고 그에 해당하는 필요한 파이썬 시각화 코드를 생성하십시오.\n",
    "        \n",
    "        코드 작성 규칙:\n",
    "        - 오직 Python코드만 작성하며, 설명이 필요할 때는 #을 활용하여 주석으로 처리\n",
    "        - exec() 함수로 바로 실행시킬 수 있게 필요한 라이브러리와 주어진 데이터 정의하는 부분을 코드에 반영\n",
    "        - 그래프의 타이틀, X축, Y축, 라벨등을 반드시 명시\n",
    "        - 적절한 색 배치로 강조할 부분을 두드러지게 보이게 코드 생성\n",
    "        - 반드시 한글이 깨지지 않아야 함 (맥OS 사용)\n",
    "        - 폰트는 버전과 상관없는 기본 폰트 사용\n",
    "        - 그래프 크기는 세로가 4인치를 넘어가면 안되고, 세로길이에 따라 그래프가 잘 표출되어야 함\n",
    "        - plt.show() 생략\n",
    "\n",
    "        시각화 유형:\n",
    "        - BarChart: 범주 값 비교\n",
    "        - PieChart: 범주별 비율 구성\n",
    "        - LineChart: 시계열 추세\n",
    "        - RadarChart: 다변량 비교\n",
    "        - BigNumber: 핵심 수치 강조\n",
    "        - AreaChart: 누적 추세          \n",
    "        - ScatterPlot: 상관 관계          \n",
    "        - BubbleChart: 값+규모 비교\n",
    "        - TreeMap: 계층 비율          \n",
    "        - HeatMap: 값 밀도 패턴           \n",
    "        - Histogram: 분포 형태\n",
    "        \n",
    "        사용자 요청: \n",
    "        {question}\n",
    "        \n",
    "        데이터:\n",
    "        {data}\n",
    "        \"\"\" \n",
    "        prompt = ChatPromptTemplate.from_template(template)\n",
    "        return prompt\n",
    "\n",
    "    def __clean_answer(self, answer:str):\n",
    "        answer = answer.replace('```', \"'''\")\n",
    "        answer = answer.replace('python', '')\n",
    "        return answer\n",
    "\n",
    "    def invoke(self, query:dict):\n",
    "        return self.chain.invoke({'question':query})\n",
    "\n",
    "    def ainoke(self, query:dict):\n",
    "        return self.chain.ainvoke({'question':query})\n",
    "\n",
    "    def __str__(self):\n",
    "        return f'{self.__class__.__name__}'\n",
    "\n",
    "    def __repr__(self):\n",
    "        return f'{self.__class__.__name__}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b981f862",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tools\n",
    "from langchain_core.tools import tool\n",
    "from langchain_community.tools.tavily_search import TavilyAnswer, TavilySearchResults\n",
    "\n",
    "@tool(name_or_callable=\"DataLoaderTool\", description='사용자 요청에 따라 DB에서 적절한 데이터를 불러와서 데이터 프레임으로 반환합니다.' ,return_direct=False)\n",
    "def load_data(query:str) -> str:\n",
    "    loader = DataLoader(db)\n",
    "    return loader.invoke(query)\n",
    "\n",
    "@tool(name_or_callable=\"DataAnalystTool\", description='사용자 요청에 따라 DB에서 적절한 데이터를 불러온 후 분석하고 해석합니다.' ,return_direct=False)\n",
    "def analysis_data(query:str) -> str:\n",
    "    analyst = DataAnalyst(db)\n",
    "    return analyst.invoke(query)\n",
    "\n",
    "@tool(name_or_callable=\"BITool\", description='사용자 요청에 따라 DB에서 적절한 데이터를 불러와서 시각화할 수 있는 코드를 작성합니다.' ,return_direct=False)\n",
    "def visualize_data(question: str) -> str:\n",
    "    bi = BI(db)\n",
    "    return bi.invoke(question)\n",
    "\n",
    "tools = [TavilySearchResults(max_results=3), load_data, visualize_data, analysis_data]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "649e6fe0",
   "metadata": {},
   "source": [
    "# Output Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa90d798",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydantic import BaseModel, Field\n",
    "from typing import Literal, Optional\n",
    "\n",
    "class Output(object):\n",
    "    class GetMode(BaseModel):\n",
    "        mode: Literal['task', 'report', 'ect'] = Field(..., description='사용자 요청을 분석하여 요청 유형을 task, report, ect로 분류')\n",
    "        reason: str = Field(default='', description='사용자 요청을 분류한 근거를 2~3로 작성하세요.')\n",
    "        \n",
    "    class PassiveGoalCreator(BaseModel):\n",
    "        description: str = Field(..., description='목표 설명')\n",
    "        \n",
    "        @property\n",
    "        def text(self) -> str:\n",
    "            return f'{self.description}'\n",
    "            \n",
    "    class GoalOptimizer(BaseModel):\n",
    "        description:str = Field(..., description='목표 설명')\n",
    "        metrics: str = Field(..., description='목표 달성도를 측정하는 방법')\n",
    "    \n",
    "        @property\n",
    "        def text(self) -> str:\n",
    "            return f'{self.description}(측정 기준: {self.metrics})'\n",
    "            \n",
    "    class TaskDecomposer(BaseModel):\n",
    "        tasks: list[str] = Field(\n",
    "            default_factory=list,\n",
    "            min_item=3,\n",
    "            max_item=8,\n",
    "            description='3~8개로 분해된 테스크')\n",
    "    \n",
    "    class GetReportInfo(BaseModel):\n",
    "        doc_val_response: Literal[\"YES\",\"NO\"] = Field(default='YES', description='문서 검증 결과')\n",
    "        doc_val_reason:str= Field(default='', description='문서 검증 증거')\n",
    "        documents:str = Field(default='', description='검증에 참조한 문서')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad18ad5f-312c-4eea-9784-172b31903938",
   "metadata": {},
   "source": [
    "# LLM&Agent"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e045c7d-81bb-4914-a021-9db4e69ea7db",
   "metadata": {},
   "source": [
    "## GetMode | get_mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5864c7d6-a5c3-4fe4-af04-a0df65860aba",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GetMode(object):\n",
    "    def __init__(self):\n",
    "        self.llm = ChatGoogleGenerativeAI(model='gemini-2.5-flash', temperature=0)\n",
    "        self.prompt = self.__create_prompt()\n",
    "        self.chain = self.prompt | self.llm.with_structured_output(Output.GetMode)\n",
    "\n",
    "    def __create_prompt(self):\n",
    "        template = \"\"\"사용자 입력을 분석하여 mode를 task, report, ect로 구분한 후, mode를 그렇게 판단한 이유는 reason에 2~3줄로 간략하게 작성하세요.\n",
    "        task:\n",
    "        - 야구 관련 데이터를 DB에서 추출하는 요청\n",
    "        - 야구 관련 데이터를 분석하는 요청\n",
    "        - 야구 관련 데이터 시각화하는 요청\n",
    "\n",
    "        report:\n",
    "        - 야구 관련 리포트를 작성하는 요청\n",
    "\n",
    "        ect:\n",
    "        - task와 report에 속하지 않는 요청\n",
    "        - 야구와 관련되지 않은 요청\n",
    "        \n",
    "        사용자 요청:\n",
    "        {query} \n",
    "        \"\"\"\n",
    "        prompt = ChatPromptTemplate.from_template(template)\n",
    "        return prompt\n",
    "        \n",
    "    def invoke(self, query:str):\n",
    "        answer = self.chain.invoke({'query':query})\n",
    "        return answer\n",
    "\n",
    "    def __str__(self):\n",
    "        return f'{self.__class__.__name__}'\n",
    "\n",
    "    def __repr__(self):\n",
    "        return f'{self.__class__.__name__}'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db88a0fb-4ce3-4fa5-ba70-9f503b613b8f",
   "metadata": {},
   "source": [
    "## PassiveGoalCreator | get_goal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "940329e9-d54d-4554-9489-39257b62333f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PassiveGoalCreator(object):\n",
    "    def __init__(self, llm=llm):\n",
    "        self.llm = llm\n",
    "        self.prompt = self.__create_prompt()\n",
    "        self.chain = self.prompt | self.llm.with_structured_output(Output.PassiveGoalCreator)\n",
    "\n",
    "    def __create_prompt(self):\n",
    "        template = \"\"\"사용자 입력을 분석하여 명확하고 실행 가능한 목표를 생성해 주세요.\n",
    "            요건\n",
    "            1. 목표는 구체적이고 명확해야 하며, 실행 가능한 수준으로 상세화되어야 합니다.\n",
    "            2. 당신이 실행할 수있는 행동은 아래와 같습니다.\n",
    "            - 사용자의 요청에 따라 적절한 데이터를 불러와 데이터프레임으로 변환합니다.\n",
    "            - 사용자 요청에 따라 DB에서 적절한 데이터를 불러온 후 분석하고 해석합니다.\n",
    "            - 사용자 요청에 따라 DB에서 적절한 데이터를 불러와서 시각화할 수 있는 코드를 작성합니다.\n",
    "            - DB외에 추가로 필요한 정보가 필요할 경우만 판단해서 인터넷 검색을 통해서 정보를 추가합니다.\n",
    "            - 사용자를 위한 보고서를 생성한다.\n",
    "            3. 절대 2.에 명시된 행동 이외의 다른 행동을 취해서는 안 됩니다.\n",
    "            4. 쿼리플랜이 없는 컨텐츠라면 DB에 접속하는 컨텐츠를 할당하지 마십시오.\n",
    "            사용자 입력: {query}\n",
    "            \"\"\"\n",
    "        prompt = ChatPromptTemplate.from_template(template)\n",
    "        return prompt\n",
    "\n",
    "    def invoke(self, query):\n",
    "        answer = self.chain.invoke({'query':query})\n",
    "        return answer.text\n",
    "\n",
    "    def __str__(self):\n",
    "        return f'{self.__class__.__name__}'\n",
    "\n",
    "    def __repr__(self):\n",
    "        return f'{self.__class__.__name__}'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70d17fe8-b371-4a83-8e63-611d0131145b",
   "metadata": {},
   "source": [
    "## GetReportInfo | get_report_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8f45040-8d75-4340-9b60-05f62449e5b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GetReportInfo(object):\n",
    "    def __init__(self, vectorstore: Chroma):\n",
    "        self.llm = ChatGoogleGenerativeAI(model='gemini-2.5-flash')\n",
    "        self.prompt = self.__create_prompt()\n",
    "        self.retriever = vectorstore.as_retriever(search_kwargs={\"k\": 1})\n",
    "        \n",
    "        def format_docs(docs: List[Document]) -> str:\n",
    "            return \"\\n\\n\".join(d.page_content for d in docs) if docs else \"(no context)\"\n",
    "        \n",
    "        self.chain = (\n",
    "        RunnablePassthrough.assign(\n",
    "            # 입력 dict -> \"query\"만 뽑아 retriever에 넣고 -> 문자열로 포맷\n",
    "            context = RunnableLambda(itemgetter(\"query\")) | self.retriever | RunnableLambda(format_docs)\n",
    "        )\n",
    "        | self.prompt\n",
    "        | self.llm.with_structured_output(Output.GetReportInfo)\n",
    "        )\n",
    "    def __create_prompt(self):\n",
    "        template = \"\"\"\n",
    "                너는 \"요구사항-계획서 정합성(Alignment) 심사관\"이다.\n",
    "                입력으로 사용자 질문과 벡터DB에서 가져온 계획서 요약/본문이 주어진다.\n",
    "                너의 임무는: \n",
    "                (a) 질문의 구체적 목표(의도/스펙)를 추출하고,\n",
    "                (b) 들고온 계획서가 그 목표를 충족하는지 평가하고, 데이터의 수집 방법론에 대해서는 평가하지않는다.\n",
    "                (c) 최종 라우팅 결정을 JSON으로 반환하는 것이다.\n",
    "                 - JSON형태 : \"doc_val_response\":\"YES|NO\",\"doc_val_reason\":\"한 줄 요약\",\"documents\":\"들고온 문서(그대로)\"\n",
    "                 \n",
    "                사용자 요구사항:\n",
    "                {query}\n",
    "                \n",
    "                들고온 문서:\n",
    "                {context} \n",
    "                \"\"\" \n",
    "                \n",
    "        prompt = ChatPromptTemplate.from_template(template)\n",
    "        return prompt\n",
    "\n",
    "    def invoke(self, query:dict):\n",
    "        answer = self.chain.invoke({'query':query})\n",
    "        return {\n",
    "            \"doc_val_response\": answer.doc_val_response,\n",
    "            \"doc_val_reason\": answer.doc_val_reason,\n",
    "            \"documents\": answer.documents\n",
    "            }\n",
    "        \n",
    "    def ainvoke(self, query:dict):\n",
    "        answer = self.chain.ainvoke({'query':query})\n",
    "        return {\n",
    "            \"doc_val_response\": answer.doc_val_response,\n",
    "            \"doc_val_reason\": answer.doc_val_reason,\n",
    "            \"documents\": answer.documents\n",
    "            }\n",
    "    \n",
    "   \n",
    "    \n",
    "    def __str__(self):\n",
    "        return f'{self.__class__.__name__}'\n",
    "\n",
    "    def __repr__(self):\n",
    "        return f'{self.__class__.__name__}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "456e7f70",
   "metadata": {},
   "outputs": [],
   "source": [
    "## SingleGetInfo | single_get_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eab29e02",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SingleGettInfo(object):\n",
    "    def __init__(self, vectorstore: Chroma):\n",
    "        self.llm = ChatGoogleGenerativeAI(model='gemini-2.5-flash')\n",
    "        self.prompt = self.__create_prompt()\n",
    "        \n",
    "        self.chain = (\n",
    "        RunnablePassthrough.assign(query=itemgetter(\"query\"))\n",
    "        | self.prompt\n",
    "        | self.llm.with_structured_output(Output.GetReportInfo)\n",
    "        )\n",
    "    def __create_prompt(self):\n",
    "        template = \"\"\"\n",
    "        너는 \"요구사항 명확성 심사관\"이다.\n",
    "        사용자의 질문이 다음 단계를 실행하기에 충분히 구체적이고 실행 가능한지 판단해야 한다.\n",
    "        다음 기준을 따른다:\n",
    "        1. 질문이 **명확한 목표**(무엇을, 왜, 어떻게)를 포함하면 YES\n",
    "        2. 질문이 **모호하거나**, **추상적이거나**, **행동이 정의되지 않으면** NO\n",
    "        3. YES/NO 판단 외에는 불필요한 설명 없이 결과만 JSON 형식으로 출력한다.\n",
    "\n",
    "        예시:\n",
    "        - \"ARI팀의 2024년 득점과 실점을 DB에서 조회해줘\" → YES\n",
    "        - \"ARI팀에 대해 알려줘\" → NO\n",
    "        - \"시즌 데이터를 분석해줘\" → NO\n",
    "        - \"ARI팀의 2024년 투수 WHIP과 OBP 상관관계 분석해줘\" → YES\n",
    "\n",
    "        사용자 질문:\n",
    "        {query}\n",
    "\n",
    "        JSON 출력 형식:\n",
    "        {{\n",
    "          \"doc_val_response\": \"YES\" | \"NO\"\n",
    "        }}\n",
    "        \"\"\"\n",
    "                \n",
    "        prompt = ChatPromptTemplate.from_template(template)\n",
    "        return prompt\n",
    "\n",
    "    def invoke(self, query:dict):\n",
    "        answer = self.chain.invoke({'query':query})\n",
    "        return {\n",
    "            \"doc_val_response\": answer.doc_val_response,\n",
    "            }\n",
    "        \n",
    "    def ainvoke(self, query:dict):\n",
    "        answer = self.chain.ainvoke({'query':query})\n",
    "        return {\n",
    "            \"doc_val_response\": answer.doc_val_response,\n",
    "            }\n",
    "    \n",
    "    def __str__(self):\n",
    "        return f'{self.__class__.__name__}'\n",
    "\n",
    "    def __repr__(self):\n",
    "        return f'{self.__class__.__name__}'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ac76ee5-6fe3-4a48-986f-7d9ca10349d8",
   "metadata": {},
   "source": [
    "## GoalOptimizer | optimize_goal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f9ef9f6-eb22-4dc6-b7c6-cc808843847c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GoalOptimizer(object):\n",
    "    def __init__(self, llm=llm):\n",
    "        self.llm = llm\n",
    "        self.prompt = self.__create_prompt()\n",
    "        self.chain = self.prompt | self.llm.with_structured_output(Output.GoalOptimizer)\n",
    "\n",
    "    def __create_prompt(self):\n",
    "        template = \"\"\"당신은 목표 설정 전문가입니다. 아래의 목표를 SMART 원치(Specific: 구체적, Measurable: 측정 가능한, Achivable: 달성 가능, Relevant: 관련성이 높은, Time-bound: 기한이 있는)에 기반하여 최적화해주세요.\n",
    "        원래목표\n",
    "        {query}\n",
    "        지시사항\n",
    "        1. 원래 목표를 분석하고, 부족한 요소나 개선점을 아래에 주어진 문서의 콘텐츠를 기반으로 파악해 주세요.\n",
    "        2. 주어진 문서의 목차 콘텐츠와 번호를 반드시 같이 명시해주세요.\n",
    "        3. 당신이 할 수 있는 행동은 아래와 같습니다.\n",
    "        - 사용자의 요청에 따라 적절한 데이터를 불러와 데이터프레임으로 변환합니다.\n",
    "        - 사용자 요청에 따라 DB에서 적절한 데이터를 불러온 후 분석하고 해석합니다.\n",
    "        - 사용자 요청에 따라 DB에서 적절한 데이터를 불러와서 시각화할 수 있는 코드를 작성합니다.\n",
    "        - DB외에 추가로 필요한 정보가 필요할 경우만 판단해서 인터넷 검색을 통해서 정보를 추가합니다.\n",
    "        - 사용자를 위한 보고서를 생성한다.\n",
    "        4. SMART 원칙의 각 요소를 고려하고 아래의 주어진 문서를 기반으로 목표를 구체적이고 상세하게 기술해 주세요.\n",
    "        - 절대 추상적인 표현을 포함해서는 안 됩니다.\n",
    "        - 반드시 모든 단어가 실행 가능하고 구체적인지 확인해 주세요.\n",
    "        5. 목표의 달성도를 측정하는 방법을 구체적이고 상세하게 기술해 주세요.\n",
    "        6. 원래 목표에서 기한이 지정되지 않은 경우에는 기한을 고려할 필요가 없습니다.\n",
    "        7. 주의: 절대로 2번 이외의 행동을 취해서는 안 됩니다.\n",
    "        \n",
    "        주어진 문서\n",
    "        {docs}\n",
    "        \"\"\"\n",
    "        prompt = ChatPromptTemplate.from_template(template)\n",
    "        return prompt\n",
    "\n",
    "    def invoke(self, query, docs):\n",
    "        answer = self.chain.invoke({'query':query, 'docs':docs})\n",
    "        return answer.text\n",
    "\n",
    "    def __str__(self):\n",
    "        return f'{self.__class__.__name__}'\n",
    "\n",
    "    def __repr__(self):\n",
    "        return f'{self.__class__.__name__}'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46d2132f",
   "metadata": {},
   "source": [
    "## SingleGoalOptimizer | single_optimize_goal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "593a8f8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SingleGoalOptimizer(object):\n",
    "    def __init__(self, llm=llm):\n",
    "        self.llm = llm\n",
    "        self.prompt = self.__create_prompt()\n",
    "        self.chain = self.prompt | self.llm.with_structured_output(Output.GoalOptimizer)\n",
    "\n",
    "    def __create_prompt(self):\n",
    "        template = \"\"\"\n",
    "        당신은 목표 설정 전문가입니다. \n",
    "        원래목표\n",
    "        {query}\n",
    "        지시사항\n",
    "        1. 원래 목표를 해석하지 말고, 그대로 정확히 수행하세요.\n",
    "        2. 수행 가능한 행동은 아래 중 하나입니다.\n",
    "        - 사용자의 요청에 따라 DB에서 적절한 데이터를 조회하고 마크다운 형식의 데이터를 제공합니다\n",
    "        - 사용자의 요청에 따라 DB에서 조회한 데이터를 분석하고 해석합니다.\n",
    "        - 사용자의 요청에 따라 DB에서 조회한 데이터를 기반으로 Python 시각화 코드를 작성합니다. (plt.show()는 주석처리)\n",
    "        3. 모든 데이터는 'DB에서 조회된 실제 데이터'만 사용합니다. 임의의 랜덤/가상/추정 데이터 생성을 엄격 금지합니다.\n",
    "        4. 주의: 2번 행동 중 하나를 수행할 수 있으며, 절대 2번 행동 이외에는 수행하지 마세요.\n",
    "        \"\"\"\n",
    "        prompt = ChatPromptTemplate.from_template(template)\n",
    "        return prompt\n",
    "\n",
    "    def invoke(self, query):\n",
    "        answer = self.chain.invoke({'query':query})\n",
    "        return answer.text\n",
    "\n",
    "    def __str__(self):\n",
    "        return f'{self.__class__.__name__}'\n",
    "\n",
    "    def __repr__(self):\n",
    "        return f'{self.__class__.__name__}'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b637f0d5-a34a-49d3-9306-1855cc6e6607",
   "metadata": {},
   "source": [
    "## ResponseOptimizer | optimize_response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f93e0d7-c9df-4228-8fb1-91d2d5f35456",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResponseOptimizer(object):\n",
    "    def __init__(self, llm=llm):\n",
    "        self.llm = llm\n",
    "        self.prompt = self.__create_prompt()\n",
    "        self.chain = self.prompt | self.llm | StrOutputParser()\n",
    "\n",
    "    def __create_prompt(self):\n",
    "        human_message = \"\"\"다음 절차에 따라 응답 최적화 프롬프트를 작성해 주세요.\n",
    "        1. 목표분석\n",
    "        제시된 목표를 분석하고 주요 요소와 의도를 파악해 주세요.\n",
    "        2. 응답 사양 수립\n",
    "        목표 달성을 위한 최적의 응답 사양을 고안해 주세요. 톤, 구조, 내용의 초점 등을 고려해 주세요.\n",
    "        3. 구체적인 지침 작성\n",
    "        사전에 수집된 정보에서 사용자의 기대에 부합하는 응답을 위해 필요한, AI 에이전트에 대한 명확하고 실행 가능한 지침을 작성해 주세요. 귀하의 지침으로 AI 에이전트가 수행할 수 있는 있는 것은 이미 조사된 결과를 정리하는 것뿐입니다. 인터넷에 접근할 수 없습니다.\n",
    "        4. 예시 제공\n",
    "        가능하다면 목표에 맞는 응답의 예시를 하나 이상 포함해주세요.\n",
    "        5. 평가 기준 설정\n",
    "        응답의 효과를 측정하기 위한 기준을 정의해 주세요.\n",
    "        다음 구조로 응답 최적화 프롬프트를 출력해 주세요.\n",
    "        목표 분석:\n",
    "        [여기에 목표 분석 결과를 기입]\n",
    "        응답 사양:\n",
    "        [여기에 수립된 응답 사영을 기입]\n",
    "        AI 에이전트에 대한 지침\n",
    "        [여기에 AI 에이전트에 대한 구체적인 지침을 기입]\n",
    "        응답 예시\n",
    "        [여기에 응답 예시를 기입]\n",
    "        평가 기준\n",
    "        [여기에 평가 기준을 기입]\n",
    "        그럼, 다음 목표에 대한 응답 최적화 프롬프트를 작성해 주세요.\n",
    "        {query}\n",
    "        \"\"\"\n",
    "        prompt = ChatPromptTemplate.from_messages(\n",
    "            [\n",
    "                ('system', '당신은 AI 에이전트 시스템의 응답 최적화 전문가입니다. 주어진 목표에 대해 에이전트가 목표에 맞는 응답을 반환하기 위한 응답 사양을 수립해 주세요.'),\n",
    "                ('human', human_message),\n",
    "            ]\n",
    "        )\n",
    "        return prompt\n",
    "\n",
    "    def invoke(self, query):\n",
    "        answer = self.chain.invoke({'query':query})\n",
    "        return answer\n",
    "\n",
    "    def __str__(self):\n",
    "        return f'{self.__class__.__name__}'\n",
    "\n",
    "    def __repr__(self):\n",
    "        return f'{self.__class__.__name__}'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "285ed8ce-995d-47a1-801b-5cd635a762e6",
   "metadata": {},
   "source": [
    "## TaskDecomposer | decompose_tasks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19944aeb-e9ef-4d08-8c6a-1a2b1d1fa60f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TaskDecomposer(object):\n",
    "    def __init__(self, llm=llm):\n",
    "        self.llm = llm\n",
    "        self.prompt = self.__create_prompt()\n",
    "        self.chain = self.prompt | self.llm.with_structured_output(Output.TaskDecomposer)\n",
    "\n",
    "    def __create_prompt(self):\n",
    "        template = \"\"\"태스크: 주어진 목표를 콘텐츠만을 기준으로 실행 가능한 태스크로 분해해 주세요.\n",
    "        요건\n",
    "        1. 다음 행동만으로 목표를 달성할 것. 절대 지정된 이외의 행동을 취하지 말 것.\n",
    "        - 사용자의 요청에 따라 적절한 데이터를 불러와 데이터프레임으로 변환합니다.\n",
    "        - 사용자 요청에 따라 DB에서 적절한 데이터를 불러와서 시각화할 수 있는 코드를 작성합니다.\n",
    "        - DB외에 추가로 필요한 정보가 필요할 경우만 판단해서 인터넷 검색을 통해서 정보를 추가합니다.\n",
    "        2. 각 태스크는 구체적으로 상세하게 기재하며, 단독으로 실행 및 검증 가능한 정보를 포함할 것. 추상적인 표현을 일절 포함하지 말것\n",
    "        3. 목표에 작성된 콘텐츠 수를 기준으로 태스크를 최소한으로 생성할 것.\n",
    "        4. 아래와 같이 기존 콘텐츠에 대한 구분이 앞에 올 것\n",
    "        - 콘텐츠 번호. 기존 콘텐츠 이름 : 내용\n",
    "        5. 태스크는 실행 가능한 순서로 리스트화할 것\n",
    "        목표: {query}\n",
    "        \"\"\"\n",
    "        prompt = ChatPromptTemplate.from_template(template)\n",
    "        return prompt\n",
    "\n",
    "    def invoke(self, query):\n",
    "        answer = self.chain.invoke({'query':query})\n",
    "        return answer.tasks\n",
    "\n",
    "    def __str__(self):\n",
    "        return f'{self.__class__.__name__}'\n",
    "\n",
    "    def __repr__(self):\n",
    "        return f'{self.__class__.__name__}'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4948114-e1a9-4c76-9d3a-3429bdf94c98",
   "metadata": {},
   "source": [
    "## ExecuteTask | report_execute_task, task_execute_task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6e5d937-9343-4b38-a1ad-cd9073a3433c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"다음 태스크를 실행하고 상세한 답변을 제공해주세요. 당신은 다음 도구에 접근할 수 있습니다:\n",
    "    \n",
    "        {tools}\n",
    "        \n",
    "        다음 형식을 사용하세요:\n",
    "        \n",
    "        Question: 답변해야 하는 입력 질문\n",
    "        Thought: 무엇을 할지 항상 생각하세요.\n",
    "        Action: 취해야 할 행동, [{tool_names}] 중 하나여야 합니다. 리스트에 있는 도구 중 1개를 택하십시오.\n",
    "        Action Input: 행동에 대한 입력값\n",
    "        Observation: 행동의 결과\n",
    "        ... (이 Thought/Action/Action Input/Observation의 과정이 N번 반복될 수 있습니다.)\n",
    "        Thought: 이제 최종 답변을 알겠습니다.\n",
    "        Final Answer: 원래 입력된 질문에 대한 최종 답변\n",
    "        \n",
    "        ## 추가적인 주의사항\n",
    "        - 반드시 [Thought/Action/Action Input format] 이 사이클의 순서를 준수하십시오. 항상 Action 전에는 Thought가 먼저 나와야 합니다.\n",
    "        - 최종 답변은 Question의 지시사항을 준수한 답변만 제공하십시오\n",
    "        - 각각 표(테이블) 형태를 Question에서 요구하면 DataLoader, 차트(시각화) 형태를 Question에서 요구하면 BITool, 요약 또는 분석 DataAnalyst 활용\n",
    "        - Question의 지시사항의 최종적인 요구의 산출문만 제공해주세요\n",
    "        - DataLoader툴을 사용했다면 Json형식의 데이터를 제공하고, BITool을 사용했다면 순수한 Python 코드만을 제공하고 마지막으로 DataAnalyst를 활용했다면 700이내의 요약을 부가적인 타이틀 없이 줄글로만 제공해주세요\n",
    "        - 정보가 취합되었다면 불필요하게 사이클을 반복하지 마십시오.\n",
    "        - 묻지 않은 정보를 찾으려고 도구를 사용하지 마십시오.\n",
    "        - 실행은 철저하고 포괄적으로 수행하세요.\n",
    "        \n",
    "        시작하세요!\n",
    "        \n",
    "        Question: {task}\n",
    "        Thought: {agent_scratchpad}\n",
    "        \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9ae0c21-be80-49b6-a2e1-c397574d5053",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ExecuteTask(object):\n",
    "    def __init__(self, tools:list=tools, llm=llm):\n",
    "        self.llm = llm\n",
    "        self.tools = tools\n",
    "        self.prompt = self.__create_prompt()\n",
    "        self.agent = self.__create_agent()\n",
    "\n",
    "    def __create_prompt(self):\n",
    "    \n",
    "        template = \"\"\"다음 태스크를 실행하고 상세한 답변을 제공해주세요. 당신은 다음 도구에 접근할 수 있습니다:\n",
    "    \n",
    "        {tools}\n",
    "        \n",
    "        다음 형식을 사용하세요:\n",
    "        \n",
    "        Question: 답변해야 하는 입력 질문\n",
    "        Thought: 무엇을 할지 항상 생각하세요.\n",
    "        Action: 취해야 할 행동, [{tool_names}] 중 하나여야 합니다. 리스트에 있는 도구 중 1개를 택하십시오.\n",
    "        Action Input: 행동에 대한 입력값\n",
    "        Observation: 행동의 결과\n",
    "        ... (이 Thought/Action/Action Input/Observation의 과정이 N번 반복될 수 있습니다.)\n",
    "        Thought: 이제 최종 답변을 알겠습니다.\n",
    "        Final Answer: 원래 입력된 질문에 대한 최종 답변\n",
    "        \n",
    "        ## 추가적인 주의사항\n",
    "        - 반드시 [Thought/Action/Action Input format] 이 사이클의 순서를 준수하십시오. 항상 Action 전에는 Thought가 먼저 나와야 합니다.\n",
    "        - 최종 답변에는 최대한 많은 내용을 포함하십시오.\n",
    "        - 한 번의 검색으로 해결되지 않을 것 같다면 문제를 분할하여 푸는 것이 중요합니다.\n",
    "        - 정보가 취합되었다면 불필요하게 사이클을 반복하지 마십시오.\n",
    "        - 묻지 않은 정보를 찾으려고 도구를 사용하지 마십시오.\n",
    "        - 실행은 철저하고 포괄적으로 수행하세요.\n",
    "        - 가능한 구체적인 사실이나 데이터를 제공하세요.\n",
    "        - 발견한 내용을 명확하게 요약하세요.\n",
    "        - 차트를 생성하는 코드를 작성하는 요청이 들어오면, 차트를 생성하는 코드만 답변하세요.\n",
    "        \n",
    "        시작하세요!\n",
    "        \n",
    "        Question: {task}\n",
    "        Thought: {agent_scratchpad}\n",
    "        \"\"\"\n",
    "        prompt = ChatPromptTemplate.from_template(template)\n",
    "        return prompt\n",
    "\n",
    "    def __create_agent(self):\n",
    "        agent = create_react_agent(llm=self.llm, tools=self.tools, prompt=self.prompt)\n",
    "        executor = AgentExecutor(agent=agent, tools=self.tools, verbose=True, handle_parsing_errors=True)\n",
    "        return executor\n",
    "        \n",
    "    def invoke(self, task):\n",
    "        answer = self.agent.invoke({'task':task})\n",
    "        return answer['output']\n",
    "\n",
    "    def ainvoke(self, task):\n",
    "        answer = self.agent.ainvoke({'task':task})\n",
    "        return answer['output']\n",
    "\n",
    "    def __str__(self):\n",
    "        return f'{self.__class__.__name__}'\n",
    "\n",
    "    def __repr__(self):\n",
    "        return f'{self.__class__.__name__}'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac040628-4169-470e-a948-ce1f9dff2cea",
   "metadata": {},
   "source": [
    "## ResultAggregator | aggregate_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4ca6add-6a61-4f4f-8fed-78e1fed31c2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResultAggregator(object):\n",
    "    def __init__(self, llm=llm):\n",
    "        self.llm = llm\n",
    "        self.prompt = self.__create_prompt()\n",
    "        self.chain = self.prompt | self.llm | StrOutputParser()\n",
    "\n",
    "    def __create_prompt(self):\n",
    "        template = \"\"\"주어진 목표:\n",
    "        {optimized_goal}\n",
    "        \n",
    "        조사결과:\n",
    "        {results}\n",
    "        \n",
    "        주어진 목표에 대해서 조사 결과를 활용하여 다음 지시에 기반한 응답을 생성해 주세요.\n",
    "        {optimized_response}\n",
    "        \"\"\"\n",
    "        prompt = ChatPromptTemplate.from_template(template)\n",
    "        return prompt\n",
    "        \n",
    "    def invoke(self, optimized_goal:str, results:str, optimized_response:str):\n",
    "        answer = self.chain.invoke({'optimized_goal':optimized_goal, 'results':results, 'optimized_response':optimized_response})\n",
    "        return answer\n",
    "\n",
    "    def __str__(self):\n",
    "        return f'{self.__class__.__name__}'\n",
    "\n",
    "    def __repr__(self):\n",
    "        return f'{self.__class__.__name__}'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f65aaa8",
   "metadata": {},
   "source": [
    "## SingleResultAggregator | single_aggregate_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "568978a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SingleResultAggreagor(object):\n",
    "    def __init__(self, llm=llm):\n",
    "        self.llm = llm\n",
    "        self.prompt = self.__create_prompt()\n",
    "        self.chain = self.prompt | self.llm | StrOutputParser() | RunnableLambda(self.__clean_answer)\n",
    "\n",
    "    def __create_prompt(self):\n",
    "        template = \"\"\"\n",
    "        주어진 목표:\n",
    "        {optimized_goal}\n",
    "        \n",
    "        조사결과:\n",
    "        {results}\n",
    "        \n",
    "        주어진 목표에 대해서 조사 결과를 활용하여 다음 지시에 기반한 응답을 무조건 하나만 생성해 주세요.\n",
    "        - 오직 조사결과만 ouput으로 지정한다. (수행 과정, 로그, 코멘트 등 작성 금지)\n",
    "        \"\"\"\n",
    "        prompt = ChatPromptTemplate.from_template(template)\n",
    "        return prompt\n",
    "\n",
    "    def __clean_answer(self, answer:str):\n",
    "        answer = answer.replace('```', '')\n",
    "        answer = answer.replace('python', '')\n",
    "        answer = answer.replace('plt.show()', '')\n",
    "        return answer\n",
    "    \n",
    "    def invoke(self, optimized_goal:str, results:str):\n",
    "        answer = self.chain.invoke({'optimized_goal':optimized_goal, 'results':results})\n",
    "        return answer\n",
    "\n",
    "    def __str__(self):\n",
    "        return f'{self.__class__.__name__}'\n",
    "\n",
    "    def __repr__(self):\n",
    "        return f'{self.__class__.__name__}'\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48276b65-e235-4487-9fdf-a430e5b6821f",
   "metadata": {},
   "source": [
    "## ResponseCustomer | response_customer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48b16a85-f722-40f2-a16c-3c37b448219b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResponseCustomer(object):\n",
    "    def __init__(self):\n",
    "        self.llm = ChatGoogleGenerativeAI(model='gemini-2.5-flash', temperature=0.2)\n",
    "        self.prompt = self.__create_prompt()\n",
    "        \n",
    "        self.chain = self.prompt | self.llm | StrOutputParser()\n",
    "        \n",
    "    def __create_prompt(self):\n",
    "        template = \"\"\"\n",
    "                당신은 챗봇입니다.\n",
    "                아래 '결정 사유'를 참고해, 사용자가 무엇을 원했는지 확인하고 아래의 조건을 선택해서 답변을 생성하십시오.\n",
    "                이전 질문이 있다면 이것도 기억하고 답변을 생성하십시오.\n",
    "                \n",
    "                조건 1: 결정 사유가 라우팅 실패에 관련된 내용일 경우\n",
    "                - 형식 가이드(3~5문장, 한국어, 공손하지만 간결하게):\n",
    "                1) 확인: 사용자의 의도를 한 문장으로 재진술 (예: \"~정보를 요청하셨군요.\")\n",
    "                2) 한계: 현재 참조 가능한 자료에 무엇이 없는지 명확히 (예: \"현재 제가 참고할 수 있는 정보에는 ~가 포함되어 있지 않습니다.\")\n",
    "                3) 대안: a) 가능한 주제로 이어가기\n",
    "\n",
    "                조건 2: 결정 사유가 모드에 대한 선택에 대한 이유일 경우\n",
    "                - 형식 가이드(3~5문장, 한국어, 공손하게 간결하게):\n",
    "                1) 확인: 사용자의 의도를 한 문장으로 재진술 (예: \"~정보를 요청하셨군요.\")\n",
    "                2) 답변: 사용자의 의도에 대해서 답변을 한다.\n",
    "                3) 한계: 최대한 꾸며내거나 부풀리지 않고 정확하게 답변하려고 노력하여야한다. 그리고 답변이 정확하지 않을 수 있다는 사실을 분명히 한다.\n",
    "\n",
    "                [사용자 질문]\n",
    "                {question}\n",
    "\n",
    "                [결정 사유]\n",
    "                {doc_val_reason}\n",
    "                \n",
    "                [이전 질문]\n",
    "                {prev_user_question}\n",
    "                \"\"\" \n",
    "        prompt = ChatPromptTemplate.from_template(template)\n",
    "        return prompt\n",
    "    \n",
    "    def invoke(self, query:dict, doc_val_reason:str, prev_user_query:str):\n",
    "        return self.chain.invoke({'question':query,\n",
    "                                  'doc_val_reason': doc_val_reason,\n",
    "                                  'prev_user_question': prev_user_query})\n",
    "\n",
    "    def ainoke(self, query:dict, doc_val_reason:str, prev_user_query:str):\n",
    "        return self.chain.ainvoke({'question':query,\n",
    "                                  'doc_val_reason': doc_val_reason,\n",
    "                                  'prev_user_question': prev_user_query})\n",
    "        \n",
    "    \n",
    "    def __format_docs(docs: List[Document]) -> str:\n",
    "            return \"\\n\\n\".join(d.page_content for d in docs) if docs else \"(no context)\"\n",
    "    \n",
    "    def __str__(self):\n",
    "        return f'{self.__class__.__name__}'\n",
    "\n",
    "    def __repr__(self):\n",
    "        return f'{self.__class__.__name__}'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc56c25d",
   "metadata": {},
   "source": [
    "## GetReportInfo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "770af44e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GetReportInfo(object):\n",
    "    def __init__(self, vectorstore: Chroma):\n",
    "        self.llm = ChatGoogleGenerativeAI(model='gemini-2.5-flash')\n",
    "        self.prompt = self.__create_prompt()\n",
    "        self.retriever = vectorstore.as_retriever(search_kwargs={\"k\": 1})\n",
    "        \n",
    "        def format_docs(docs: List[Document]) -> str:\n",
    "            return \"\\n\\n\".join(d.page_content for d in docs) if docs else \"(no context)\"\n",
    "        \n",
    "        self.chain = (\n",
    "        RunnablePassthrough.assign(\n",
    "            # 입력 dict -> \"query\"만 뽑아 retriever에 넣고 -> 문자열로 포맷\n",
    "            context = RunnableLambda(itemgetter(\"query\")) | self.retriever | RunnableLambda(format_docs)\n",
    "        )\n",
    "        | self.prompt\n",
    "        | self.llm.with_structured_output(Output.GetReportInfo)\n",
    "        )\n",
    "    def __create_prompt(self):\n",
    "        template = \"\"\"\n",
    "                너는 \"요구사항-계획서 정합성(Alignment) 심사관\"이다.\n",
    "                입력으로 사용자 질문과 벡터DB에서 가져온 계획서 요약/본문이 주어진다.\n",
    "                너의 임무는: \n",
    "                (a) 질문의 구체적 목표(의도/스펙)를 추출하고,\n",
    "                (b) 들고온 계획서가 그 목표를 충족하는지 평가하고, 데이터의 수집 방법론에 대해서는 평가하지않는다.\n",
    "                (c) 사용자의 목표에 구체적인 보고서 작성 대상이 있는지 판단한다.\n",
    "                (d) 최종 라우팅 결정을 JSON으로 반환하는 것이다.\n",
    "                 - JSON형태 : \"doc_val_response\":\"YES|NO\",\"doc_val_reason\":\"한 줄 요약\",\"documents\":\"들고온 문서(그대로)\"\n",
    "                 \n",
    "                사용자 요구사항:\n",
    "                {query}\n",
    "                \n",
    "                들고온 문서:\n",
    "                {context} \n",
    "                \"\"\" \n",
    "                \n",
    "        prompt = ChatPromptTemplate.from_template(template)\n",
    "        return prompt\n",
    "\n",
    "    def invoke(self, query:dict):\n",
    "        answer = self.chain.invoke({'query':query})\n",
    "        return {\n",
    "            \"doc_val_response\": answer.doc_val_response,\n",
    "            \"doc_val_reason\": answer.doc_val_reason,\n",
    "            \"documents\": answer.documents\n",
    "            }\n",
    "        \n",
    "    def ainvoke(self, query:dict):\n",
    "        answer = self.chain.ainvoke({'query':query})\n",
    "        return {\n",
    "            \"doc_val_response\": answer.doc_val_response,\n",
    "            \"doc_val_reason\": answer.doc_val_reason,\n",
    "            \"documents\": answer.documents\n",
    "            }\n",
    "    \n",
    "   \n",
    "    \n",
    "    def __str__(self):\n",
    "        return f'{self.__class__.__name__}'\n",
    "\n",
    "    def __repr__(self):\n",
    "        return f'{self.__class__.__name__}'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b935ce29-09d3-4e98-aa33-e17ec7a5b7e1",
   "metadata": {},
   "source": [
    "# LangGraph"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19586083",
   "metadata": {},
   "source": [
    "## State"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24b9bbb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Turn(BaseModel):\n",
    "    user_query: str=Field(default_factory=list, description='유저 쿼리')      \n",
    "    mode: Literal['task', 'report', 'ect'] = Field(default='', description=\"모드\")\n",
    "    ai_answer: str=Field(default_factory=list, description='답변')                           \n",
    "    ts: datetime=Field(default_factory=datetime.now())\n",
    "\n",
    "class State(BaseModel):\n",
    "    query: str = Field(..., description='사용자가 입력한 쿼리')\n",
    "    history: Annotated[list[Turn], add] = Field(default_factory= list, description=' 이전 기록')\n",
    "    goal: str = Field(default='', description='사용자가 입력한 쿼리에서 목표 추출')\n",
    "    mode: Literal['task', 'report', 'ect'] = Field(default='', description='사용자 요청 유형')\n",
    "    doc_val_response: Literal[\"YES\",\"NO\"] = Field(default='YES', description='문서 검증 결과')\n",
    "    doc_val_reason:str= Field(default='', description='문서 검증 증거')\n",
    "    documents:str = Field(default='', description='검증에 참조한 문서')\n",
    "    optimized_goal: str = Field(default='', description='최적화된 목표') \n",
    "    optimized_response: str = Field(default='', description='최적화된 응답 정의')\n",
    "    tasks: list = Field(default_factory=list, description='실행할 테스크 리스트')\n",
    "    current_task_index: int = Field(default=0, description='현재 실행 중인 테스크 변호')\n",
    "    results: list = Field(default_factory=list, description='실행 완료된 테스크 결과 리스트')\n",
    "    final_output: str = Field(default='', description='최종 출력 결과')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27a05e07",
   "metadata": {},
   "source": [
    "## Node"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37645542-2ec4-45c0-b421-2b6ff3581d1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.graph import START, END, StateGraph\n",
    "from functools import wraps\n",
    "\n",
    "def node_logging(func):\n",
    "    @wraps(func)\n",
    "    def wrapper(*args, **kwargs):\n",
    "        print(f\"{func.__name__} 시작\")\n",
    "        result = func(*args, **kwargs)\n",
    "        print(f\"{func.__name__} 완료\")\n",
    "        return result\n",
    "    return wrapper"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81a22618-2024-4401-87c6-81911bc83def",
   "metadata": {},
   "source": [
    "### Node 정의"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "724f7360",
   "metadata": {},
   "outputs": [],
   "source": [
    "@node_logging\n",
    "def get_mode(state:State):\n",
    "    state = state.dict()\n",
    "    query = state['query']\n",
    "    answer = GetMode().invoke(query)\n",
    "    return {'mode':answer.mode, 'doc_val_reason':answer.reason}\n",
    "\n",
    "\n",
    "# 리포트\n",
    "@node_logging\n",
    "def get_goal(state:State):\n",
    "    state = state.dict()\n",
    "    query = state['query']\n",
    "    asnwer = PassiveGoalCreator().invoke(query)\n",
    "    return {'goal':asnwer}\n",
    "\n",
    "@node_logging\n",
    "def get_report_info(state:State):\n",
    "    state = state.dict()\n",
    "    query = state['goal']\n",
    "    answer = GetReportInfo(vectorstore=vectorstore).invoke(query)\n",
    "    return {'doc_val_response': answer['doc_val_response'],\n",
    "            \"doc_val_reason\": answer['doc_val_reason'],\n",
    "            \"documents\": answer['documents']}\n",
    "\n",
    "@node_logging\n",
    "def optimize_goal(state:State):\n",
    "    state = state.dict()\n",
    "    query = state['goal']\n",
    "    docs = state['documents']\n",
    "    answer = GoalOptimizer().invoke(query, docs)\n",
    "    \n",
    "    # tasks, index 초기화\n",
    "\n",
    "    return {\n",
    "            'optimized_goal':answer,\n",
    "            \"tasks\": [],\n",
    "            'results': [],\n",
    "            \"current_task_index\": 0\n",
    "            }\n",
    " \n",
    "@node_logging\n",
    "def optimize_response(state:State):\n",
    "    state = state.dict()\n",
    "    query = state['optimized_goal']\n",
    "    answer = ResponseOptimizer().invoke(query)\n",
    "    return {'optimized_response':answer}\n",
    "\n",
    "@node_logging\n",
    "def decompose_tasks(state:State):\n",
    "    state = state.dict()\n",
    "    query = state['optimized_goal']\n",
    "    answer = TaskDecomposer().invoke(query)\n",
    "    return {'tasks': answer}\n",
    "\n",
    "@node_logging\n",
    "def execute_task(state:State):\n",
    "    state = state.dict()\n",
    "    complete_tasks = state['results']\n",
    "    current_task_index = state['current_task_index']\n",
    "    task = state['tasks'][current_task_index]\n",
    "    answer = ExecuteTask().invoke(task)\n",
    "    current_task_index += 1\n",
    "    return {'results': complete_tasks + [answer], 'current_task_index':current_task_index}\n",
    "\n",
    "@node_logging\n",
    "def aggregate_result(state:State):\n",
    "    state = state.dict()\n",
    "    results = state['results']\n",
    "    optimized_goal = state['optimized_goal']\n",
    "    optimized_response = state['optimized_response']\n",
    "    answer = ResultAggregator().invoke(optimized_goal, results, optimized_response)\n",
    "    \n",
    "    history = {\n",
    "        \"user_query\": state['query'],\n",
    "        \"ai_answer\": answer,\n",
    "        \"ts\" : datetime.now()\n",
    "    }\n",
    "    \n",
    "    return {'final_output': answer, \"history\" : [history]}\n",
    "\n",
    "\n",
    "\n",
    "# 단일 태스크\n",
    "\n",
    "\n",
    "@node_logging\n",
    "def single_get_info(state:State):\n",
    "    state = state.dict()\n",
    "    query = state['goal']\n",
    "    answer = SingleGettInfo(vectorstore=vectorstore).invoke(query)\n",
    "    return {'doc_val_response': answer['doc_val_response']}\n",
    "\n",
    "@node_logging\n",
    "def single_optimize_goal(state:State):\n",
    "    state = state.dict()\n",
    "    query = state['goal']\n",
    "    answer = SingleGoalOptimizer().invoke(query)\n",
    "    return {'optimized_goal':answer}\n",
    "\n",
    "@node_logging\n",
    "def single_execute_task(state:State):\n",
    "    state = state.dict()\n",
    "    task = state['optimized_goal']\n",
    "    answer = ExecuteTask().invoke(task)\n",
    "    return {'results': [answer]}\n",
    "\n",
    "@node_logging\n",
    "def single_aggregate_result(state:State):\n",
    "    state = state.dict()\n",
    "    results = state['results']\n",
    "    optimized_goal = state['optimized_goal']\n",
    "    answer = SingleResultAggreagor().invoke(optimized_goal, results)\n",
    "    \n",
    "    history = {\n",
    "        \"user_query\": state['query'],\n",
    "        \"ai_answer\": answer,\n",
    "        \"ts\" : datetime.now()\n",
    "    }\n",
    "    \n",
    "    return {'final_output': answer, 'history': [history]}\n",
    "\n",
    "\n",
    "# 챗봇\n",
    "@node_logging\n",
    "def response_customer(state:State):\n",
    "    state = state.dict()\n",
    "    query = state['query']\n",
    "    doc_val_reason = state['doc_val_reason']\n",
    "    \n",
    "    history = state.get('history', [])\n",
    "    if history:\n",
    "        prev_user_query = history[-1]['user_query']\n",
    "    else: \n",
    "        prev_user_query=\"이전 질문 없음\"\n",
    "        \n",
    "    answer = ResponseCustomer().invoke(query = query, doc_val_reason = doc_val_reason, prev_user_query=prev_user_query)\n",
    "    \n",
    "    history = {\n",
    "        \"user_query\": state['query'],\n",
    "        \"ai_answer\": answer,\n",
    "        \"ts\" : datetime.now()\n",
    "    }\n",
    "    \n",
    "    return {'final_output': answer, \"history\" : [history]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17a3a8c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "workflow = StateGraph(State)\n",
    "\n",
    "workflow.add_node('get_mode', get_mode)\n",
    "\n",
    "# 리포트\n",
    "workflow.add_node('get_goal', get_goal)\n",
    "workflow.add_node('get_report_info', get_report_info)\n",
    "workflow.add_node('optimize_goal', optimize_goal)\n",
    "workflow.add_node('optimize_response', optimize_response)\n",
    "workflow.add_node('decompose_tasks', decompose_tasks)\n",
    "workflow.add_node('report_execute_task', execute_task)\n",
    "workflow.add_node('aggregate_result', aggregate_result)\n",
    "\n",
    "# 단일 태스크\n",
    "workflow.add_node('single_get_goal', get_goal)\n",
    "workflow.add_node('single_get_info', single_get_info)\n",
    "workflow.add_node('single_optimize_goal', single_optimize_goal) \n",
    "workflow.add_node('single_execute_task', single_execute_task)\n",
    "workflow.add_node('single_aggregate_result', single_aggregate_result)\n",
    "\n",
    "\n",
    "\n",
    "# 챗봇\n",
    "workflow.add_node('response_customer', response_customer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b588d17c",
   "metadata": {},
   "source": [
    "## Edge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "042102c4-25f4-4374-b1b9-ace60988cd8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "workflow.add_edge(START, 'get_mode')\n",
    "workflow.add_conditional_edges('get_mode', lambda state: state.dict()['mode'], {'task':'single_get_goal', 'report':'get_goal', 'ect':'response_customer'})\n",
    "workflow.add_edge('single_get_goal', 'single_get_info')\n",
    "workflow.add_conditional_edges('single_get_info', lambda state: state.dict()['doc_val_response'], {'YES':'single_optimize_goal', 'NO': END})\n",
    "workflow.add_edge('single_optimize_goal', 'single_execute_task')\n",
    "workflow.add_edge('single_execute_task', 'single_aggregate_result')\n",
    "\n",
    "workflow.add_edge('response_customer', END)\n",
    "\n",
    "workflow.add_edge('get_goal', 'get_report_info')\n",
    "workflow.add_conditional_edges('get_report_info', lambda state: state.dict()['doc_val_response'], {'YES':'optimize_goal', 'NO':'response_customer'})\n",
    "workflow.add_edge('optimize_goal', 'optimize_response')\n",
    "workflow.add_edge('optimize_response', 'decompose_tasks')\n",
    "workflow.add_edge('decompose_tasks', 'report_execute_task')\n",
    "workflow.add_conditional_edges('report_execute_task', lambda state: state.dict()['current_task_index'] < len(state.dict()['tasks']), {True:'report_execute_task', False:'aggregate_result'})\n",
    "workflow.add_edge('aggregate_result', END)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebf8608e-b652-4f20-86db-7b194ddfe531",
   "metadata": {},
   "source": [
    "## Graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "554e5daf-9b64-48fa-b843-6bf28c1f2023",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.checkpoint.memory import MemorySaver\n",
    "\n",
    "memory = MemorySaver()\n",
    "graph = workflow.compile(checkpointer=memory)\n",
    "conversation_id = \"my-test-session-001\" \n",
    "config = {\"configurable\": {\"thread_id\": conversation_id}}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48453d9f",
   "metadata": {},
   "source": [
    "# 테스트"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb8b8f8a-5762-4761-881a-c826941837d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "result_ect = graph.invoke({'query':'야구에서 WHIP이라는 지표에 대해서 알려줘'}, config)\n",
    "result_ect['final_output']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abac996d-962b-4b45-9b69-76204d4e9c23",
   "metadata": {},
   "outputs": [],
   "source": [
    "result_ect2 = graph.invoke({'query':'그럼 내가 전에 물어봤던 지표랑 비슷한 지표는 뭐가 있을까'}, config)\n",
    "result_ect2['final_output']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa21cb49-86b7-4349-939a-d2b7ebb9f012",
   "metadata": {},
   "outputs": [],
   "source": [
    "result_task = graph.invoke({'query':'ARI팀의 2024년 시즌 득점과 실점 데이터를 보여줘'}, config)\n",
    "result_task['final_output']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a634e9b4-d5cf-49f5-be4d-99e3ded0a105",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "result_task2 = graph.invoke({'query':'2024년 시즌 1위 팀의 승률을 차트로 그려줘.'}, config)\n",
    "print(result_task2['final_output'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ac452ce-38d3-45b2-94ba-986842c12f84",
   "metadata": {},
   "outputs": [],
   "source": [
    "result_task3 = graph.invoke({'query':'2024년 ARI팀의 전력분석보고서 작성해줘.'}, config)\n",
    "result_task3['final_output']"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
