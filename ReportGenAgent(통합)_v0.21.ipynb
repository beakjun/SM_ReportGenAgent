{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "074e14c7-629b-4963-a662-b6f4944e07a8",
   "metadata": {},
   "source": [
    "# 모듈 불러오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "23775e48",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\EXEM\\Documents\\두산베어스\\.venv\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "c:\\Users\\EXEM\\Documents\\두산베어스\\.venv\\Lib\\site-packages\\IPython\\core\\interactiveshell.py:3699: LangChainDeprecationWarning: As of langchain-core 0.3.0, LangChain uses pydantic v2 internally. The langchain_core.pydantic_v1 module was a compatibility shim for pydantic v1, and should no longer be used. Please update the code to import from Pydantic directly.\n",
      "\n",
      "For example, replace imports like: `from langchain_core.pydantic_v1 import BaseModel`\n",
      "with: `from pydantic import BaseModel`\n",
      "or the v1 compatibility namespace if you are working in a code base that has not been fully upgraded to pydantic 2 yet. \tfrom pydantic.v1 import BaseModel\n",
      "\n",
      "  exec(code_obj, self.user_global_ns, self.user_ns)\n"
     ]
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "\n",
    "from langchain_community.tools import QuerySQLDatabaseTool\n",
    "from langchain_community.utilities import SQLDatabase\n",
    "from langchain.chains import create_sql_query_chain\n",
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain.prompts import ChatPromptTemplate\n",
    "from langchain.schema.runnable import RunnableLambda, RunnablePassthrough\n",
    "from langchain_community.tools.tavily_search import TavilyAnswer, TavilySearchResults\n",
    "from langsmith import Client\n",
    "\n",
    "from BK.db import DB\n",
    "import re\n",
    "\n",
    "from langchain_community.embeddings import HuggingFaceEmbeddings\n",
    "from langchain_community.vectorstores import Chroma\n",
    "from operator import itemgetter\n",
    "from langchain.schema import Document\n",
    "from typing import List, Literal, Any\n",
    "\n",
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "from langchain.prompts import ChatPromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.pydantic_v1 import BaseModel, Field\n",
    "\n",
    "from langchain.agents import create_react_agent,AgentExecutor\n",
    "\n",
    "from typing import Annotated\n",
    "from datetime import datetime \n",
    "from operator import add"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60a85ad1",
   "metadata": {},
   "source": [
    "# 필요 환경정의 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4093fca9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\EXEM\\AppData\\Local\\Temp\\ipykernel_40800\\3921034538.py:15: LangChainDeprecationWarning: The class `HuggingFaceEmbeddings` was deprecated in LangChain 0.2.2 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-huggingface package and should be used instead. To use it run `pip install -U :class:`~langchain-huggingface` and import as `from :class:`~langchain_huggingface import HuggingFaceEmbeddings``.\n",
      "  embedding = HuggingFaceEmbeddings(\n",
      "C:\\Users\\EXEM\\AppData\\Local\\Temp\\ipykernel_40800\\3921034538.py:24: LangChainDeprecationWarning: The class `Chroma` was deprecated in LangChain 0.2.9 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-chroma package and should be used instead. To use it run `pip install -U :class:`~langchain-chroma` and import as `from :class:`~langchain_chroma import Chroma``.\n",
      "  vectorstore = Chroma(\n"
     ]
    }
   ],
   "source": [
    "load_dotenv('.env')\n",
    "\n",
    "# llm\n",
    "llm = ChatGoogleGenerativeAI(model='gemini-2.5-flash', temperature=0)\n",
    "llm_chat = ChatGoogleGenerativeAI(model='gemini-2.5-flash', temperature=0.2)\n",
    "\n",
    "# 랭스미스\n",
    "client = Client()\n",
    "# DB\n",
    "db = SQLDatabase.from_uri('postgresql://postgres:postgres@10.10.50.155:1108/postgres', schema=\"doosan\")\n",
    "\n",
    "# 벡터 DB\n",
    "from langchain_community.embeddings import HuggingFaceEmbeddings\n",
    "embedding_model_name = \"nlpai-lab/KoE5\"\n",
    "embedding = HuggingFaceEmbeddings(\n",
    "    model_name=embedding_model_name,\n",
    "    model_kwargs={\n",
    "        \"device\": \"cpu\",\n",
    "        # \"trust_remote_code\": True,  # 모델에 따라 필요할 수 있음\n",
    "    },\n",
    "    # encode_kwargs={\"normalize_embeddings\": True},  # 코사인 유사도 안정화 (버전에 따라 지원)\n",
    ")\n",
    "\n",
    "vectorstore = Chroma(\n",
    "    persist_directory='./chroma_reports_db',\n",
    "    embedding_function=embedding,\n",
    "    collection_name=\"reports_ko1\" \n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2c56716-267f-45fa-9d23-0cf1c947bfca",
   "metadata": {},
   "source": [
    "# Tools"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cab98db",
   "metadata": {},
   "source": [
    "## DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4f774b5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# DataLoader\n",
    "class DataLoader(object):\n",
    "    def __init__(self, db:SQLDatabase = db):\n",
    "        self.llm = ChatGoogleGenerativeAI(model='gemini-2.5-flash', temperature=0)\n",
    "        self.db = db\n",
    "        self.write_query = create_sql_query_chain(llm, db)\n",
    "        self.execute_query = QuerySQLDatabaseTool(db=db)\n",
    "        self.chain = RunnableLambda(self.__create_prompt) | self.write_query | RunnableLambda(self.__clean_answer) |RunnableLambda(self._execute_query)\n",
    "\n",
    "    def __create_prompt(self, question:str):\n",
    "        question = question['question']\n",
    "        prompt = f\"\"\"\n",
    "        당신은 SQL 쿼리 전문가입니다. 사용자의 요청을 SQL 쿼리로 변환하는 임무를 맡습니다. \n",
    "        주어진 input을 활용하여 툴을 호출한 후 나오는 DB정보를 활용해 SELECT문을 써서 PostgreSQL로 정의하시오.\n",
    "\n",
    "        쿼리 작성 규칙:\n",
    "        - 주어진 정보를 깊게 생각하여 쿼리를 생성하여라.\n",
    "        - tool을 있는 그대로(축약금지, 꾸며내기 금지) 활용해 참조한 DB정보를 바탕으로 불러온 DB정보안에 들어있는 컬럼명을 반드시 참조해서 SQL문 작성.\n",
    "        - 모든 컬럼명에는 \"\"로 감싸주며, as를 통해서 alias 하더라도 \"\"를 사용할 것.\n",
    "        - Select외 나머지 DDL 사용 금지.\n",
    "        - 최종 출력은 SQL 쿼리만 출력.\n",
    "        - 어떤 경우에도 \"SQLQuery:\", \"Answer:\", \"Output:\" 등의 접두어를 포함하지 않는다.\n",
    "        - 반드시 SQL문만 순수하게 출력한다. (SELECT로 시작해야 함)\n",
    "        - 지표별 리그 내 순위 생성이 명시된 콘텐츠에서만 순위 생성 시 반드시 아래와 같은 규칙을 따라줘:\n",
    "            * 논리적 순서: 먼저 해당 시즌 데이터만 필터링하고, 그 안에서 모든 팀의 각 지표에 대한 순위를 계산해줘. 마지막으로 내가 원하는 특정 팀의 데이터만 필터링해서 보여줘.\n",
    "            * 포함할 컬럼: \"팀 명\", \"시즌\"을 제외한 지표들의 값.\n",
    "        - tool을 호출하지 않고는 절대 판단하지 말 것.\n",
    "        - Schema정보를 반드시 참조하여 테이블명을 완성시킬 것.\n",
    "        - 소수점이 긴 경우, numeric 타입으로 변환 후 둘째 자리까지 반올림한다.\n",
    "        - 어떤 경우에도 쿼리는 ```을 사용하지 않고 작성한다.\n",
    "        - LIMIT에 대한 요청이 없는 경우 전체 데이터 조회\n",
    "\n",
    "        사용자 요청:\n",
    "        {question}\n",
    "        \"\"\"\n",
    "        \n",
    "        return {'question':prompt}\n",
    "\n",
    "    def _execute_query(self, query):\n",
    "        rdb = DB('pg', 'postgres')\n",
    "        data = rdb.read_table(query)\n",
    "        return data\n",
    "\n",
    "    def invoke(self, query:dict):\n",
    "        return self.chain.invoke({'question':query})\n",
    "\n",
    "    def ainoke(self, query:dict):\n",
    "        return self.chain.ainvoke({'question':query})\n",
    "    \n",
    "    def __clean_answer(self, query):\n",
    "        clean_query = re.sub('SQLQuery: {0,1}', '', query)\n",
    "        clean_query = re.sub('^sql|sql', '', clean_query)\n",
    "        clean_query = re.sub('```', \"'''\", clean_query)\n",
    "        return clean_query.strip()\n",
    "        \n",
    "\n",
    "    def __str__(self):\n",
    "        return f'{self.__class__.__name__}'\n",
    "\n",
    "    def __repr__(self):\n",
    "        return f'{self.__class__.__name__}'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c48ec3e1",
   "metadata": {},
   "source": [
    "## DataAnalyst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d5e051f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataAnalyst(object):\n",
    "    def __init__(self, db:SQLDatabase = db):\n",
    "        self.llm = ChatGoogleGenerativeAI(model='gemini-2.5-flash')\n",
    "        self.prompt = self.__create_prompt()\n",
    "        self.data_loader_chain = DataLoader(db).chain\n",
    "        self.chain = RunnablePassthrough.assign(data= self.data_loader_chain) | self.prompt | llm | StrOutputParser()\n",
    "\n",
    "    def __create_prompt(self):\n",
    "        template = \"\"\"\n",
    "                    당신은 데이터 분석 전문가입니다. 사용자에게 요청에 따라 데이터를 해석하고 분석하는 임무를 맡습니다. \n",
    "                \n",
    "                    데이터 해석 규칙:\n",
    "                    - 사용자 요청과 주어진 데이터만 활용해서 해석을 합니다.\n",
    "                    - 다만 주어진 데이터로 새로운 변수를 만들어 해석할 여지가 있으면 새로운 변수를 만들어서 해석을 해야합니다.\n",
    "                    - 데이터는 사용자 요청과 관련있는 데이터입니다.\n",
    "                    \n",
    "                    사용자 요청: \n",
    "                    {question}\n",
    "                    \n",
    "                    데이터:\n",
    "                    {data}\n",
    "                \"\"\" \n",
    "        prompt = ChatPromptTemplate.from_template(template)\n",
    "        return prompt\n",
    "\n",
    "    def invoke(self, query:dict):\n",
    "        return self.chain.invoke({'question':query})\n",
    "\n",
    "    def ainoke(self, query:dict):\n",
    "        return self.chain.ainvoke({'question':query})\n",
    "    \n",
    "    def __str__(self):\n",
    "        return f'{self.__class__.__name__}'\n",
    "\n",
    "    def __repr__(self):\n",
    "        return f'{self.__class__.__name__}'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34808a72",
   "metadata": {},
   "source": [
    "## BI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "103c42dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BI(object):\n",
    "    def __init__(self, db:SQLDatabase = db):\n",
    "        self.llm = ChatGoogleGenerativeAI(model='gemini-2.5-flash')\n",
    "        self.prompt = self.__create_prompt()\n",
    "        self.data_loader_chain = DataLoader(db).chain\n",
    "        self.chain = RunnablePassthrough.assign(data= self.data_loader_chain) | self.prompt | llm | StrOutputParser() | RunnableLambda(self.__clean_answer)\n",
    "\n",
    "    def __create_prompt(self):\n",
    "        template = \"\"\"\n",
    "        당신은 Python Matplotlib 및 Seaborn 시각화 전문가입니다.\n",
    "        당신의 임무는 제공된 데이터(DataFrame)와 사용자 요청을 바탕으로 가장 적합한 시각화 유형을 자동으로 선택하고, 실행 가능한 코드를 생성하는 것입니다.\n",
    "        제공된 데이터(DataFrame)를 분석하고, 컬럼의 데이터 타입(num / category / datetime)을 직접 정의해서 가장 적합한 시각화 유형을 자동으로 선택해야 합니다.\n",
    "\n",
    "        1. 데이터 분석 단계\n",
    "        - 컬럼 데이터 타입 판별: num, category, datetime\n",
    "        - 고유값 개수(unique count) 및 결측치 비율 확인\n",
    "        - 단일 핵심 지표 여부 확인\n",
    "        - 누적값 여부 확인 (시계열/누적 구조 판단)\n",
    "        - 데이터를 정의할 경우 반드시 DB에서 조회된 데이터만 사용한다. (임의의 값 생성 금지)\n",
    "        - 모든 컬럼 길이가 동일하도록 반드시 확인\n",
    "\n",
    "        2. 후보 그래프 선택 로직 (조건 기반)\n",
    "        - 분포(Distribution):\n",
    "            * x=num → Histogram\n",
    "            * x=category, y=num → Histogram Four\n",
    "            * x & y=num → Histo Split / Density Split / KDE 2D\n",
    "            * x=category, y=num → Violin\n",
    "            * x=category, y=num, hue=category → Violin Split\n",
    "        - 관계(Relationship):\n",
    "            * x & y=num → Scatter / Jointplot / Connected Scatter\n",
    "            * x & y=num, size=num, category=category → Bubble\n",
    "            * num 컬럼 여러 개 → Splom\n",
    "        - 비교(Comparison):\n",
    "            * x=category, y=num → Bar\n",
    "            * x=category, y=num, 비율 강조 필요 → Pie\n",
    "            * Box(num) + Line(num) → Mixed\n",
    "            * min_ num, max_ num, target category → Min to Max\n",
    "        - 상관 / 행렬:\n",
    "            * x=category, y=category, target=num → Heatmap\n",
    "        - 구조적 / 복합:\n",
    "            * target, value=num, group=category → Circular\n",
    "            * 시계열/누적값 구조 → Area Stack\n",
    "\n",
    "        3. 판단 기준 예시 (우선순위)\n",
    "        - x=category, y 값 편차 큼 → BarChart\n",
    "        - x=category, y 비율 강조 필요 → PieChart\n",
    "        - datetime + 데이터 포인트 많음 → LineChart\n",
    "        - datetime + 누적 값 → AreaChart\n",
    "        - 단일 핵심 지표 → BigNumber\n",
    "        - num 컬럼 2개 이상 → ScatterPlot / BubbleChart\n",
    "        - 변수 분포 비교 → BoxPlot / ViolinPlot\n",
    "        - 변수 상관관계 → Heatmap\n",
    "        - 여러 변수 관계 → PairPlot / Splom\n",
    "        - 여러 항목 균형 비교 → RadarChart\n",
    "        - 카테고리별 누적 구조 → StackedBar / AreaStack\n",
    "\n",
    "        4. 코드 생성 규칙\n",
    "        - 반드시 실행 가능한 Python 코드만 작성\n",
    "        - 한글이 깨지지 않도록 Python 코드 작성\n",
    "        - 코드는 절대 마크다운(`````, ''') 블록 안에 넣지 말고, 실행 가능한 Python 코드만 출력하라.\n",
    "        - 주석(#)은 허용하되, 불필요한 설명, 문자열, 마크다운(`````, `'''`)은 포함하지 않음\n",
    "        - exec() 함수로 바로 실행 가능한 형태여야 함\n",
    "        - 폰트는 라이브러리에 내장된 기본 폰트를 반드시 사용한다. (Windows 환경)\n",
    "        - plt.show()는 생략\n",
    "        - print()로 요청에 대한 부연 설명 생략\n",
    "        - 그래프 제목, X/Y축 라벨, 주요 범례 및 색상 강조 필수\n",
    "        - 모든 컬럼 길이가 동일해야 함 (데이터 정합성 확인 필수)\n",
    "        - 시각화에 사용된 컬럼명을 코드 주석으로 명시\n",
    "        - 버전과 상관없는 오류가 가장 적은 기본적인 코드로만 구성\n",
    "        - 결과를 저장할 필요 없음 (코드만 생성)\n",
    "\n",
    "        입력 데이터:\n",
    "        {data}\n",
    "\n",
    "        사용자 요청:\n",
    "        {question}\n",
    "        \"\"\" \n",
    "        \n",
    "        prompt = ChatPromptTemplate.from_template(template)\n",
    "        return prompt\n",
    "\n",
    "    def __clean_answer(self, answer:str):\n",
    "        answer = answer.replace('```', \"'''\")\n",
    "        answer = answer.replace('python', '')\n",
    "        return answer\n",
    "\n",
    "    def invoke(self, query:dict):\n",
    "        return self.chain.invoke({'question':query})\n",
    "\n",
    "    def ainoke(self, query:dict):\n",
    "        return self.chain.ainvoke({'question':query})\n",
    "\n",
    "    def __str__(self):\n",
    "        return f'{self.__class__.__name__}'\n",
    "\n",
    "    def __repr__(self):\n",
    "        return f'{self.__class__.__name__}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b981f862",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\EXEM\\AppData\\Local\\Temp\\ipykernel_40800\\4150906449.py:20: LangChainDeprecationWarning: The class `TavilySearchResults` was deprecated in LangChain 0.3.25 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-tavily package and should be used instead. To use it run `pip install -U :class:`~langchain-tavily` and import as `from :class:`~langchain_tavily import TavilySearch``.\n",
      "  tools = [TavilySearchResults(max_results=3), load_data, visualize_data]\n"
     ]
    }
   ],
   "source": [
    "# Tools\n",
    "from langchain_core.tools import tool\n",
    "from langchain_community.tools.tavily_search import TavilyAnswer, TavilySearchResults\n",
    "\n",
    "@tool(name_or_callable=\"DataLoaderTool\", description='사용자 요청에 따라 DB에서 적절한 데이터를 불러와서 데이터 프레임으로 반환합니다.' ,return_direct=False)\n",
    "def load_data(query:str) -> str:\n",
    "    loader = DataLoader(db)\n",
    "    return loader.invoke(query)\n",
    "\n",
    "@tool(name_or_callable=\"DataAnalystTool\", description='사용자 요청에 따라 DB에서 적절한 데이터를 불러온 후 분석하고 해석합니다.' ,return_direct=False)\n",
    "def analysis_data(query:str) -> str:\n",
    "    analyst = DataAnalyst(db)\n",
    "    return analyst.invoke(query)\n",
    "\n",
    "@tool(name_or_callable=\"BITool\", description='사용자 요청에 따라 DB에서 적절한 데이터를 불러와서 시각화할 수 있는 코드를 작성합니다.' ,return_direct=False)\n",
    "def visualize_data(question: str) -> str:\n",
    "    bi = BI(db)\n",
    "    return bi.invoke(question)\n",
    "\n",
    "tools = [TavilySearchResults(max_results=3), load_data, visualize_data]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "649e6fe0",
   "metadata": {},
   "source": [
    "# Output Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "fa90d798",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydantic import BaseModel, Field\n",
    "from typing import Literal, Optional\n",
    "\n",
    "\n",
    "\n",
    "class TaskInfo(BaseModel):\n",
    "    contents_id: str = Field(..., description=\"콘텐츠 목차 + 콘텐츠 명\")\n",
    "    type: Literal[\"Chart\", \"Table\"] = Field(..., description=\"콘텐츠 결과 유형\")\n",
    "    contents: str = Field(..., description=\"태스크 설명\")\n",
    "\n",
    "class Output(object):\n",
    "    class GetMode(BaseModel):\n",
    "        mode: Literal['task', 'report', 'ect'] = Field(..., description='사용자 요청을 분석하여 요청 유형을 task, report, ect로 분류')\n",
    "        reason: str = Field(default='', description='사용자 요청을 분류한 근거를 2~3로 작성하세요.')\n",
    "        \n",
    "    class PassiveGoalCreator(BaseModel):\n",
    "        report_title: str = Field(..., description='보고서 제목')\n",
    "        description: str = Field(..., description='목표 설명')\n",
    "        \n",
    "        \n",
    "        @property\n",
    "        def text(self) -> str:\n",
    "            return f'{self.description}'\n",
    "            \n",
    "    class GoalOptimizer(BaseModel):\n",
    "        description:str = Field(..., description='목표 설명')\n",
    "    \n",
    "        @property\n",
    "        def text(self) -> str:\n",
    "            return f'{self.description}'\n",
    "\n",
    "    \n",
    "    class TaskDecomposer(BaseModel):\n",
    "        tasks: list[TaskInfo] = Field(\n",
    "            default_factory=list,\n",
    "            min_item=3,\n",
    "            max_item=8,\n",
    "            description='3~8개로 분해된 테스크')\n",
    "    \n",
    "    class GetReportInfo(BaseModel):\n",
    "        doc_val_response: Literal[\"YES\",\"NO\"] = Field(default='YES', description='문서 검증 결과')\n",
    "        doc_val_reason:str= Field(default='', description='문서 검증 증거')\n",
    "        documents:str = Field(default='', description='검증에 참조한 문서')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad18ad5f-312c-4eea-9784-172b31903938",
   "metadata": {},
   "source": [
    "# LLM&Agent"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e045c7d-81bb-4914-a021-9db4e69ea7db",
   "metadata": {},
   "source": [
    "## GetMode | get_mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5864c7d6-a5c3-4fe4-af04-a0df65860aba",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GetMode(object):\n",
    "    def __init__(self):\n",
    "        self.llm = ChatGoogleGenerativeAI(model='gemini-2.5-flash', temperature=0)\n",
    "        self.prompt = self.__create_prompt()\n",
    "        self.chain = self.prompt | self.llm.with_structured_output(Output.GetMode)\n",
    "\n",
    "    def __create_prompt(self):\n",
    "        template = \"\"\"사용자 입력을 분석하여 mode를 task, report, ect로 구분한 후, mode를 그렇게 판단한 이유는 reason에 2~3줄로 간략하게 작성하세요.\n",
    "        task:\n",
    "        - 야구 관련 데이터를 DB에서 추출하는 요청\n",
    "        - 야구 관련 데이터를 분석하는 요청\n",
    "        - 야구 관련 데이터 시각화하는 요청\n",
    "\n",
    "        report:\n",
    "        - 야구 관련 리포트를 작성하는 요청\n",
    "\n",
    "        ect:\n",
    "        - task와 report에 속하지 않는 요청\n",
    "        - 야구와 관련되지 않은 요청\n",
    "        \n",
    "        사용자 요청:\n",
    "        {query} \n",
    "        \"\"\"\n",
    "        prompt = ChatPromptTemplate.from_template(template)\n",
    "        return prompt\n",
    "        \n",
    "    def invoke(self, query:str):\n",
    "        answer = self.chain.invoke({'query':query})\n",
    "        return answer\n",
    "\n",
    "    def __str__(self):\n",
    "        return f'{self.__class__.__name__}'\n",
    "\n",
    "    def __repr__(self):\n",
    "        return f'{self.__class__.__name__}'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db88a0fb-4ce3-4fa5-ba70-9f503b613b8f",
   "metadata": {},
   "source": [
    "## PassiveGoalCreator | get_goal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "940329e9-d54d-4554-9489-39257b62333f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PassiveGoalCreator(object):\n",
    "    def __init__(self, llm=llm):\n",
    "        self.llm = llm\n",
    "        self.prompt = self.__create_prompt()\n",
    "        self.chain = self.prompt | self.llm.with_structured_output(Output.PassiveGoalCreator)\n",
    "\n",
    "    def __create_prompt(self):\n",
    "        template = \"\"\"너는 야구전문가야. 사용자 입력을 분석하여 명확한 목표와 그에 해당하는 문서 제목을 생성해주세요.\n",
    "            요건\n",
    "            1. 사용자의 입력을 바탕으로 꾸밈없이 명확한 톤으로 다음 LLM이 처리할 수 있도록 문장을 생성하시오.\n",
    "            2. 기간에 대한 범위가 없다면 가장 최신 시즌을 고려하여 작성하십시오. \n",
    "            3. 사용자의 요청과 생성된 목적들을 기반으로 문서 제목을 생성해주십시오. \n",
    "            다만 기간에 대한 사용자의 정확한 요청이 없을 경우 제목을 작성할 때 기간을 명시하는 텍스트는 제외하십시오.\n",
    "            사용자 입력: {query}\n",
    "            \"\"\"\n",
    "            \n",
    "            # 사용자의 부정확한 입력을 다음 LLM이 처리할 수 있도록 명확하게 한문장의로 재작성하는 작업 담당\n",
    "        prompt = ChatPromptTemplate.from_template(template)\n",
    "        return prompt\n",
    "\n",
    "    def invoke(self, query):\n",
    "        answer = self.chain.invoke({'query':query})\n",
    "        return {\n",
    "            \"goal\": answer.description,\n",
    "            \"report_title\": answer.report_title,\n",
    "            }\n",
    "\n",
    "    def __str__(self):\n",
    "        return f'{self.__class__.__name__}'\n",
    "\n",
    "    def __repr__(self):\n",
    "        return f'{self.__class__.__name__}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "28154602",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = PassiveGoalCreator()\n",
    "ab = a.invoke(\"ARI팀의 전력분석보고서써줘\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "975ae09e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'goal': 'ARI 팀의 최신 시즌 전력 분석 보고서를 작성합니다.', 'report_title': 'ARI 팀 전력 분석 보고서'}"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ab"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70d17fe8-b371-4a83-8e63-611d0131145b",
   "metadata": {},
   "source": [
    "## GetReportInfo | get_report_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "c8f45040-8d75-4340-9b60-05f62449e5b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GetReportInfo(object):\n",
    "    def __init__(self, vectorstore: Chroma):\n",
    "        self.llm = ChatGoogleGenerativeAI(model='gemini-2.5-flash')\n",
    "        self.prompt = self.__create_prompt()\n",
    "        self.retriever = vectorstore.as_retriever(search_kwargs={\"k\": 1})\n",
    "        \n",
    "        def format_docs(docs: List[Document]) -> str:\n",
    "            return \"\\n\\n\".join(d.page_content for d in docs) if docs else \"(no context)\"\n",
    "        \n",
    "        self.chain = (\n",
    "        RunnablePassthrough.assign(\n",
    "            # 입력 dict -> \"query\"만 뽑아 retriever에 넣고 -> 문자열로 포맷\n",
    "            context = RunnableLambda(itemgetter(\"query\")) | self.retriever | RunnableLambda(format_docs)\n",
    "        )\n",
    "        | self.prompt\n",
    "        | self.llm.with_structured_output(Output.GetReportInfo)\n",
    "        )\n",
    "    def __create_prompt(self):\n",
    "        template = \"\"\"\n",
    "                당신은 엄격하고 객관적인 문서 유효성 검사관입니다. 아래에 제시된 **[사용자 목표/질문]**과 **[검색된 문서]**를 철저하게 비교하여, 문서가 목표를 설명하는 데 충분한 정보를 제공하는지 여부를 판단하세요.\n",
    "\n",
    "                [판단 기준]\n",
    "                YES:\n",
    "                문서의 내용이 **[사용자 목표/질문]**의 핵심 키워드나 주제에 대해 직접적이고 구체적인 정보를 포함하고 있는 경우.\n",
    "                제시된 문서만으로도 목표에 대한 초안 설명이나 답변을 구성하는 데 충분하다고 판단되는 경우.\n",
    "\n",
    "                NO:\n",
    "                문서의 내용이 **[사용자 목표/질문]**과 완전히 다른 주제를 다루고 있거나, 매우 일반적인 정보만 제공하여 목표에 대한 실질적인 설명을 할 수 없는 경우.\n",
    "                문서가 목표와 관련된 키워드를 포함하고 있더라도, 그 내용이 목표에 대한 의도를 충족시키지 못하는 경우.\n",
    "                \n",
    "                마지막으로 증거를 남기기위해 들고온 문서에 대해서 그대로 들고와주십시오.\n",
    "                 \n",
    "                목표:\n",
    "                {query}\n",
    "                \n",
    "                들고온 문서:\n",
    "                {context} \n",
    "                \"\"\" \n",
    "                # 키워드 위주로 비교하며 정해진 목표가 문서로서 완성될 수 있는지 판단\n",
    "        prompt = ChatPromptTemplate.from_template(template)\n",
    "        return prompt\n",
    "\n",
    "    def invoke(self, query:dict):\n",
    "        answer = self.chain.invoke({'query':query})\n",
    "        return {\n",
    "            \"doc_val_response\": answer.doc_val_response,\n",
    "            \"doc_val_reason\": answer.doc_val_reason,\n",
    "            \"documents\": answer.documents\n",
    "            }\n",
    "        \n",
    "    def ainvoke(self, query:dict):\n",
    "        answer = self.chain.ainvoke({'query':query})\n",
    "        return {\n",
    "            \"doc_val_response\": answer.doc_val_response,\n",
    "            \"doc_val_reason\": answer.doc_val_reason,\n",
    "            \"documents\": answer.documents\n",
    "            }\n",
    "    \n",
    "   \n",
    "    \n",
    "    def __str__(self):\n",
    "        return f'{self.__class__.__name__}'\n",
    "\n",
    "    def __repr__(self):\n",
    "        return f'{self.__class__.__name__}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "ef07f66f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'doc_val_response': 'YES',\n",
       " 'doc_val_reason': \"문서의 제목, 범위, 목적 및 목차 내용이 'ARI 팀의 최신 시즌 전력 분석 보고서를 작성합니다.'라는 사용자 목표에 직접적으로 부합합니다. 특히, '시즌 팀 종합 성적', '직전년도 성적과 비교', '투수/타자/수비 능력' 등 구체적인 분석 항목들이 보고서 작성에 필요한 정보를 충분히 제공합니다.\",\n",
       " 'documents': '문서 제목: [시즌](팀 명) 전력 분석 보고서 -문서 타입: 보고서 -문서 범위: 특정 팀, 특정 시즌 -문서 목적: 팀의 전력을 분석하기 위해 해당 팀의 시즌 종합 성적을 강함을 평가하고 투수, 타자, 수비진의 시즌 지표를 활용해 구체적인 전력을 분석하기 위함 - -주요 목차: 1. 시즌 팀 종합 성적 2. 시즌 팀 직전년도 성적과 비교 3. 시즌 팀 경 기력 분석 -목차 콘텐츠: 1. 시즌 팀 종합 성적 - 목적: 해당 팀의 특정 시즌의 종합 성적을 분석하는 콘텐츠 - 콘텐츠 타입: Table - 쿼리 플랜: 특정 팀의 특정 시즌의 순위, 경기 수, 승리 수, 패배 수, 승률, 득점, 실점, 평균 경기당 득/실을 불러오기 2. 시즌 팀 직전년도 성적과 비교 - 목적: 차트를 활용해 직전년도의 성적과 비교해 무엇이 개선됐고 후퇴했는지 확인하는 콘텐츠 - 콘텐츠 타입: Chart - 쿼리 플랜: 특정 팀의 특정 시즌의 순위, 승률, 평균 경기당 득/실과 직전년도의 순위, 승률, 평균 경기당 득/실을 불러오기 3. 시즌 팀 경기력 분석 - 목적: 해당 팀의 각 포지션별 경기력을 분석하는 콘텐츠 - 콘텐츠 타입: Multi-Table - 하위 콘텐츠: 3.1. 투수 능력: - 쿼리 플랜: 특정 팀의 특정 시즌의 투수 대체선수 대비 승리 기여도를 가져온다. - 상세 분석 쿼리 플랜: 상세 분석의 요청이 있는 경우 기존 쿼리 플랜에서 평균 자책점, 이닝당 출루 허용률, 수비 무관 투구 지표도 불러온다. 3.2. 타자 능력: - 쿼리 플랜: 특정 팀의 특정 시즌의 타자 대체선수 대비 승리 기여도를 가져온다. - 상세 분석 쿼리 플랜: 상세 분석의 요청이 있는 경우 기존 쿼리 플랜에서 타율, 출루율, 장타율 지표도 불러온다. 3.3. 수비 능력: - 쿼리 플랜: 특정 팀의 특정 시즌의 수비로 막아낸 득점을 가져온다. - 상세 분석 쿼리 플랜: 상세 분석의 요청이 있는 경우 기존 쿼리 플랜에서 평균 수비로 막아낸 득점, 궁극적인 수비 범위 점수 지표도 불러온다. '}"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cc  =GetReportInfo(vectorstore=vectorstore)\n",
    "ccc = cc.invoke(ab['goal'])\n",
    "ccc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "456e7f70",
   "metadata": {},
   "source": [
    "## SingleGetInfo | single_get_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "eab29e02",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SingleGettInfo(object):\n",
    "    def __init__(self, vectorstore: Chroma):\n",
    "        self.llm = ChatGoogleGenerativeAI(model='gemini-2.5-flash')\n",
    "        self.prompt = self.__create_prompt()\n",
    "        \n",
    "        self.chain = (\n",
    "        RunnablePassthrough.assign(query=itemgetter(\"query\"))\n",
    "        | self.prompt\n",
    "        | self.llm.with_structured_output(Output.GetReportInfo)\n",
    "        )\n",
    "    def __create_prompt(self):\n",
    "        template = \"\"\"\n",
    "        너는 \"요구사항 명확성 심사관\"이다.\n",
    "        사용자의 질문이 다음 단계를 실행하기에 충분히 구체적이고 실행 가능한지 판단해야 한다.\n",
    "        다음 기준을 따른다:\n",
    "        1. 질문이 **명확한 목표**(무엇을, 왜, 어떻게)를 포함하면 YES\n",
    "        2. 질문이 **모호하거나**, **추상적이거나**, **행동이 정의되지 않으면** NO\n",
    "        3. YES/NO 판단 외에는 불필요한 설명 없이 결과만 JSON 형식으로 출력한다.\n",
    "\n",
    "        예시:\n",
    "        - \"ARI팀의 2024년 득점과 실점을 DB에서 조회해줘\" → YES\n",
    "        - \"ARI팀에 대해 알려줘\" → NO\n",
    "        - \"시즌 데이터를 분석해줘\" → NO\n",
    "        - \"ARI팀의 2024년 투수 WHIP과 OBP 상관관계 분석해줘\" → YES\n",
    "\n",
    "        사용자 질문:\n",
    "        {query}\n",
    "\n",
    "        JSON 출력 형식:\n",
    "        {{\n",
    "          \"doc_val_response\": \"YES\" | \"NO\"\n",
    "        }}\n",
    "        \"\"\"\n",
    "                \n",
    "        prompt = ChatPromptTemplate.from_template(template)\n",
    "        return prompt\n",
    "\n",
    "    def invoke(self, query:dict):\n",
    "        answer = self.chain.invoke({'query':query})\n",
    "        return {\n",
    "            \"doc_val_response\": answer.doc_val_response,\n",
    "            }\n",
    "        \n",
    "    def ainvoke(self, query:dict):\n",
    "        answer = self.chain.ainvoke({'query':query})\n",
    "        return {\n",
    "            \"doc_val_response\": answer.doc_val_response,\n",
    "            }\n",
    "    \n",
    "    def __str__(self):\n",
    "        return f'{self.__class__.__name__}'\n",
    "\n",
    "    def __repr__(self):\n",
    "        return f'{self.__class__.__name__}'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ac76ee5-6fe3-4a48-986f-7d9ca10349d8",
   "metadata": {},
   "source": [
    "## GoalOptimizer | optimize_goal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "3f9ef9f6-eb22-4dc6-b7c6-cc808843847c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GoalOptimizer(object):\n",
    "    def __init__(self, llm=llm):\n",
    "        self.llm = llm\n",
    "        self.prompt = self.__create_prompt()\n",
    "        self.chain = self.prompt | self.llm.with_structured_output(Output.GoalOptimizer)\n",
    "\n",
    "    def __create_prompt(self):\n",
    "        template = \"\"\"당신은 목표 설정 전문가입니다.주어진 원래목표와 주어진 문서(계획서)를 기반으로 콘텐츠별로 달성 가능한 세부적인 목표를 생성하십시오.\n",
    "        [원래목표]\n",
    "        {query}\n",
    "\n",
    "        [지시사항]\n",
    "        1. 주어진 문서에서의 목차번호와 해당 콘텐츠의 제목을 반드시 세부적인 목표와 같이 명시해주십시오.\n",
    "        2. 주어진 문서의 콘텐츠별로 최종적으로 달성해야할 목표를 아래와 같이 매핑하여 명시해주십시오.\n",
    "            - 표, Table : 데이터 반환\n",
    "            - Chart : 파이썬 코드 반환\n",
    "            \n",
    "        3. 원래 목표의 범위를 기준으로 주어진 문서를 기반으로 콘텐츠별로 달성해야될 목표를 상세하게 작성하십시오.\n",
    "        4. 상세한 분석 요청이 있을 경우만 상세분석쿼리를 참조하여 목표를 작성해주십시오.\n",
    "        \n",
    "        [주어진 문서]\n",
    "        {docs}\n",
    "        \"\"\"\n",
    "        prompt = ChatPromptTemplate.from_template(template)\n",
    "        return prompt\n",
    "\n",
    "    def invoke(self, query, docs):\n",
    "        answer = self.chain.invoke({'query':query, 'docs':docs})\n",
    "        return answer.text\n",
    "\n",
    "    def __str__(self):\n",
    "        return f'{self.__class__.__name__}'\n",
    "\n",
    "    def __repr__(self):\n",
    "        return f'{self.__class__.__name__}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "2fc3f26f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1. 시즌 팀 종합 성적: ARI 팀의 최신 시즌 순위, 경기 수, 승리 수, 패배 수, 승률, 득점, 실점, 평균 경기당 득/실 데이터를 반환합니다.\\n2. 시즌 팀 직전년도 성적과 비교: ARI 팀의 최신 시즌과 직전년도의 순위, 승률, 평균 경기당 득/실을 비교하는 파이썬 코드를 반환합니다.\\n3.1. 투수 능력: ARI 팀의 최신 시즌 투수 대체선수 대비 승리 기여도 데이터를 반환합니다.\\n3.2. 타자 능력: ARI 팀의 최신 시즌 타자 대체선수 대비 승리 기여도 데이터를 반환합니다.\\n3.3. 수비 능력: ARI 팀의 최신 시즌 수비로 막아낸 득점 데이터를 반환합니다.'"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "go = GoalOptimizer()\n",
    "gogo = go.invoke(ab['goal'],ccc['documents'])\n",
    "gogo"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46d2132f",
   "metadata": {},
   "source": [
    "## SingleGoalOptimizer | single_optimize_goal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "593a8f8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SingleGoalOptimizer(object):\n",
    "    def __init__(self, llm=llm):\n",
    "        self.llm = llm\n",
    "        self.prompt = self.__create_prompt()\n",
    "        self.chain = self.prompt | self.llm.with_structured_output(Output.GoalOptimizer)\n",
    "\n",
    "    def __create_prompt(self):\n",
    "        template = \"\"\"\n",
    "        당신은 목표 설정 전문가입니다. \n",
    "        원래목표\n",
    "        {query}\n",
    "        지시사항\n",
    "        1. 원래 목표를 해석하지 말고, 그대로 정확히 수행하세요.\n",
    "        2. 수행 가능한 행동은 아래 중 하나입니다.\n",
    "        - 사용자의 요청에 따라 DB에서 적절한 데이터를 조회하고 마크다운 형식의 데이터를 제공합니다\n",
    "        - 사용자의 요청에 따라 DB에서 조회한 데이터를 분석하고 해석합니다.\n",
    "        - 사용자의 요청에 따라 DB에서 조회한 데이터를 기반으로 Python 시각화 코드를 작성합니다. (plt.show()는 주석처리)\n",
    "        3. 모든 데이터는 'DB에서 조회된 실제 데이터'만 사용합니다. 임의의 랜덤/가상/추정 데이터 생성을 엄격 금지합니다.\n",
    "        4. 주의: 2번 행동 중 하나를 수행할 수 있으며, 절대 2번 행동 이외에는 수행하지 마세요.\n",
    "        \"\"\"\n",
    "        prompt = ChatPromptTemplate.from_template(template)\n",
    "        return prompt\n",
    "\n",
    "    def invoke(self, query):\n",
    "        answer = self.chain.invoke({'query':query})\n",
    "        return answer.text\n",
    "\n",
    "    def __str__(self):\n",
    "        return f'{self.__class__.__name__}'\n",
    "\n",
    "    def __repr__(self):\n",
    "        return f'{self.__class__.__name__}'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b637f0d5-a34a-49d3-9306-1855cc6e6607",
   "metadata": {},
   "source": [
    "## ResponseOptimizer | optimize_response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "6f93e0d7-c9df-4228-8fb1-91d2d5f35456",
   "metadata": {},
   "outputs": [],
   "source": [
    "# class ResponseOptimizer(object):\n",
    "#     def __init__(self, llm=llm):\n",
    "#         self.llm = llm\n",
    "#         self.prompt = self.__create_prompt()\n",
    "#         self.chain = self.prompt | self.llm | StrOutputParser()\n",
    "\n",
    "#     def __create_prompt(self):\n",
    "#         human_message = \"\"\"다음 절차에 따라 응답 최적화 프롬프트를 작성해 주세요.\n",
    "#         1. 목표분석\n",
    "#         제시된 목표를 분석하고 주요 요소와 의도를 파악해 주세요.\n",
    "#         2. 응답 사양 수립\n",
    "#         목표 달성을 위한 최적의 응답 사양을 고안해 주세요. 톤, 구조, 내용의 초점 등을 고려해 주세요.\n",
    "#         3. 구체적인 지침 작성\n",
    "#         사전에 수집된 정보에서 사용자의 기대에 부합하는 응답을 위해 필요한, AI 에이전트에 대한 명확하고 실행 가능한 지침을 작성해 주세요. 귀하의 지침으로 AI 에이전트가 수행할 수 있는 있는 것은 이미 조사된 결과를 정리하는 것뿐입니다. 인터넷에 접근할 수 없습니다.\n",
    "#         4. 예시 제공\n",
    "#         가능하다면 목표에 맞는 응답의 예시를 하나 이상 포함해주세요.\n",
    "#         5. 평가 기준 설정\n",
    "#         응답의 효과를 측정하기 위한 기준을 정의해 주세요.\n",
    "#         다음 구조로 응답 최적화 프롬프트를 출력해 주세요.\n",
    "#         목표 분석:\n",
    "#         [여기에 목표 분석 결과를 기입]\n",
    "#         응답 사양:\n",
    "#         [여기에 수립된 응답 사영을 기입]\n",
    "#         AI 에이전트에 대한 지침\n",
    "#         [여기에 AI 에이전트에 대한 구체적인 지침을 기입]\n",
    "#         응답 예시\n",
    "#         [여기에 응답 예시를 기입]\n",
    "#         평가 기준\n",
    "#         [여기에 평가 기준을 기입]\n",
    "#         그럼, 다음 목표에 대한 응답 최적화 프롬프트를 작성해 주세요.\n",
    "#         {query}\n",
    "#         \"\"\"\n",
    "#         prompt = ChatPromptTemplate.from_messages(\n",
    "#             [\n",
    "#                 ('system', '당신은 AI 에이전트 시스템의 응답 최적화 전문가입니다. 주어진 목표에 대해 에이전트가 목표에 맞는 응답을 반환하기 위한 응답 사양을 수립해 주세요.'),\n",
    "#                 ('human', human_message),\n",
    "#             ]\n",
    "#         )\n",
    "#         return prompt\n",
    "\n",
    "#     def invoke(self, query):\n",
    "#         answer = self.chain.invoke({'query':query})\n",
    "#         return answer\n",
    "\n",
    "#     def __str__(self):\n",
    "#         return f'{self.__class__.__name__}'\n",
    "\n",
    "#     def __repr__(self):\n",
    "#         return f'{self.__class__.__name__}'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "285ed8ce-995d-47a1-801b-5cd635a762e6",
   "metadata": {},
   "source": [
    "## TaskDecomposer | decompose_tasks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "19944aeb-e9ef-4d08-8c6a-1a2b1d1fa60f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TaskDecomposer(object):\n",
    "    def __init__(self, llm=llm):\n",
    "        self.llm = llm\n",
    "        self.prompt = self.__create_prompt()\n",
    "        self.chain = self.prompt | self.llm.with_structured_output(Output.TaskDecomposer)\n",
    "\n",
    "    def __create_prompt(self):\n",
    "        template = \"\"\"태스크: 주어진 목표를 콘텐츠만을 기준으로 실행 가능한 태스크로 분해해 주세요.\n",
    "        요건\n",
    "        1. 다음 행동만으로 목표를 달성할 것. 절대 지정된 이외의 행동을 취하지 말 것.\n",
    "        - 사용자의 요청에 따라 적절한 데이터를 불러와 데이터프레임으로 변환합니다.\n",
    "        - 사용자 요청에 따라 DB에서 적절한 데이터를 불러와서 시각화할 수 있는 코드를 작성합니다.\n",
    "        - DB외에 추가로 필요한 정보가 필요할 경우만 판단해서 인터넷 검색을 통해서 정보를 추가합니다.\n",
    "        2. 각 태스크는 구체적으로 상세하게 기재하며, 단독으로 실행 및 검증 가능한 정보를 포함할 것. 추상적인 표현을 일절 포함하지 말것\n",
    "        3. 목표에 작성된 콘텐츠 수를 기준으로 태스크를 최소한으로 생성할 것.\n",
    "        4. 아래와 같이 구성할 것\n",
    "        - contents_id: 콘텐츠 번호. 기존 콘텐츠 명 , type: 결과유형 [Chart, Table], contents: 태스크 내용\n",
    "        5. 태스크는 실행 가능한 순서로 리스트화 할 것\n",
    "        목표: {query}\n",
    "        \"\"\"\n",
    "        prompt = ChatPromptTemplate.from_template(template)\n",
    "        return prompt\n",
    "\n",
    "    def invoke(self, query):\n",
    "        answer = self.chain.invoke({'query':query})\n",
    "        return answer.tasks\n",
    "\n",
    "    def __str__(self):\n",
    "        return f'{self.__class__.__name__}'\n",
    "\n",
    "    def __repr__(self):\n",
    "        return f'{self.__class__.__name__}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "d0ea79d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "td=TaskDecomposer()\n",
    "\n",
    "ttd = td.invoke(gogo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "4a2367dd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[TaskInfo(contents_id='1. 시즌 팀 종합 성적', type='Table', contents='DB에서 ARI 팀의 최신 시즌 순위, 경기 수, 승리 수, 패배 수, 승률, 득점, 실점, 평균 경기당 득/실 데이터를 불러와 데이터프레임으로 변환합니다.'),\n",
       " TaskInfo(contents_id='2. 시즌 팀 직전년도 성적과 비교', type='Chart', contents='DB에서 ARI 팀의 최신 시즌과 직전년도의 순위, 승률, 평균 경기당 득/실 데이터를 불러와, 두 시즌의 순위, 승률, 평균 경기당 득/실을 비교하는 시각화 파이썬 코드를 작성합니다.'),\n",
       " TaskInfo(contents_id='3.1. 투수 능력', type='Table', contents='DB에서 ARI 팀의 최신 시즌 투수 대체선수 대비 승리 기여도 데이터를 불러와 데이터프레임으로 변환합니다.'),\n",
       " TaskInfo(contents_id='3.2. 타자 능력', type='Table', contents='DB에서 ARI 팀의 최신 시즌 타자 대체선수 대비 승리 기여도 데이터를 불러와 데이터프레임으로 변환합니다.'),\n",
       " TaskInfo(contents_id='3.3. 수비 능력', type='Table', contents='DB에서 ARI 팀의 최신 시즌 수비로 막아낸 득점 데이터를 불러와 데이터프레임으로 변환합니다.')]"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ttd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4948114-e1a9-4c76-9d3a-3429bdf94c98",
   "metadata": {},
   "source": [
    "## ExecuteTask | report_execute_task, task_execute_task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "e6e5d937-9343-4b38-a1ad-cd9073a3433c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'다음 태스크를 실행하고 상세한 답변을 제공해주세요. 당신은 다음 도구에 접근할 수 있습니다:\\n\\n        {tools}\\n\\n        다음 형식을 사용하세요:\\n\\n        Question: 답변해야 하는 입력 질문\\n        Thought: 무엇을 할지 항상 생각하세요.\\n        Action: 취해야 할 행동, [{tool_names}] 중 하나여야 합니다. 리스트에 있는 도구 중 1개를 택하십시오.\\n        Action Input: 행동에 대한 입력값\\n        Observation: 행동의 결과\\n        ... (이 Thought/Action/Action Input/Observation의 과정이 N번 반복될 수 있습니다.)\\n        Thought: 이제 최종 답변을 알겠습니다.\\n        Final Answer: 원래 입력된 질문에 대한 최종 답변\\n\\n        ## 추가적인 주의사항\\n        - 반드시 [Thought/Action/Action Input format] 이 사이클의 순서를 준수하십시오. 항상 Action 전에는 Thought가 먼저 나와야 합니다.\\n        - 최종 답변은 Question의 지시사항을 준수한 답변만 제공하십시오\\n        - 각각 표(테이블) 형태를 Question에서 요구하면 DataLoader, 차트(시각화) 형태를 Question에서 요구하면 BITool, 요약 또는 분석 DataAnalyst 활용\\n        - Question의 지시사항의 최종적인 요구의 산출문만 제공해주세요\\n        - DataLoader툴을 사용했다면 Json형식의 데이터를 제공하고, BITool을 사용했다면 순수한 Python 코드만을 제공하고 마지막으로 DataAnalyst를 활용했다면 700이내의 요약을 부가적인 타이틀 없이 줄글로만 제공해주세요\\n        - 정보가 취합되었다면 불필요하게 사이클을 반복하지 마십시오.\\n        - 묻지 않은 정보를 찾으려고 도구를 사용하지 마십시오.\\n        - 실행은 철저하고 포괄적으로 수행하세요.\\n\\n        시작하세요!\\n\\n        Question: {task}\\n        Thought: {agent_scratchpad}\\n        '"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"다음 태스크를 실행하고 상세한 답변을 제공해주세요. 당신은 다음 도구에 접근할 수 있습니다:\n",
    "    \n",
    "        {tools}\n",
    "        \n",
    "        다음 형식을 사용하세요:\n",
    "        \n",
    "        Question: 답변해야 하는 입력 질문\n",
    "        Thought: 무엇을 할지 항상 생각하세요.\n",
    "        Action: 취해야 할 행동, [{tool_names}] 중 하나여야 합니다. 리스트에 있는 도구 중 1개를 택하십시오.\n",
    "        Action Input: 행동에 대한 입력값\n",
    "        Observation: 행동의 결과\n",
    "        ... (이 Thought/Action/Action Input/Observation의 과정이 N번 반복될 수 있습니다.)\n",
    "        Thought: 이제 최종 답변을 알겠습니다.\n",
    "        Final Answer: 원래 입력된 질문에 대한 최종 답변\n",
    "        \n",
    "        ## 추가적인 주의사항\n",
    "        - 반드시 [Thought/Action/Action Input format] 이 사이클의 순서를 준수하십시오. 항상 Action 전에는 Thought가 먼저 나와야 합니다.\n",
    "        - 최종 답변은 Question의 지시사항을 준수한 답변만 제공하십시오\n",
    "        - 각각 표(테이블) 형태를 Question에서 요구하면 DataLoader, 차트(시각화) 형태를 Question에서 요구하면 BITool, 요약 또는 분석 DataAnalyst 활용\n",
    "        - Question의 지시사항의 최종적인 요구의 산출문만 제공해주세요\n",
    "        - DataLoader툴을 사용했다면 Json형식의 데이터를 제공하고, BITool을 사용했다면 순수한 Python 코드만을 제공하고 마지막으로 DataAnalyst를 활용했다면 700이내의 요약을 부가적인 타이틀 없이 줄글로만 제공해주세요\n",
    "        - 정보가 취합되었다면 불필요하게 사이클을 반복하지 마십시오.\n",
    "        - 묻지 않은 정보를 찾으려고 도구를 사용하지 마십시오.\n",
    "        - 실행은 철저하고 포괄적으로 수행하세요.\n",
    "        \n",
    "        시작하세요!\n",
    "        \n",
    "        Question: {task}\n",
    "        Thought: {agent_scratchpad}\n",
    "        \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "d9ae0c21-be80-49b6-a2e1-c397574d5053",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ExecuteTask(object):\n",
    "    def __init__(self, tools:list=tools, llm=llm):\n",
    "        self.llm = llm\n",
    "        self.tools = tools\n",
    "        self.prompt = self.__create_prompt()\n",
    "        self.agent = self.__create_agent()\n",
    "\n",
    "    def __create_prompt(self):\n",
    "    \n",
    "        template = \"\"\"다음 태스크를 실행하고 상세한 답변을 제공해주세요. 당신은 다음 도구에 접근할 수 있습니다:\n",
    "    \n",
    "        {tools}\n",
    "        \n",
    "        다음 형식을 사용하세요:\n",
    "        \n",
    "        Question: 답변해야 하는 입력 질문\n",
    "        Thought: 무엇을 할지 항상 생각하세요.\n",
    "        Action: 취해야 할 행동, [{tool_names}] 중 하나여야 합니다.\n",
    "        Action Input: 행동에 대한 입력값\n",
    "        Observation: 행동의 결과\n",
    "        ... (이 Thought/Action/Action Input/Observation의 과정이 N번 반복될 수 있습니다.)\n",
    "        Thought: 이제 최종 답변을 알겠습니다.\n",
    "        Final Answer: 원래 입력된 질문에 대한 최종 답변\n",
    "        \n",
    "        ## 추가적인 주의사항\n",
    "        - 반드시 [Thought/Action/Action Input format] 이 사이클의 순서를 준수하십시오. 항상 Action 전에는 Thought가 먼저 나와야 합니다.\n",
    "        - 한 번의 검색으로 해결되지 않을 것 같다면 문제를 분할하여 푸는 것이 중요합니다.\n",
    "        - 정보가 취합되었다면 불필요하게 사이클을 반복하지 마십시오.\n",
    "        - 묻지 않은 정보를 찾으려고 도구를 사용하지 마십시오.\n",
    "        - 실행은 철저하고 포괄적으로 수행하세요.\n",
    "        - 가능한 구체적인 사실이나 데이터를 제공하세요.\n",
    "        - 차트를 생성하는 코드를 작성하는 요청이 들어오면, 차트를 생성하는 순수한 파이썬 코드만 답변하세요.\n",
    "        \n",
    "        시작하세요!\n",
    "        \n",
    "        Question: {task}\n",
    "        Thought: {agent_scratchpad}\n",
    "        \"\"\"\n",
    "        prompt = ChatPromptTemplate.from_template(template)\n",
    "        return prompt\n",
    "\n",
    "    def __create_agent(self):\n",
    "        agent = create_react_agent(llm=self.llm, tools=self.tools, prompt=self.prompt)\n",
    "        executor = AgentExecutor(agent=agent, tools=self.tools, verbose=True, handle_parsing_errors=True)\n",
    "        return executor\n",
    "        \n",
    "    def invoke(self, task):\n",
    "        answer = self.agent.invoke({'task':task})\n",
    "        return answer['output']\n",
    "\n",
    "    def ainvoke(self, task):\n",
    "        answer = self.agent.ainvoke({'task':task})\n",
    "        return answer['output']\n",
    "\n",
    "    def __str__(self):\n",
    "        return f'{self.__class__.__name__}'\n",
    "\n",
    "    def __repr__(self):\n",
    "        return f'{self.__class__.__name__}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "8de6a57b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3mAction: DataLoaderTool\n",
      "Action Input: query=\"contents_id='1. 시즌 팀 종합 성적' type='Table' contents='DB에서 ARI 팀의 최신 시즌 순위, 경기 수, 승리 수, 패배 수, 승률, 득점, 실점, 평균 경기당 득/실 데이터를 불러와 데이터프레임으로 변환합니다.'\"\u001b[0m\u001b[33;1m\u001b[1;3m   Rank    G   W   L       W-L    R   RA  평균 경기당 득점  평균 경기당 실점\n",
      "0     8  162  89  73  0.549383  886  788       5.47       4.86\u001b[0m\u001b[32;1m\u001b[1;3mFinal Answer: DB에서 ARI 팀의 최신 시즌 순위, 경기 수, 승리 수, 패배 수, 승률, 득점, 실점, 평균 경기당 득/실 데이터를 불러와 데이터프레임으로 변환한 결과입니다:\n",
      "\n",
      "```\n",
      "   Rank    G   W   L       W-L    R   RA  평균 경기당 득점  평균 경기당 실점\n",
      "0     8  162  89  73  0.549383  886  788       5.47       4.86\n",
      "```\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3mAction: BITool\n",
      "Action Input: DB에서 ARI 팀의 최신 시즌과 직전년도의 순위, 승률, 평균 경기당 득/실 데이터를 불러와, 두 시즌의 순위, 승률, 평균 경기당 득/실을 비교하는 시각화 파이썬 코드를 작성합니다.\u001b[0m\u001b[38;5;200m\u001b[1;3mimport pandas as pd\n",
      "import matplotlib.pyplot as plt\n",
      "import seaborn as sns\n",
      "\n",
      "# 데이터 정의 (DB에서 조회된 데이터만 사용)\n",
      "data = {\n",
      "    'Season': [2024, 2023],\n",
      "    'Rank': [8, 12],\n",
      "    'Win-Loss Percentage': [0.55, 0.52],\n",
      "    'Runs per Game': [5.47, 4.60],\n",
      "    'Runs Allowed per Game': [4.86, 4.70]\n",
      "}\n",
      "df = pd.DataFrame(data)\n",
      "\n",
      "# 1. 데이터 분석 단계\n",
      "# 컬럼 데이터 타입 판별:\n",
      "# Season: category (비교 대상 시즌을 구분하는 범주형)\n",
      "# Rank: num (순위, 수치형)\n",
      "# Win-Loss Percentage: num (승률, 수치형)\n",
      "# Runs per Game: num (경기당 득점, 수치형)\n",
      "# Runs Allowed per Game: num (경기당 실점, 수치형)\n",
      "# 고유값 개수 및 결측치 비율: 데이터가 작고 결측치가 없어 추가 분석 생략\n",
      "# 단일 핵심 지표 여부: No (여러 지표 비교)\n",
      "# 누적값 여부: No (시즌별 단일 값)\n",
      "# 모든 컬럼 길이가 동일함 (DataFrame 생성 시 확인 완료)\n",
      "\n",
      "# 2. 후보 그래프 선택 로직 및 3. 판단 기준 예시\n",
      "# - x=category, y=num → Bar: 'Season' (category)과 각 지표 (num)를 비교하는 데 적합.\n",
      "# - 여러 수치형 컬럼을 두 개의 범주(시즌)에 대해 비교하므로, 각 지표별로 바 차트를 생성하는 것이 가장 명확합니다.\n",
      "#   서로 다른 스케일을 가진 지표들을 한 그래프에 표시하기보다는, 서브플롯을 사용하여 각 지표를 독립적으로 비교하는 것이 좋습니다.\n",
      "\n",
      "# 데이터 변환: wide format을 long format으로 변경하여 Seaborn facet plot에 적합하게 만듭니다.\n",
      "# 'Season' 컬럼은 id_vars로 유지하고, 나머지 컬럼들을 'Metric'과 'Value'로 변환합니다.\n",
      "df_melted = df.melt(id_vars=['Season'], var_name='Metric', value_name='Value')\n",
      "\n",
      "# 한글 폰트 설정 (Windows 환경 기본 폰트)\n",
      "plt.rcParams['font.family'] = 'Malgun Gothic'\n",
      "plt.rcParams['axes.unicode_minus'] = False # 마이너스 부호 깨짐 방지\n",
      "\n",
      "# 시각화 코드 생성\n",
      "# 각 지표별로 서브플롯을 생성하여 두 시즌을 비교합니다.\n",
      "# 'Metric' 컬럼을 기준으로 서브플롯을 나누고, 각 서브플롯 내에서 'Season'별로 바 차트를 그립니다.\n",
      "g = sns.catplot(\n",
      "    data=df_melted,\n",
      "    x='Season', # x축: 시즌\n",
      "    y='Value',  # y축: 값\n",
      "    col='Metric', # 'Metric' 컬럼을 기준으로 서브플롯 생성\n",
      "    kind='bar', # 바 차트\n",
      "    col_wrap=2, # 한 줄에 2개의 서브플롯 (총 4개 지표이므로 2x2 그리드)\n",
      "    height=4, aspect=1.2, # 서브플롯 크기 조절\n",
      "    palette='viridis', # 색상 팔레트\n",
      "    sharey=False # 각 서브플롯의 y축 스케일을 독립적으로 설정 (지표별 스케일이 다르므로 중요)\n",
      ")\n",
      "\n",
      "# 전체 그래프 제목 설정\n",
      "g.fig.suptitle('ARI 팀 두 시즌 (2024 vs 2023) 주요 지표 비교', y=1.02, fontsize=16)\n",
      "\n",
      "# 각 서브플롯에 제목과 라벨 설정 및 값 표시\n",
      "for ax in g.axes.flat:\n",
      "    metric_name = ax.get_title().replace('Metric = ', '') # 서브플롯 제목에서 지표 이름 추출\n",
      "    ax.set_xlabel(\"시즌\")\n",
      "    ax.set_ylabel(\"값\")\n",
      "    ax.set_title(f'{metric_name} 비교') # 서브플롯 제목을 더 명확하게 설정\n",
      "\n",
      "    # 각 바 위에 값 표시, 'Rank'는 정수, 나머지는 소수점 둘째 자리\n",
      "    for container in ax.containers:\n",
      "        if metric_name == 'Rank':\n",
      "            ax.bar_label(container, fmt='%.0f', label_type='edge')\n",
      "        else:\n",
      "            ax.bar_label(container, fmt='%.2f', label_type='edge')\n",
      "\n",
      "# 레이아웃 조정 (전체 제목이 겹치지 않도록 상단 여백 확보)\n",
      "plt.tight_layout(rect=[0, 0, 1, 0.98])\n",
      "\n",
      "# 시각화에 사용된 컬럼명: Season, Rank, Win-Loss Percentage, Runs per Game, Runs Allowed per Game\u001b[0m\u001b[32;1m\u001b[1;3mFinal Answer: ```python\n",
      "import pandas as pd\n",
      "import matplotlib.pyplot as plt\n",
      "import seaborn as sns\n",
      "\n",
      "# 데이터 정의 (DB에서 조회된 데이터만 사용)\n",
      "data = {\n",
      "    'Season': [2024, 2023],\n",
      "    'Rank': [8, 12],\n",
      "    'Win-Loss Percentage': [0.55, 0.52],\n",
      "    'Runs per Game': [5.47, 4.60],\n",
      "    'Runs Allowed per Game': [4.86, 4.70]\n",
      "}\n",
      "df = pd.DataFrame(data)\n",
      "\n",
      "# 데이터 변환: wide format을 long format으로 변경하여 Seaborn facet plot에 적합하게 만듭니다.\n",
      "# 'Season' 컬럼은 id_vars로 유지하고, 나머지 컬럼들을 'Metric'과 'Value'로 변환합니다.\n",
      "df_melted = df.melt(id_vars=['Season'], var_name='Metric', value_name='Value')\n",
      "\n",
      "# 한글 폰트 설정 (Windows 환경 기본 폰트)\n",
      "plt.rcParams['font.family'] = 'Malgun Gothic'\n",
      "plt.rcParams['axes.unicode_minus'] = False # 마이너스 부호 깨짐 방지\n",
      "\n",
      "# 시각화 코드 생성\n",
      "# 각 지표별로 서브플롯을 생성하여 두 시즌을 비교합니다.\n",
      "# 'Metric' 컬럼을 기준으로 서브플롯을 나누고, 각 서브플롯 내에서 'Season'별로 바 차트를 그립니다.\n",
      "g = sns.catplot(\n",
      "    data=df_melted,\n",
      "    x='Season', # x축: 시즌\n",
      "    y='Value',  # y축: 값\n",
      "    col='Metric', # 'Metric' 컬럼을 기준으로 서브플롯 생성\n",
      "    kind='bar', # 바 차트\n",
      "    col_wrap=2, # 한 줄에 2개의 서브플롯 (총 4개 지표이므로 2x2 그리드)\n",
      "    height=4, aspect=1.2, # 서브플롯 크기 조절\n",
      "    palette='viridis', # 색상 팔레트\n",
      "    sharey=False # 각 서브플롯의 y축 스케일을 독립적으로 설정 (지표별 스케일이 다르므로 중요)\n",
      ")\n",
      "\n",
      "# 전체 그래프 제목 설정\n",
      "g.fig.suptitle('ARI 팀 두 시즌 (2024 vs 2023) 주요 지표 비교', y=1.02, fontsize=16)\n",
      "\n",
      "# 각 서브플롯에 제목과 라벨 설정 및 값 표시\n",
      "for ax in g.axes.flat:\n",
      "    metric_name = ax.get_title().replace('Metric = ', '') # 서브플롯 제목에서 지표 이름 추출\n",
      "    ax.set_xlabel(\"시즌\")\n",
      "    ax.set_ylabel(\"값\")\n",
      "    ax.set_title(f'{metric_name} 비교') # 서브플롯 제목을 더 명확하게 설정\n",
      "\n",
      "    # 각 바 위에 값 표시, 'Rank'는 정수, 나머지는 소수점 둘째 자리\n",
      "    for container in ax.containers:\n",
      "        if metric_name == 'Rank':\n",
      "            ax.bar_label(container, fmt='%.0f', label_type='edge')\n",
      "        else:\n",
      "            ax.bar_label(container, fmt='%.2f', label_type='edge')\n",
      "\n",
      "# 레이아웃 조정 (전체 제목이 겹치지 않도록 상단 여백 확보)\n",
      "plt.tight_layout(rect=[0, 0, 1, 0.98])\n",
      "\n",
      "# 시각화에 사용된 컬럼명: Season, Rank, Win-Loss Percentage, Runs per Game, Runs Allowed per Game\n",
      "```\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3mAction: DataLoaderTool\n",
      "Action Input: query=\"ARI 팀의 최신 시즌 투수 대체선수 대비 승리 기여도 데이터를 불러와 데이터프레임으로 변환합니다.\"\u001b[0m\u001b[33;1m\u001b[1;3m  Team Season  p_WAR\n",
      "0  ARI   2024   12.4\u001b[0m\u001b[32;1m\u001b[1;3mFinal Answer: DB에서 ARI 팀의 최신 시즌 투수 대체선수 대비 승리 기여도 데이터를 불러와 데이터프레임으로 변환한 결과는 다음과 같습니다:\n",
      "\n",
      "```\n",
      "  Team Season  p_WAR\n",
      "0  ARI   2024   12.4\n",
      "```\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3mAction: DataLoaderTool\n",
      "Action Input: query=\"ARI 팀의 최신 시즌 타자 대체선수 대비 승리 기여도 데이터를 불러와 데이터프레임으로 변환합니다.\"\u001b[0m\u001b[33;1m\u001b[1;3m  Team Season  b_WAR\n",
      "0  ARI   2024   34.1\u001b[0m\u001b[32;1m\u001b[1;3mFinal Answer: DB에서 ARI 팀의 최신 시즌 타자 대체선수 대비 승리 기여도 데이터를 성공적으로 불러와 데이터프레임으로 변환했습니다.\n",
      "\n",
      "데이터프레임은 다음과 같습니다:\n",
      "```\n",
      "  Team Season  b_WAR\n",
      "0  ARI   2024   34.1\n",
      "```\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3mAction: DataLoaderTool\n",
      "Action Input: query=\"DB에서 ARI 팀의 최신 시즌 수비로 막아낸 득점 데이터를 불러와 데이터프레임으로 변환합니다.\"\u001b[0m\u001b[33;1m\u001b[1;3m  Team Season  DRS\n",
      "0  ARI   2024   13\u001b[0m\u001b[32;1m\u001b[1;3mFinal Answer: contents_id='3.3. 수비 능력' type='Table' contents='DB에서 ARI 팀의 최신 시즌 수비로 막아낸 득점 데이터를 불러와 데이터프레임으로 변환합니다.'\n",
      "```\n",
      "  Team Season  DRS\n",
      "0  ARI   2024   13\n",
      "```\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "et = ExecuteTask()\n",
    "\n",
    "etts = []\n",
    "for i in ttd: \n",
    "    ett = et.invoke(i)\n",
    "    etts.append(ett)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "b56dbc8e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'DB에서 ARI 팀의 최신 시즌 순위, 경기 수, 승리 수, 패배 수, 승률, 득점, 실점, 평균 경기당 득/실 데이터를 불러와 데이터프레임으로 변환한 결과입니다:\\n\\n```\\n   Rank    G   W   L       W-L    R   RA  평균 경기당 득점  평균 경기당 실점\\n0     8  162  89  73  0.549383  886  788       5.47       4.86\\n```'"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "etts[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac040628-4169-470e-a948-ce1f9dff2cea",
   "metadata": {},
   "source": [
    "## ResultAggregator | aggregate_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4ca6add-6a61-4f4f-8fed-78e1fed31c2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResultAggregator(object):\n",
    "    def __init__(self, llm=llm):\n",
    "        self.llm = llm\n",
    "        self.prompt = self.__create_prompt()\n",
    "        self.chain = self.prompt | self.llm | StrOutputParser()\n",
    "\n",
    "    def __create_prompt(self):\n",
    "        template = \"\"\"주어진 목표:\n",
    "        {optimized_goal}\n",
    "        \n",
    "        조사결과:\n",
    "        {results}\n",
    "        \n",
    "        주어진 목표에 대해서 조사 결과를 활용하여 다음 지시에 기반한 응답을 생성해 주세요.\n",
    "        \"\"\"\n",
    "        prompt = ChatPromptTemplate.from_template(template)\n",
    "        return prompt\n",
    "        \n",
    "    def invoke(self, optimized_goal:str, results:str):\n",
    "        answer = self.chain.invoke({'optimized_goal':optimized_goal, 'results':results})\n",
    "        return answer\n",
    "\n",
    "    def __str__(self):\n",
    "        return f'{self.__class__.__name__}'\n",
    "\n",
    "    def __repr__(self):\n",
    "        return f'{self.__class__.__name__}'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f65aaa8",
   "metadata": {},
   "source": [
    "## SingleResultAggregator | single_aggregate_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "568978a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SingleResultAggreagor(object):\n",
    "    def __init__(self, llm=llm):\n",
    "        self.llm = llm\n",
    "        self.prompt = self.__create_prompt()\n",
    "        self.chain = self.prompt | self.llm | StrOutputParser() | RunnableLambda(self.__clean_answer)\n",
    "\n",
    "    def __create_prompt(self):\n",
    "        template = \"\"\"\n",
    "        주어진 목표:\n",
    "        {optimized_goal}\n",
    "        \n",
    "        조사결과:\n",
    "        {results}\n",
    "        \n",
    "        주어진 목표에 대해서 조사 결과를 활용하여 다음 지시에 기반한 응답을 무조건 하나만 생성해 주세요.\n",
    "        - 오직 조사결과만 ouput으로 지정한다. (수행 과정, 로그, 코멘트 등 작성 금지)\n",
    "        \"\"\"\n",
    "        prompt = ChatPromptTemplate.from_template(template)\n",
    "        return prompt\n",
    "\n",
    "    def __clean_answer(self, answer:str):\n",
    "        answer = answer.replace('```', '')\n",
    "        answer = answer.replace('python', '')\n",
    "        answer = answer.replace('plt.show()', '')\n",
    "        return answer\n",
    "    \n",
    "    def invoke(self, optimized_goal:str, results:str):\n",
    "        answer = self.chain.invoke({'optimized_goal':optimized_goal, 'results':results})\n",
    "        return answer\n",
    "\n",
    "    def __str__(self):\n",
    "        return f'{self.__class__.__name__}'\n",
    "\n",
    "    def __repr__(self):\n",
    "        return f'{self.__class__.__name__}'\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48276b65-e235-4487-9fdf-a430e5b6821f",
   "metadata": {},
   "source": [
    "## ResponseCustomer | response_customer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48b16a85-f722-40f2-a16c-3c37b448219b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResponseCustomer(object):\n",
    "    def __init__(self):\n",
    "        self.llm = ChatGoogleGenerativeAI(model='gemini-2.5-flash', temperature=0.2)\n",
    "        self.prompt = self.__create_prompt()\n",
    "        \n",
    "        self.chain = self.prompt | self.llm | StrOutputParser()\n",
    "        \n",
    "    def __create_prompt(self):\n",
    "        template = \"\"\"\n",
    "                당신은 챗봇입니다.\n",
    "                아래 '결정 사유'를 참고해, 사용자가 무엇을 원했는지 확인하고 아래의 조건을 선택해서 답변을 생성하십시오.\n",
    "                이전 질문이 있다면 이것도 기억하고 답변을 생성하십시오.\n",
    "                \n",
    "                조건 1: 결정 사유가 라우팅 실패에 관련된 내용일 경우\n",
    "                - 형식 가이드(3~5문장, 한국어, 공손하지만 간결하게):\n",
    "                1) 확인: 사용자의 의도를 한 문장으로 재진술 (예: \"~정보를 요청하셨군요.\")\n",
    "                2) 한계: 현재 참조 가능한 자료에 무엇이 없는지 명확히 (예: \"현재 제가 참고할 수 있는 정보에는 ~가 포함되어 있지 않습니다.\")\n",
    "                3) 대안: a) 가능한 주제로 이어가기\n",
    "\n",
    "                조건 2: 결정 사유가 모드에 대한 선택에 대한 이유일 경우\n",
    "                - 형식 가이드(3~5문장, 한국어, 공손하게 간결하게):\n",
    "                1) 확인: 사용자의 의도를 한 문장으로 재진술 (예: \"~정보를 요청하셨군요.\")\n",
    "                2) 답변: 사용자의 의도에 대해서 답변을 한다.\n",
    "                3) 한계: 최대한 꾸며내거나 부풀리지 않고 정확하게 답변하려고 노력하여야한다. 그리고 답변이 정확하지 않을 수 있다는 사실을 분명히 한다.\n",
    "\n",
    "                [사용자 질문]\n",
    "                {question}\n",
    "\n",
    "                [결정 사유]\n",
    "                {doc_val_reason}\n",
    "                \n",
    "                [이전 질문]\n",
    "                {prev_user_question}\n",
    "                \"\"\" \n",
    "        prompt = ChatPromptTemplate.from_template(template)\n",
    "        return prompt\n",
    "    \n",
    "    def invoke(self, query:dict, doc_val_reason:str, prev_user_query:str):\n",
    "        return self.chain.invoke({'question':query,\n",
    "                                  'doc_val_reason': doc_val_reason,\n",
    "                                  'prev_user_question': prev_user_query})\n",
    "\n",
    "    def ainoke(self, query:dict, doc_val_reason:str, prev_user_query:str):\n",
    "        return self.chain.ainvoke({'question':query,\n",
    "                                  'doc_val_reason': doc_val_reason,\n",
    "                                  'prev_user_question': prev_user_query})\n",
    "        \n",
    "    \n",
    "    def __format_docs(docs: List[Document]) -> str:\n",
    "            return \"\\n\\n\".join(d.page_content for d in docs) if docs else \"(no context)\"\n",
    "    \n",
    "    def __str__(self):\n",
    "        return f'{self.__class__.__name__}'\n",
    "\n",
    "    def __repr__(self):\n",
    "        return f'{self.__class__.__name__}'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc56c25d",
   "metadata": {},
   "source": [
    "## GetReportInfo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "770af44e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GetReportInfo(object):\n",
    "    def __init__(self, vectorstore: Chroma):\n",
    "        self.llm = ChatGoogleGenerativeAI(model='gemini-2.5-flash')\n",
    "        self.prompt = self.__create_prompt()\n",
    "        self.retriever = vectorstore.as_retriever(search_kwargs={\"k\": 1})\n",
    "        \n",
    "        def format_docs(docs: List[Document]) -> str:\n",
    "            return \"\\n\\n\".join(d.page_content for d in docs) if docs else \"(no context)\"\n",
    "        \n",
    "        self.chain = (\n",
    "        RunnablePassthrough.assign(\n",
    "            # 입력 dict -> \"query\"만 뽑아 retriever에 넣고 -> 문자열로 포맷\n",
    "            context = RunnableLambda(itemgetter(\"query\")) | self.retriever | RunnableLambda(format_docs)\n",
    "        )\n",
    "        | self.prompt\n",
    "        | self.llm.with_structured_output(Output.GetReportInfo)\n",
    "        )\n",
    "    def __create_prompt(self):\n",
    "        template = \"\"\"\n",
    "                너는 \"요구사항-계획서 정합성(Alignment) 심사관\"이다.\n",
    "                입력으로 사용자 질문과 벡터DB에서 가져온 계획서 요약/본문이 주어진다.\n",
    "                너의 임무는: \n",
    "                (a) 질문의 구체적 목표(의도/스펙)를 추출하고,\n",
    "                (b) 들고온 계획서가 그 목표를 충족하는지 평가하고, 데이터의 수집 방법론에 대해서는 평가하지않는다.\n",
    "                (c) 사용자의 목표에 구체적인 보고서 작성 대상이 있는지 판단한다.\n",
    "                (d) 최종 라우팅 결정을 JSON으로 반환하는 것이다.\n",
    "                 - JSON형태 : \"doc_val_response\":\"YES|NO\",\"doc_val_reason\":\"한 줄 요약\",\"documents\":\"들고온 문서(그대로)\"\n",
    "                 \n",
    "                사용자 요구사항:\n",
    "                {query}\n",
    "                \n",
    "                들고온 문서:\n",
    "                {context} \n",
    "                \"\"\" \n",
    "                \n",
    "        prompt = ChatPromptTemplate.from_template(template)\n",
    "        return prompt\n",
    "\n",
    "    def invoke(self, query:dict):\n",
    "        answer = self.chain.invoke({'query':query})\n",
    "        return {\n",
    "            \"doc_val_response\": answer.doc_val_response,\n",
    "            \"doc_val_reason\": answer.doc_val_reason,\n",
    "            \"documents\": answer.documents\n",
    "            }\n",
    "        \n",
    "    def ainvoke(self, query:dict):\n",
    "        answer = self.chain.ainvoke({'query':query})\n",
    "        return {\n",
    "            \"doc_val_response\": answer.doc_val_response,\n",
    "            \"doc_val_reason\": answer.doc_val_reason,\n",
    "            \"documents\": answer.documents\n",
    "            }\n",
    "    \n",
    "   \n",
    "    \n",
    "    def __str__(self):\n",
    "        return f'{self.__class__.__name__}'\n",
    "\n",
    "    def __repr__(self):\n",
    "        return f'{self.__class__.__name__}'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b935ce29-09d3-4e98-aa33-e17ec7a5b7e1",
   "metadata": {},
   "source": [
    "# LangGraph"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19586083",
   "metadata": {},
   "source": [
    "## State"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24b9bbb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Turn(BaseModel):\n",
    "    user_query: str=Field(default_factory=list, description='유저 쿼리')      \n",
    "    mode: Literal['task', 'report', 'ect'] = Field(default='', description=\"모드\")\n",
    "    ai_answer: str=Field(default_factory=list, description='답변')                           \n",
    "    ts: datetime=Field(default_factory=datetime.now())\n",
    "\n",
    "class State(BaseModel):\n",
    "    query: str = Field(..., description='사용자가 입력한 쿼리')\n",
    "    history: Annotated[list[Turn], add] = Field(default_factory= list, description=' 이전 기록')\n",
    "    goal: str = Field(default='', description='사용자가 입력한 쿼리에서 목표 추출')\n",
    "    report_title: str(default='', description='사용자요청을 기반으로 생성된 보고서 제목')\n",
    "    mode: Literal['task', 'report', 'ect'] = Field(default='', description='사용자 요청 유형')\n",
    "    doc_val_response: Literal[\"YES\",\"NO\"] = Field(default='YES', description='문서 검증 결과')\n",
    "    doc_val_reason:str= Field(default='', description='문서 검증 증거')\n",
    "    documents:str = Field(default='', description='검증에 참조한 문서')\n",
    "    optimized_goal: str = Field(default='', description='최적화된 목표') \n",
    "    #optimized_response: str = Field(default='', description='최적화된 응답 정의')\n",
    "    tasks: list = Field(default_factory=list, description='실행할 테스크 리스트')\n",
    "    current_task_index: int = Field(default=0, description='현재 실행 중인 테스크 변호')\n",
    "    results: list = Field(default_factory=list, description='실행 완료된 테스크 결과 리스트')\n",
    "    final_output: str = Field(default='', description='최종 출력 결과')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27a05e07",
   "metadata": {},
   "source": [
    "## Node"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37645542-2ec4-45c0-b421-2b6ff3581d1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.graph import START, END, StateGraph\n",
    "from functools import wraps\n",
    "\n",
    "def node_logging(func):\n",
    "    @wraps(func)\n",
    "    def wrapper(*args, **kwargs):\n",
    "        print(f\"{func.__name__} 시작\")\n",
    "        result = func(*args, **kwargs)\n",
    "        print(f\"{func.__name__} 완료\")\n",
    "        return result\n",
    "    return wrapper"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81a22618-2024-4401-87c6-81911bc83def",
   "metadata": {},
   "source": [
    "### Node 정의"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "724f7360",
   "metadata": {},
   "outputs": [],
   "source": [
    "@node_logging\n",
    "def get_mode(state:State):\n",
    "    state = state.dict()\n",
    "    query = state['query']\n",
    "    answer = GetMode().invoke(query)\n",
    "    return {'mode':answer.mode, 'doc_val_reason':answer.reason}\n",
    "\n",
    "\n",
    "# 리포트\n",
    "@node_logging\n",
    "def get_goal(state:State):\n",
    "    state = state.dict()\n",
    "    query = state['query']\n",
    "    answer = PassiveGoalCreator().invoke(query)\n",
    "    return {'goal':answer['goal'], 'report_title': answer['report_title']}\n",
    "\n",
    "@node_logging\n",
    "def get_report_info(state:State):\n",
    "    state = state.dict()\n",
    "    query = state['goal']\n",
    "    answer = GetReportInfo(vectorstore=vectorstore).invoke(query)\n",
    "    return {'doc_val_response': answer['doc_val_response'],\n",
    "            \"doc_val_reason\": answer['doc_val_reason'],\n",
    "            \"documents\": answer['documents']}\n",
    "\n",
    "@node_logging\n",
    "def optimize_goal(state:State):\n",
    "    state = state.dict()\n",
    "    query = state['goal']\n",
    "    docs = state['documents']\n",
    "    answer = GoalOptimizer().invoke(query, docs)\n",
    "    \n",
    "    # tasks, index 초기화\n",
    "\n",
    "    return {\n",
    "            'optimized_goal':answer,\n",
    "            \"tasks\": [],\n",
    "            'results': [],\n",
    "            \"current_task_index\": 0\n",
    "            }\n",
    " \n",
    "# @node_logging\n",
    "# def optimize_response(state:State):\n",
    "#     state = state.dict()\n",
    "#     query = state['optimized_goal']\n",
    "#     answer = ResponseOptimizer().invoke(query)\n",
    "#     return {'optimized_response':answer}\n",
    "\n",
    "@node_logging\n",
    "def decompose_tasks(state:State):\n",
    "    state = state.dict()\n",
    "    query = state['optimized_goal']\n",
    "    answer = TaskDecomposer().invoke(query)\n",
    "    return {'tasks': answer}\n",
    "\n",
    "@node_logging\n",
    "def execute_task(state:State):\n",
    "    state = state.dict()\n",
    "    complete_tasks = state['results']\n",
    "    current_task_index = state['current_task_index']\n",
    "    task = state['tasks'][current_task_index]\n",
    "    answer = ExecuteTask().invoke(task)\n",
    "    current_task_index += 1\n",
    "    return {'results': complete_tasks + [answer], 'current_task_index':current_task_index}\n",
    "\n",
    "@node_logging\n",
    "def aggregate_result(state:State):\n",
    "    state = state.dict()\n",
    "    results = state['results']\n",
    "    optimized_goal = state['optimized_goal']\n",
    "    #optimized_response = state['optimized_response']\n",
    "    answer = ResultAggregator().invoke(optimized_goal, results)\n",
    "    \n",
    "    history = {\n",
    "        \"user_query\": state['query'],\n",
    "        \"ai_answer\": answer,\n",
    "        \"ts\" : datetime.now()\n",
    "    }\n",
    "    \n",
    "    return {'final_output': answer, \"history\" : [history]}\n",
    "\n",
    "\n",
    "\n",
    "# 단일 태스크\n",
    "\n",
    "\n",
    "@node_logging\n",
    "def single_get_info(state:State):\n",
    "    state = state.dict()\n",
    "    query = state['goal']\n",
    "    answer = SingleGettInfo(vectorstore=vectorstore).invoke(query)\n",
    "    return {'doc_val_response': answer['doc_val_response']}\n",
    "\n",
    "@node_logging\n",
    "def single_optimize_goal(state:State):\n",
    "    state = state.dict()\n",
    "    query = state['goal']\n",
    "    answer = SingleGoalOptimizer().invoke(query)\n",
    "    return {'optimized_goal':answer}\n",
    "\n",
    "@node_logging\n",
    "def single_execute_task(state:State):\n",
    "    state = state.dict()\n",
    "    task = state['optimized_goal']\n",
    "    answer = ExecuteTask().invoke(task)\n",
    "    return {'results': [answer]}\n",
    "\n",
    "@node_logging\n",
    "def single_aggregate_result(state:State):\n",
    "    state = state.dict()\n",
    "    results = state['results']\n",
    "    optimized_goal = state['optimized_goal']\n",
    "    answer = SingleResultAggreagor().invoke(optimized_goal, results)\n",
    "    \n",
    "    history = {\n",
    "        \"user_query\": state['query'],\n",
    "        \"ai_answer\": answer,\n",
    "        \"ts\" : datetime.now()\n",
    "    }\n",
    "    \n",
    "    return {'final_output': answer, 'history': [history]}\n",
    "\n",
    "\n",
    "# 챗봇\n",
    "@node_logging\n",
    "def response_customer(state:State):\n",
    "    state = state.dict()\n",
    "    query = state['query']\n",
    "    doc_val_reason = state['doc_val_reason']\n",
    "    \n",
    "    history = state.get('history', [])\n",
    "    if history:\n",
    "        prev_user_query = history[-1]['user_query']\n",
    "    else: \n",
    "        prev_user_query=\"이전 질문 없음\"\n",
    "        \n",
    "    answer = ResponseCustomer().invoke(query = query, doc_val_reason = doc_val_reason, prev_user_query=prev_user_query)\n",
    "    \n",
    "    history = {\n",
    "        \"user_query\": state['query'],\n",
    "        \"ai_answer\": answer,\n",
    "        \"ts\" : datetime.now()\n",
    "    }\n",
    "    \n",
    "    return {'final_output': answer, \"history\" : [history]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17a3a8c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "workflow = StateGraph(State)\n",
    "\n",
    "workflow.add_node('get_mode', get_mode)\n",
    "\n",
    "# 리포트\n",
    "workflow.add_node('get_goal', get_goal)\n",
    "workflow.add_node('get_report_info', get_report_info)\n",
    "workflow.add_node('optimize_goal', optimize_goal)\n",
    "#workflow.add_node('optimize_response', optimize_response)\n",
    "workflow.add_node('decompose_tasks', decompose_tasks)\n",
    "workflow.add_node('report_execute_task', execute_task)\n",
    "workflow.add_node('aggregate_result', aggregate_result)\n",
    "\n",
    "# 단일 태스크\n",
    "workflow.add_node('single_get_goal', get_goal)\n",
    "workflow.add_node('single_get_info', single_get_info)\n",
    "workflow.add_node('single_optimize_goal', single_optimize_goal) \n",
    "workflow.add_node('single_execute_task', single_execute_task)\n",
    "workflow.add_node('single_aggregate_result', single_aggregate_result)\n",
    "\n",
    "\n",
    "\n",
    "# 챗봇\n",
    "workflow.add_node('response_customer', response_customer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b588d17c",
   "metadata": {},
   "source": [
    "## Edge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "042102c4-25f4-4374-b1b9-ace60988cd8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "workflow.add_edge(START, 'get_mode')\n",
    "workflow.add_conditional_edges('get_mode', lambda state: state.dict()['mode'], {'task':'single_get_goal', 'report':'get_goal', 'ect':'response_customer'})\n",
    "workflow.add_edge('single_get_goal', 'single_get_info')\n",
    "workflow.add_conditional_edges('single_get_info', lambda state: state.dict()['doc_val_response'], {'YES':'single_optimize_goal', 'NO': END})\n",
    "workflow.add_edge('single_optimize_goal', 'single_execute_task')\n",
    "workflow.add_edge('single_execute_task', 'single_aggregate_result')\n",
    "\n",
    "workflow.add_edge('response_customer', END)\n",
    "\n",
    "workflow.add_edge('get_goal', 'get_report_info')\n",
    "workflow.add_conditional_edges('get_report_info', lambda state: state.dict()['doc_val_response'], {'YES':'optimize_goal', 'NO':'response_customer'})\n",
    "workflow.add_edge('optimize_goal', 'decompose_tasks')\n",
    "workflow.add_edge('decompose_tasks', 'report_execute_task')\n",
    "workflow.add_conditional_edges('report_execute_task', lambda state: state.dict()['current_task_index'] < len(state.dict()['tasks']), {True:'report_execute_task', False:'aggregate_result'})\n",
    "workflow.add_edge('aggregate_result', END)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebf8608e-b652-4f20-86db-7b194ddfe531",
   "metadata": {},
   "source": [
    "## Graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "554e5daf-9b64-48fa-b843-6bf28c1f2023",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.checkpoint.memory import MemorySaver\n",
    "\n",
    "memory = MemorySaver()\n",
    "graph = workflow.compile(checkpointer=memory)\n",
    "conversation_id = \"my-test-session-001\" \n",
    "config = {\"configurable\": {\"thread_id\": conversation_id}}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48453d9f",
   "metadata": {},
   "source": [
    "# 테스트"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb8b8f8a-5762-4761-881a-c826941837d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "result_ect = graph.invoke({'query':'야구에서 WHIP이라는 지표에 대해서 알려줘'}, config)\n",
    "result_ect['final_output']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abac996d-962b-4b45-9b69-76204d4e9c23",
   "metadata": {},
   "outputs": [],
   "source": [
    "result_ect2 = graph.invoke({'query':'그럼 내가 전에 물어봤던 지표랑 비슷한 지표는 뭐가 있을까'}, config)\n",
    "result_ect2['final_output']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa21cb49-86b7-4349-939a-d2b7ebb9f012",
   "metadata": {},
   "outputs": [],
   "source": [
    "result_task = graph.invoke({'query':'ARI팀의 2024년 시즌 득점과 실점 데이터를 보여줘'}, config)\n",
    "result_task['final_output']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a634e9b4-d5cf-49f5-be4d-99e3ded0a105",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "result_task2 = graph.invoke({'query':'2024년 시즌 1위 팀의 승률을 차트로 그려줘.'}, config)\n",
    "print(result_task2['final_output'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ac452ce-38d3-45b2-94ba-986842c12f84",
   "metadata": {},
   "outputs": [],
   "source": [
    "result_task3 = graph.invoke({'query':'2024년 ARI팀의 전력분석보고서 작성해줘.'}, config)\n",
    "result_task3['final_output']"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
