{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "074e14c7-629b-4963-a662-b6f4944e07a8",
   "metadata": {},
   "source": [
    "# 모듈 불러오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23775e48",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "\n",
    "from langchain_community.tools import QuerySQLDatabaseTool\n",
    "from langchain_community.utilities import SQLDatabase\n",
    "from langchain.chains import create_sql_query_chain\n",
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain.prompts import ChatPromptTemplate\n",
    "from langchain.schema.runnable import RunnableLambda, RunnablePassthrough\n",
    "from langchain_community.tools.tavily_search import TavilyAnswer, TavilySearchResults\n",
    "from langsmith import Client\n",
    "\n",
    "from BK.db import DB\n",
    "import re\n",
    "\n",
    "from langchain_community.embeddings import HuggingFaceEmbeddings\n",
    "from langchain_community.vectorstores import Chroma\n",
    "from operator import itemgetter\n",
    "from langchain.schema import Document\n",
    "from typing import List, Literal, Any\n",
    "\n",
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "from langchain.prompts import ChatPromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.pydantic_v1 import BaseModel, Field\n",
    "\n",
    "from langchain.agents import create_react_agent,AgentExecutor\n",
    "\n",
    "from typing import Annotated\n",
    "from datetime import datetime \n",
    "from operator import add\n",
    "\n",
    "import uuid"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60a85ad1",
   "metadata": {},
   "source": [
    "# 필요 환경정의 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4093fca9",
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv('.env')\n",
    "\n",
    "# llm\n",
    "llm = ChatGoogleGenerativeAI(model='gemini-2.5-flash', temperature=0)\n",
    "llm_chat = ChatGoogleGenerativeAI(model='gemini-2.5-flash', temperature=0.2)\n",
    "\n",
    "# 랭스미스\n",
    "client = Client()\n",
    "# DB\n",
    "db = SQLDatabase.from_uri('postgresql://postgres:postgres@10.10.50.155:1108/postgres', schema=\"doosan\")\n",
    "\n",
    "# 벡터 DB\n",
    "from langchain_community.embeddings import HuggingFaceEmbeddings\n",
    "embedding_model_name = \"nlpai-lab/KoE5\"\n",
    "embedding = HuggingFaceEmbeddings(\n",
    "    model_name=embedding_model_name,\n",
    "    model_kwargs={\n",
    "        \"device\": \"cpu\",\n",
    "        # \"trust_remote_code\": True,  # 모델에 따라 필요할 수 있음\n",
    "    },\n",
    "    # encode_kwargs={\"normalize_embeddings\": True},  # 코사인 유사도 안정화 (버전에 따라 지원)\n",
    ")\n",
    "\n",
    "vectorstore = Chroma(\n",
    "    persist_directory='./chroma_reports_db',\n",
    "    embedding_function=embedding,\n",
    "    collection_name=\"reports_ko1\" \n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2c56716-267f-45fa-9d23-0cf1c947bfca",
   "metadata": {},
   "source": [
    "# Tools"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cab98db",
   "metadata": {},
   "source": [
    "## DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f774b5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# DataLoader\n",
    "class DataLoader(object):\n",
    "    def __init__(self, db:SQLDatabase = db):\n",
    "        self.llm = ChatGoogleGenerativeAI(model='gemini-2.5-flash', temperature=0)\n",
    "        self.db = db\n",
    "        self.write_query = create_sql_query_chain(llm, db)\n",
    "        self.execute_query = QuerySQLDatabaseTool(db=db)\n",
    "        self.chain = RunnableLambda(self.__create_prompt) | self.write_query | RunnableLambda(self.__clean_answer) |RunnableLambda(self._execute_query)\n",
    "\n",
    "    def __create_prompt(self, question:str):\n",
    "        question = question['question']\n",
    "        prompt = f\"\"\"\n",
    "        당신은 SQL 쿼리 전문가입니다. 사용자의 요청을 SQL 쿼리로 변환하는 임무를 맡습니다. \n",
    "        주어진 input을 활용하여 툴을 호출한 후 나오는 DB정보를 활용해 SELECT문을 써서 PostgreSQL로 정의하시오.\n",
    "\n",
    "        쿼리 작성 규칙:\n",
    "        - 주어진 정보를 깊게 생각하여 쿼리를 생성하여라.\n",
    "        - tool을 있는 그대로(축약금지, 꾸며내기 금지) 활용해 참조한 DB정보를 바탕으로 불러온 DB정보안에 들어있는 컬럼명을 반드시 참조해서 SQL문 작성.\n",
    "        - 모든 컬럼명에는 \"\"로 감싸주며, as를 통해서 alias 하더라도 \"\"를 사용할 것.\n",
    "        - Select외 나머지 DDL 사용 금지.\n",
    "        - 최종 출력은 SQL 쿼리만 출력.\n",
    "        - 어떤 경우에도 \"SQLQuery:\", \"Answer:\", \"Output:\" 등의 접두어를 포함하지 않는다.\n",
    "        - 반드시 SQL문만 순수하게 출력한다. (SELECT로 시작해야 함)\n",
    "        - 지표별 리그 내 순위 생성이 명시된 콘텐츠에서만 순위 생성 시 반드시 아래와 같은 규칙을 따라줘:\n",
    "            * 논리적 순서: 먼저 해당 시즌 데이터만 필터링하고, 그 안에서 모든 팀의 각 지표에 대한 순위를 계산해줘. 마지막으로 내가 원하는 특정 팀의 데이터만 필터링해서 보여줘.\n",
    "            * 포함할 컬럼: \"팀 명\", \"시즌\"을 제외한 지표들의 값.\n",
    "        - tool을 호출하지 않고는 절대 판단하지 말 것.\n",
    "        - Schema정보를 반드시 참조하여 테이블명을 완성시킬 것.\n",
    "        - 소수점이 긴 경우, numeric 타입으로 변환 후 둘째 자리까지 반올림한다.\n",
    "        - 어떤 경우에도 쿼리는 ```을 사용하지 않고 작성한다.\n",
    "        - LIMIT에 대한 요청이 없는 경우 전체 데이터 조회\n",
    "\n",
    "        사용자 요청:\n",
    "        {question}\n",
    "        \"\"\"\n",
    "        \n",
    "        return {'question':prompt}\n",
    "\n",
    "    def _execute_query(self, query):\n",
    "        rdb = DB('pg', 'postgres')\n",
    "        data = rdb.read_table(query)\n",
    "        return data\n",
    "\n",
    "    def invoke(self, query:dict):\n",
    "        return self.chain.invoke({'question':query})\n",
    "\n",
    "    def ainoke(self, query:dict):\n",
    "        return self.chain.ainvoke({'question':query})\n",
    "    \n",
    "    def __clean_answer(self, query):\n",
    "        clean_query = re.sub('SQLQuery: {0,1}', '', query)\n",
    "        clean_query = re.sub('^sql|sql', '', clean_query)\n",
    "        clean_query = re.sub('```', \"'''\", clean_query)\n",
    "        return clean_query.strip()\n",
    "        \n",
    "\n",
    "    def __str__(self):\n",
    "        return f'{self.__class__.__name__}'\n",
    "\n",
    "    def __repr__(self):\n",
    "        return f'{self.__class__.__name__}'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c48ec3e1",
   "metadata": {},
   "source": [
    "## DataAnalyst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5e051f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataAnalyst(object):\n",
    "    def __init__(self, db:SQLDatabase = db):\n",
    "        self.llm = ChatGoogleGenerativeAI(model='gemini-2.5-flash')\n",
    "        self.prompt = self.__create_prompt()\n",
    "        self.data_loader_chain = DataLoader(db).chain\n",
    "        self.chain = RunnablePassthrough.assign(data= self.data_loader_chain) | self.prompt | llm | StrOutputParser()\n",
    "\n",
    "    def __create_prompt(self):\n",
    "        template = \"\"\"\n",
    "                    당신은 데이터 분석 전문가입니다. 사용자에게 요청에 따라 데이터를 해석하고 분석하는 임무를 맡습니다. \n",
    "                \n",
    "                    데이터 해석 규칙:\n",
    "                    - 사용자 요청과 주어진 데이터만 활용해서 해석을 합니다.\n",
    "                    - 다만 주어진 데이터로 새로운 변수를 만들어 해석할 여지가 있으면 새로운 변수를 만들어서 해석을 해야합니다.\n",
    "                    - 데이터는 사용자 요청과 관련있는 데이터입니다.\n",
    "                    \n",
    "                    사용자 요청: \n",
    "                    {question}\n",
    "                    \n",
    "                    데이터:\n",
    "                    {data}\n",
    "                \"\"\" \n",
    "        prompt = ChatPromptTemplate.from_template(template)\n",
    "        return prompt\n",
    "\n",
    "    def invoke(self, query:dict):\n",
    "        return self.chain.invoke({'question':query})\n",
    "\n",
    "    def ainoke(self, query:dict):\n",
    "        return self.chain.ainvoke({'question':query})\n",
    "    \n",
    "    def __str__(self):\n",
    "        return f'{self.__class__.__name__}'\n",
    "\n",
    "    def __repr__(self):\n",
    "        return f'{self.__class__.__name__}'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34808a72",
   "metadata": {},
   "source": [
    "## BI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "103c42dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BI(object):\n",
    "    def __init__(self, db:SQLDatabase = db):\n",
    "        self.llm = ChatGoogleGenerativeAI(model='gemini-2.5-flash')\n",
    "        self.prompt = self.__create_prompt()\n",
    "        self.data_loader_chain = DataLoader(db).chain\n",
    "        self.chain = RunnablePassthrough.assign(data= self.data_loader_chain) | self.prompt | llm | StrOutputParser() | RunnableLambda(self.__clean_answer)\n",
    "\n",
    "    def __create_prompt(self):\n",
    "        template = \"\"\"\n",
    "        당신은 Python Matplotlib 및 Seaborn 시각화 전문가입니다.\n",
    "        당신의 임무는 제공된 데이터(DataFrame)와 사용자 요청을 바탕으로 가장 적합한 시각화 유형을 자동으로 선택하고, 실행 가능한 코드를 생성하는 것입니다.\n",
    "        제공된 데이터(DataFrame)를 분석하고, 컬럼의 데이터 타입(num / category / datetime)을 직접 정의해서 가장 적합한 시각화 유형을 자동으로 선택해야 합니다.\n",
    "\n",
    "        1. 데이터 확인 원칙\n",
    "        - 컬럼 데이터 타입 판별: num, category, datetime\n",
    "        - 고유값 개수(unique count) 및 결측치 비율 확인\n",
    "        - 단일 핵심 지표 여부 확인\n",
    "        - 누적값 여부 확인 (시계열/누적 구조 판단)\n",
    "        - 데이터를 정의할 경우 반드시 DB에서 조회된 데이터만 사용한다. (임의의 값 생성 금지)\n",
    "        - 모든 컬럼 길이가 동일하도록 반드시 확인\n",
    "\n",
    "        2. 시각화 선택 원칙\n",
    "        - 데이터의 주요 컬럼 타입(num / category / datetime)을 파악한 후 가장 기본적인 그래프를 선택합니다.\n",
    "        - 고급형(복합, 분포, 상관) 그래프는 사용하지 않습니다.\n",
    "        - 오직 다음 기본 유형만 고려합니다:\n",
    "         * 막대그래프 (Bar) : category → num 비교\n",
    "         * 선그래프 (Line) : datetime → num 시계열\n",
    "         * 산점도 (Scatter) : num ↔ num 관계\n",
    "         * 히스토그램 (Histogram) : 단일 num 분포\n",
    "         * 박스플롯 (Boxplot) : category → num 분포 비교\n",
    "         * 파이차트 (Pie) : 비율 강조 필요 시\n",
    "\n",
    "        3. 코드 생성 규칙\n",
    "        - 반드시 실행 가능한 Python 코드만 작성\n",
    "        - 한글이 깨지지 않도록 Python 코드 작성\n",
    "        - 코드는 절대 마크다운(`````, ''') 블록 안에 넣지 말고, 실행 가능한 Python 코드만 출력하라.\n",
    "        - 주석(#)은 허용하되, 불필요한 설명, 문자열, 마크다운(`````, `'''`)은 포함하지 않음\n",
    "        - exec() 함수로 바로 실행 가능한 형태여야 함\n",
    "        - 폰트는 라이브러리에 내장된 기본 폰트를 반드시 사용한다. (Windows 환경)\n",
    "        - plt.show()는 생략\n",
    "        - print()는 사용하지 않음\n",
    "        - 그래프 제목, X/Y축 라벨, 주요 범례 및 색상 강조 필수\n",
    "        - 시각화에 사용된 컬럼명을 코드 주석으로 명시\n",
    "        - 버전과 상관없는 오류가 가장 적은 기본적인 코드로만 구성\n",
    "        - 결과를 저장할 필요 없음 (코드만 생성)\n",
    "        - 결과가 글자 겹침, 범례 와 차트간의 간격 등을 잘 고려해서 최대한 보기 좋을 수 있도록 Python 코드 작성\n",
    "\n",
    "        입력 데이터:\n",
    "        {data}\n",
    "\n",
    "        사용자 요청:\n",
    "        {question}\n",
    "        \"\"\" \n",
    "        \n",
    "        prompt = ChatPromptTemplate.from_template(template)\n",
    "        return prompt\n",
    "\n",
    "    def __clean_answer(self, answer:str):\n",
    "        answer = answer.replace('```', \"'''\")\n",
    "        answer = answer.replace('python', '')\n",
    "        return answer\n",
    "\n",
    "    def invoke(self, query:dict):\n",
    "        return self.chain.invoke({'question':query})\n",
    "\n",
    "    def ainoke(self, query:dict):\n",
    "        return self.chain.ainvoke({'question':query})\n",
    "\n",
    "    def __str__(self):\n",
    "        return f'{self.__class__.__name__}'\n",
    "\n",
    "    def __repr__(self):\n",
    "        return f'{self.__class__.__name__}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b981f862",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tools\n",
    "from langchain_core.tools import tool\n",
    "from langchain_community.tools.tavily_search import TavilyAnswer, TavilySearchResults\n",
    "\n",
    "@tool(name_or_callable=\"DataLoaderTool\", description='사용자 요청에 따라 DB에서 적절한 데이터를 불러와서 데이터 프레임으로 반환합니다.' ,return_direct=False)\n",
    "def load_data(query:str) -> str:\n",
    "    loader = DataLoader(db)\n",
    "    return loader.invoke(query)\n",
    "\n",
    "@tool(name_or_callable=\"DataAnalystTool\", description='사용자 요청에 따라 DB에서 적절한 데이터를 불러온 후 분석하고 해석합니다.' ,return_direct=False)\n",
    "def analysis_data(query:str) -> str:\n",
    "    analyst = DataAnalyst(db)\n",
    "    return analyst.invoke(query)\n",
    "\n",
    "@tool(name_or_callable=\"BITool\", description='사용자 요청에 따라 DB에서 적절한 데이터를 불러와서 시각화할 수 있는 코드를 작성합니다.' ,return_direct=False)\n",
    "def visualize_data(question: str) -> str:\n",
    "    bi = BI(db)\n",
    "    return bi.invoke(question)\n",
    "\n",
    "report_tools = [TavilySearchResults(max_results=3), load_data, visualize_data]\n",
    "\n",
    "task_tools = [TavilySearchResults(max_results=3), load_data, visualize_data, analysis_data]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "649e6fe0",
   "metadata": {},
   "source": [
    "# Output Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa90d798",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydantic import BaseModel, Field\n",
    "from typing import Literal, Optional\n",
    "\n",
    "\n",
    "\n",
    "class TaskInfo(BaseModel):\n",
    "    contents_id: str = Field(..., description=\"콘텐츠 목차 + 콘텐츠 명\")\n",
    "    type: Literal[\"Chart\", \"Table\"] = Field(..., description=\"콘텐츠 결과 유형\")\n",
    "    contents: str = Field(..., description=\"태스크 설명\")\n",
    "\n",
    "class Output(object):\n",
    "    class GetMode(BaseModel):\n",
    "        mode: Literal['task', 'report', 'ect'] = Field(..., description='사용자 요청을 분석하여 요청 유형을 task, report, ect로 분류')\n",
    "        reason: str = Field(default='', description='사용자 요청을 분류한 근거를 2~3로 작성하세요.')\n",
    "        query_id: str = Field(default='', description='Python에서 UUID로 생성되는 고유 ID')\n",
    "        \n",
    "    class PassiveGoalCreator(BaseModel):\n",
    "        report_title: str = Field(..., description='보고서 제목')\n",
    "        description: str = Field(..., description='목표 설명')\n",
    "        \n",
    "        \n",
    "        @property\n",
    "        def text(self) -> str:\n",
    "            return f'{self.description}'\n",
    "            \n",
    "    class GoalOptimizer(BaseModel):\n",
    "        description:str = Field(..., description='목표 설명')\n",
    "    \n",
    "        @property\n",
    "        def text(self) -> str:\n",
    "            return f'{self.description}'\n",
    "\n",
    "    \n",
    "    class TaskDecomposer(BaseModel):\n",
    "        tasks: list[TaskInfo] = Field(\n",
    "            default_factory=list,\n",
    "            min_item=3,\n",
    "            max_item=8,\n",
    "            description='3~8개로 분해된 테스크')\n",
    "    \n",
    "    class GetReportInfo(BaseModel):\n",
    "        doc_val_response: Literal[\"YES\",\"NO\"] = Field(default='YES', description='문서 검증 결과')\n",
    "        doc_val_reason:str= Field(default='', description='문서 검증 증거')\n",
    "        documents:str = Field(default='', description='검증에 참조한 문서')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad18ad5f-312c-4eea-9784-172b31903938",
   "metadata": {},
   "source": [
    "# LLM&Agent"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e045c7d-81bb-4914-a021-9db4e69ea7db",
   "metadata": {},
   "source": [
    "## GetMode | get_mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5864c7d6-a5c3-4fe4-af04-a0df65860aba",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GetMode(object):\n",
    "    def __init__(self, llm=llm):\n",
    "        self.llm = llm\n",
    "        self.prompt = self.__create_prompt()\n",
    "        self.chain = self.prompt | self.llm.with_structured_output(Output.GetMode)\n",
    "\n",
    "    def __create_prompt(self):\n",
    "        template = \"\"\"사용자 입력을 분석하여 mode를 task, report, ect로 구분한 후, mode를 그렇게 판단한 이유는 reason에 2~3줄로 간략하게 작성하세요.\n",
    "        task:\n",
    "        - 야구 관련 데이터를 DB에서 추출하는 요청\n",
    "        - 야구 관련 데이터를 분석하는 요청\n",
    "        - 야구 관련 데이터 시각화하는 요청\n",
    "\n",
    "        report:\n",
    "        - 야구 관련 리포트를 작성하는 요청\n",
    "\n",
    "        ect:\n",
    "        - task와 report에 속하지 않는 요청\n",
    "        - 야구와 관련되지 않은 요청\n",
    "        \n",
    "        사용자 요청:\n",
    "        {query} \n",
    "        \"\"\"\n",
    "        prompt = ChatPromptTemplate.from_template(template)\n",
    "        return prompt\n",
    "        \n",
    "    def invoke(self, query:str):\n",
    "        answer = self.chain.invoke({'query':query})\n",
    "        return answer\n",
    "\n",
    "    def __str__(self):\n",
    "        return f'{self.__class__.__name__}'\n",
    "\n",
    "    def __repr__(self):\n",
    "        return f'{self.__class__.__name__}'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db88a0fb-4ce3-4fa5-ba70-9f503b613b8f",
   "metadata": {},
   "source": [
    "## PassiveGoalCreator | get_goal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "940329e9-d54d-4554-9489-39257b62333f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PassiveGoalCreator(object):\n",
    "    def __init__(self, llm=llm):\n",
    "        self.llm = llm\n",
    "        self.prompt = self.__create_prompt()\n",
    "        self.chain = self.prompt | self.llm.with_structured_output(Output.PassiveGoalCreator)\n",
    "\n",
    "    def __create_prompt(self):\n",
    "        template = \"\"\"너는 야구전문가야. 사용자 입력을 분석하여 명확한 목표와 그에 해당하는 문서 제목을 생성해주세요.\n",
    "            요건\n",
    "            1. 사용자의 입력을 바탕으로 꾸밈없이 명확한 톤으로 다음 LLM이 처리할 수 있도록 문장을 생성하시오.\n",
    "            2. 기간에 대한 범위가 없다면 가장 최신 시즌을 고려하여 작성하십시오. \n",
    "            3. 사용자의 요청과 생성된 목적들을 기반으로 문서 제목을 생성해주십시오. \n",
    "            다만 기간에 대한 사용자의 정확한 요청이 없을 경우 제목을 작성할 때 기간을 명시하는 텍스트는 제외하십시오.\n",
    "            사용자 입력: {query}\n",
    "            \"\"\"\n",
    "            \n",
    "            # 사용자의 부정확한 입력을 다음 LLM이 처리할 수 있도록 명확하게 한문장의로 재작성하는 작업 담당\n",
    "        prompt = ChatPromptTemplate.from_template(template)\n",
    "        return prompt\n",
    "\n",
    "    def invoke(self, query):\n",
    "        answer = self.chain.invoke({'query':query})\n",
    "        return {\n",
    "            \"goal\": answer.description,\n",
    "            \"report_title\": answer.report_title,\n",
    "            }\n",
    "\n",
    "    def __str__(self):\n",
    "        return f'{self.__class__.__name__}'\n",
    "\n",
    "    def __repr__(self):\n",
    "        return f'{self.__class__.__name__}'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70d17fe8-b371-4a83-8e63-611d0131145b",
   "metadata": {},
   "source": [
    "## GetReportInfo | get_report_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8f45040-8d75-4340-9b60-05f62449e5b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GetReportInfo(object):\n",
    "    def __init__(self, vectorstore: Chroma, llm=llm):\n",
    "        self.llm = llm\n",
    "        self.prompt = self.__create_prompt()\n",
    "        self.retriever = vectorstore.as_retriever(search_kwargs={\"k\": 1})\n",
    "        \n",
    "        def format_docs(docs: List[Document]) -> str:\n",
    "            return \"\\n\\n\".join(d.page_content for d in docs) if docs else \"(no context)\"\n",
    "        \n",
    "        self.chain = (\n",
    "        RunnablePassthrough.assign(\n",
    "            # 입력 dict -> \"query\"만 뽑아 retriever에 넣고 -> 문자열로 포맷\n",
    "            context = RunnableLambda(itemgetter(\"query\")) | self.retriever | RunnableLambda(format_docs)\n",
    "        )\n",
    "        | self.prompt\n",
    "        | self.llm.with_structured_output(Output.GetReportInfo)\n",
    "        )\n",
    "    def __create_prompt(self):\n",
    "        template = \"\"\"\n",
    "                당신은 엄격하고 객관적인 문서 유효성 검사관입니다. 아래에 제시된 **[사용자 목표/질문]**과 **[검색된 문서]**를 철저하게 비교하여, 문서가 목표를 설명하는 데 충분한 정보를 제공하는지 여부를 판단하세요.\n",
    "\n",
    "                [판단 기준]\n",
    "                YES:\n",
    "                문서의 내용이 **[사용자 목표/질문]**의 핵심 키워드나 주제에 대해 직접적이고 구체적인 정보를 포함하고 있는 경우.\n",
    "                제시된 문서만으로도 목표에 대한 초안 설명이나 답변을 구성하는 데 충분하다고 판단되는 경우.\n",
    "\n",
    "                NO:\n",
    "                문서의 내용이 **[사용자 목표/질문]**과 완전히 다른 주제를 다루고 있거나, 매우 일반적인 정보만 제공하여 목표에 대한 실질적인 설명을 할 수 없는 경우.\n",
    "                문서가 목표와 관련된 키워드를 포함하고 있더라도, 그 내용이 목표에 대한 의도를 충족시키지 못하는 경우.\n",
    "                \n",
    "                마지막으로 증거를 남기기위해 들고온 문서에 대해서 그대로 들고와주십시오.\n",
    "                 \n",
    "                목표:\n",
    "                {query}\n",
    "                \n",
    "                들고온 문서:\n",
    "                {context} \n",
    "                \"\"\" \n",
    "                # 키워드 위주로 비교하며 정해진 목표가 문서로서 완성될 수 있는지 판단\n",
    "        prompt = ChatPromptTemplate.from_template(template)\n",
    "        return prompt\n",
    "\n",
    "    def invoke(self, query:dict):\n",
    "        answer = self.chain.invoke({'query':query})\n",
    "        return {\n",
    "            \"doc_val_response\": answer.doc_val_response,\n",
    "            \"doc_val_reason\": answer.doc_val_reason,\n",
    "            \"documents\": answer.documents\n",
    "            }\n",
    "        \n",
    "    def ainvoke(self, query:dict):\n",
    "        answer = self.chain.ainvoke({'query':query})\n",
    "        return {\n",
    "            \"doc_val_response\": answer.doc_val_response,\n",
    "            \"doc_val_reason\": answer.doc_val_reason,\n",
    "            \"documents\": answer.documents\n",
    "            }\n",
    "    \n",
    "   \n",
    "    \n",
    "    def __str__(self):\n",
    "        return f'{self.__class__.__name__}'\n",
    "\n",
    "    def __repr__(self):\n",
    "        return f'{self.__class__.__name__}'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "456e7f70",
   "metadata": {},
   "source": [
    "## SingleGetInfo | single_get_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eab29e02",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SingleGettInfo(object):\n",
    "    def __init__(self, llm=llm):\n",
    "        self.llm = llm\n",
    "        self.prompt = self.__create_prompt()\n",
    "        \n",
    "        self.chain = (\n",
    "        RunnablePassthrough.assign(query=itemgetter(\"query\"))\n",
    "        | self.prompt\n",
    "        | self.llm.with_structured_output(Output.GetReportInfo)\n",
    "        )\n",
    "    def __create_prompt(self):\n",
    "        template = \"\"\"\n",
    "        너는 \"요구사항 명확성 심사관\"이다.  \n",
    "        사용자의 질문이 주어진 목표를 실행하기에 충분히 구체적이고 실행 가능한지 유형별로 판단해야 한다.  \n",
    "\n",
    "        판단 규칙:\n",
    "        1. 질문 유형별로 아래 기준을 따른다.\n",
    "        [1] 시각화\n",
    "        - 조회한 데이터가 막대그래프, 선그래프, 산점도, 히스토그램, 박스플롯, 파이차트 6가지 유형 각화 요청일 경우:\n",
    "        - 데이터셋 또는 시각화에 필요한 컬럼이 명시되어 있는가?\n",
    "        - 조회한 데이터가 차트를 그리기에 충분한 조건 및 비교 대상(예: 팀, 시즌, 선수 등)이 포함되어 있는가?중 하나로 선택해서 표현할 수 있는가?\n",
    "\n",
    "        [2] 데이터 추출 요청일 경우:\n",
    "        - 어떤 데이터를 어떤 조건으로 조회할지 명시되어 있는가?\n",
    "        - 필요한 컬럼 또는 기준(예: 팀명, 연도, 통계 항목 등)이 포함되어 있는가?\n",
    "\n",
    "        [3] 분석 요청일 경우:\n",
    "        - 분석의 목적(예: 상관관계, 추세, 비교 등)이 명확한가?\n",
    "        - 분석 대상 데이터와 기준(예: 팀, 시즌, 변수 등)이 구체적인가?\n",
    "        \n",
    "        2. 위 조건이 충족되어 있으면 \"YES\", 불충분하거나 모호하면 \"NO\"로 판단한다.\n",
    "        \n",
    "        3. 판단 이유를 한 줄 요약한다.\n",
    "\n",
    "        JSON 출력 형식:\n",
    "        {{\n",
    "        \"doc_val_response\": \"YES\" | \"NO\",\n",
    "        \"doc_val_reason\": \"한 줄 요약\"\n",
    "        }}\n",
    "\n",
    "        사용자 질문:\n",
    "        {query}\n",
    "        \"\"\"\n",
    "                \n",
    "        prompt = ChatPromptTemplate.from_template(template)\n",
    "        return prompt\n",
    "\n",
    "    def invoke(self, query:dict):\n",
    "        answer = self.chain.invoke({'query':query})\n",
    "        return {\n",
    "            \"doc_val_response\": answer.doc_val_response,\n",
    "            \"doc_val_reason\": answer.doc_val_reason\n",
    "            }\n",
    "        \n",
    "    def ainvoke(self, query:dict):\n",
    "        answer = self.chain.ainvoke({'query':query})\n",
    "        return {\n",
    "            \"doc_val_response\": answer.doc_val_response,\n",
    "            \"doc_val_reason\": answer.doc_val_reason\n",
    "            }\n",
    "    \n",
    "    def __str__(self):\n",
    "        return f'{self.__class__.__name__}'\n",
    "\n",
    "    def __repr__(self):\n",
    "        return f'{self.__class__.__name__}'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ac76ee5-6fe3-4a48-986f-7d9ca10349d8",
   "metadata": {},
   "source": [
    "## GoalOptimizer | optimize_goal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f9ef9f6-eb22-4dc6-b7c6-cc808843847c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GoalOptimizer(object):\n",
    "    def __init__(self, llm=llm):\n",
    "        self.llm = llm\n",
    "        self.prompt = self.__create_prompt()\n",
    "        self.chain = self.prompt | self.llm.with_structured_output(Output.GoalOptimizer)\n",
    "\n",
    "    def __create_prompt(self):\n",
    "        template = \"\"\"당신은 야구 관련된 리포트 작성을 위한 목표 설정 전문가입니다.\n",
    "        주어진 원래목표와 주어진 문서(계획서)를 기반으로 콘텐츠별로 달성 가능한 세부적인 목표를 생성하십시오.\n",
    "        [원래목표]\n",
    "        {query}\n",
    "\n",
    "        [지시사항]\n",
    "        1. 주어진 문서에서의 목차번호와 해당 콘텐츠의 제목을 반드시 세부적인 목표와 같이 명시해주십시오.\n",
    "        2. 주어진 문서의 콘텐츠별로 최종적으로 달성해야할 목표를 아래와 같이 매핑하여 명시해주십시오.\n",
    "            - 표, Table : 데이터 반환\n",
    "            - Chart : 파이썬 코드 반환\n",
    "            \n",
    "        3. 원래 목표의 범위를 기준으로 주어진 문서를 기반으로 콘텐츠별로 달성해야될 목표를 상세하게 작성하십시오.\n",
    "        \n",
    "        [주어진 문서]\n",
    "        {docs}\n",
    "        \"\"\"\n",
    "        prompt = ChatPromptTemplate.from_template(template)\n",
    "        return prompt\n",
    "\n",
    "    def invoke(self, query, docs):\n",
    "        answer = self.chain.invoke({'query':query, 'docs':docs})\n",
    "        return answer.text\n",
    "\n",
    "    def __str__(self):\n",
    "        return f'{self.__class__.__name__}'\n",
    "\n",
    "    def __repr__(self):\n",
    "        return f'{self.__class__.__name__}'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "285ed8ce-995d-47a1-801b-5cd635a762e6",
   "metadata": {},
   "source": [
    "## TaskDecomposer | decompose_tasks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19944aeb-e9ef-4d08-8c6a-1a2b1d1fa60f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TaskDecomposer(object):\n",
    "    def __init__(self, llm=llm):\n",
    "        self.llm = llm\n",
    "        self.prompt = self.__create_prompt()\n",
    "        self.chain = self.prompt | self.llm.with_structured_output(Output.TaskDecomposer)\n",
    "\n",
    "    def __create_prompt(self):\n",
    "        template = \"\"\"태스크: 주어진 목표를 콘텐츠만을 기준으로 실행 가능한 태스크로 분해해 주세요.\n",
    "        요건\n",
    "        1. 다음 행동만으로 목표를 달성할 것. 절대 지정된 이외의 행동을 취하지 말 것.\n",
    "        - 사용자의 요청에 따라 적절한 데이터를 불러와 데이터프레임으로 변환합니다.\n",
    "        - 사용자 요청에 따라 DB에서 적절한 데이터를 불러와서 시각화할 수 있는 코드를 작성합니다.\n",
    "        - DB외에 추가로 필요한 정보가 필요할 경우만 판단해서 인터넷 검색을 통해서 정보를 추가합니다.\n",
    "        2. 각 태스크는 구체적으로 상세하게 기재하며, 단독으로 실행 및 검증 가능한 정보를 포함할 것. 추상적인 표현을 일절 포함하지 말것\n",
    "        3. 목표에 작성된 콘텐츠 수를 기준으로 태스크를 최소한으로 생성할 것.\n",
    "        4. 아래와 같이 구성할 것\n",
    "        - contents_id: 콘텐츠 번호. 기존 콘텐츠 명 , type: 결과유형 [Chart, Table], contents: 태스크 내용\n",
    "        5. 태스크는 실행 가능한 순서로 리스트화 할 것\n",
    "        목표: {query}\n",
    "        \"\"\"\n",
    "        prompt = ChatPromptTemplate.from_template(template)\n",
    "        return prompt\n",
    "\n",
    "    def invoke(self, query):\n",
    "        answer = self.chain.invoke({'query':query})\n",
    "        return answer.tasks\n",
    "\n",
    "    def __str__(self):\n",
    "        return f'{self.__class__.__name__}'\n",
    "\n",
    "    def __repr__(self):\n",
    "        return f'{self.__class__.__name__}'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4948114-e1a9-4c76-9d3a-3429bdf94c98",
   "metadata": {},
   "source": [
    "## ExecuteTask | report_execute_task, task_execute_task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9ae0c21-be80-49b6-a2e1-c397574d5053",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ExecuteTask(object):\n",
    "    def __init__(self, tools:list, llm=llm):\n",
    "        self.llm = llm\n",
    "        self.tools = tools\n",
    "        self.prompt = self.__create_prompt()\n",
    "        self.agent = self.__create_agent()\n",
    "\n",
    "    def __create_prompt(self):\n",
    "    \n",
    "        template = \"\"\"다음 태스크를 실행하고 상세한 답변을 제공해주세요. 당신은 다음 도구에 접근할 수 있습니다:\n",
    "    \n",
    "        {tools}\n",
    "        \n",
    "        다음 형식을 사용하세요:\n",
    "        \n",
    "        Question: 답변해야 하는 입력 질문\n",
    "        Thought: 무엇을 할지 항상 생각하세요.\n",
    "        Action: 취해야 할 행동, [{tool_names}] 중 하나여야 합니다.\n",
    "        Action Input: 행동에 대한 입력값\n",
    "        Observation: 행동의 결과\n",
    "        ... (이 Thought/Action/Action Input/Observation의 과정이 N번 반복될 수 있습니다.)\n",
    "        Thought: 이제 최종 답변을 알겠습니다.\n",
    "        Final Answer: 원래 입력된 질문에 대한 최종 답변\n",
    "        \n",
    "        ## 추가적인 주의사항\n",
    "        - 반드시 [Thought/Action/Action Input format] 이 사이클의 순서를 준수하십시오. 항상 Action 전에는 Thought가 먼저 나와야 합니다.\n",
    "        - 한 번의 검색으로 해결되지 않을 것 같다면 문제를 분할하여 푸는 것이 중요합니다.\n",
    "        - 정보가 취합되었다면 불필요하게 사이클을 반복하지 마십시오.\n",
    "        - 묻지 않은 정보를 찾으려고 도구를 사용하지 마십시오.\n",
    "        - 실행은 철저하고 포괄적으로 수행하세요.\n",
    "        - 가능한 구체적인 사실이나 데이터를 제공하세요.\n",
    "        - 차트를 생성하는 코드를 작성하는 요청이 들어오면, 차트를 생성하는 순수한 파이썬 코드만 답변하세요. \n",
    "        - 데이터프레임을 반환하는 경우는 마크다운 형식말고 순수한 dictionary 형태로 작성하고, 차트는 파이썬 코드는 마크다운 형식 말고 순수한 파이썬 코드만 생성\n",
    "        \n",
    "        시작하세요!\n",
    "        \n",
    "        Question: {task}\n",
    "        Thought: {agent_scratchpad}\n",
    "        \"\"\"\n",
    "        prompt = ChatPromptTemplate.from_template(template)\n",
    "        return prompt\n",
    "\n",
    "    def __create_agent(self):\n",
    "        agent = create_react_agent(llm=self.llm, tools=self.tools, prompt=self.prompt)\n",
    "        executor = AgentExecutor(agent=agent, tools=self.tools, verbose=True, handle_parsing_errors=True)\n",
    "        return executor\n",
    "        \n",
    "    def invoke(self, task):\n",
    "        answer = self.agent.invoke({'task':task})\n",
    "        return answer['output']\n",
    "\n",
    "    def ainvoke(self, task):\n",
    "        answer = self.agent.ainvoke({'task':task})\n",
    "        return answer['output']\n",
    "\n",
    "    def __str__(self):\n",
    "        return f'{self.__class__.__name__}'\n",
    "\n",
    "    def __repr__(self):\n",
    "        return f'{self.__class__.__name__}'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac040628-4169-470e-a948-ce1f9dff2cea",
   "metadata": {},
   "source": [
    "## ResultAggregator | aggregate_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4ca6add-6a61-4f4f-8fed-78e1fed31c2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResultAggregator(object):\n",
    "    def __init__(self, llm=llm):\n",
    "        self.llm = llm\n",
    "        self.prompt = self.__create_prompt()\n",
    "        self.chain = self.prompt | self.llm | StrOutputParser()\n",
    "\n",
    "    def __create_prompt(self):\n",
    "        template = \"\"\"주어진 목표:\n",
    "        {optimized_goal}\n",
    "        \n",
    "        조사결과:\n",
    "        {results}\n",
    "        \n",
    "        너는 조사결과와 주어진 목표를 바탕으로 보고서 결론을 작성하는 야구 전문가야. 다음과 같은 지시 사항을 준수하여 응답을 생성해줘\n",
    "        [지시사항]\n",
    "        - 조사결과를 활용하여 주어진 목표를 달성할 수 있는 글을 700자 내외로 작성해주십시오.\n",
    "        - 타이틀과 같은 마크다운요소를 제외하고 오직 줄글로 작성하여 해당 보고서의 결론을 생성해주십시오.\n",
    "        \"\"\"\n",
    "        prompt = ChatPromptTemplate.from_template(template)\n",
    "        return prompt\n",
    "        \n",
    "    def invoke(self, optimized_goal:str, results:str):\n",
    "        answer = self.chain.invoke({'optimized_goal':optimized_goal, 'results':results})\n",
    "        return answer\n",
    "\n",
    "    def __str__(self):\n",
    "        return f'{self.__class__.__name__}'\n",
    "\n",
    "    def __repr__(self):\n",
    "        return f'{self.__class__.__name__}'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f65aaa8",
   "metadata": {},
   "source": [
    "## SingleResultInspect | single_inspect_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "568978a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SingleResultInspect(object):\n",
    "    def __init__(self, llm=llm):\n",
    "        self.llm = llm\n",
    "        self.prompt = self.__create_prompt()\n",
    "        self.chain = self.prompt | self.llm | StrOutputParser() | RunnableLambda(self.__clean_answer)\n",
    "\n",
    "    def __create_prompt(self):\n",
    "        template = \"\"\"\n",
    "        주어진 목표:\n",
    "        {goal}\n",
    "        \n",
    "        조사결과:\n",
    "        {results}\n",
    "        \n",
    "        주어진 목표에 대해서 리스트안의 조사 결과를 활용하여 다음 지시에 기반한 응답을 무조건 하나만 생성해 주세요.\n",
    "        - 리스트 안의 조사결과가 하나일 경우 리스트가 아닌 text형식으로 조사결과를 ouput으로 지정한다. (수행 과정, 로그, 코멘트 등 작성 금지)\n",
    "        \"\"\"\n",
    "        prompt = ChatPromptTemplate.from_template(template)\n",
    "        return prompt\n",
    "\n",
    "    def __clean_answer(self, answer:str):\n",
    "        answer = answer.replace('```', '')\n",
    "        answer = answer.replace('python', '')\n",
    "        answer = answer.replace('plt.show()', '')\n",
    "        return answer\n",
    "    \n",
    "    def invoke(self, goal:str, results:str):\n",
    "        answer = self.chain.invoke({'goal':goal, 'results':results})\n",
    "        return answer\n",
    "\n",
    "    def __str__(self):\n",
    "        return f'{self.__class__.__name__}'\n",
    "\n",
    "    def __repr__(self):\n",
    "        return f'{self.__class__.__name__}'\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48276b65-e235-4487-9fdf-a430e5b6821f",
   "metadata": {},
   "source": [
    "## ResponseCustomer | response_customer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48b16a85-f722-40f2-a16c-3c37b448219b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResponseCustomer(object):\n",
    "    def __init__(self, llm= llm_chat):\n",
    "        self.llm = llm\n",
    "        self.prompt = self.__create_prompt()\n",
    "        \n",
    "        self.chain = self.prompt | self.llm | StrOutputParser()\n",
    "        \n",
    "    def __create_prompt(self):\n",
    "        template = \"\"\"\n",
    "                당신은 챗봇입니다.\n",
    "                아래 '결정 사유'를 참고해, 사용자가 무엇을 원했는지 확인하고 아래의 조건을 선택해서 답변을 생성하십시오.\n",
    "                이전 질문이 있다면 이것도 기억하고 답변을 생성하십시오.\n",
    "                \n",
    "                조건 1: 결정 사유가 라우팅 실패에 관련된 내용일 경우\n",
    "                - 형식 가이드(3~5문장, 한국어, 공손하지만 간결하게):\n",
    "                1) 확인: 사용자의 의도를 한 문장으로 재진술 (예: \"~정보를 요청하셨군요.\")\n",
    "                2) 한계: 현재 참조 가능한 자료에 무엇이 없는지 명확히 (예: \"현재 제가 참고할 수 있는 정보에는 ~가 포함되어 있지 않습니다.\")\n",
    "                3) 대안: a) 가능한 주제로 이어가기\n",
    "\n",
    "                조건 2: 결정 사유가 모드에 대한 선택에 대한 이유일 경우\n",
    "                - 형식 가이드(3~5문장, 한국어, 공손하게 간결하게):\n",
    "                1) 확인: 사용자의 의도를 한 문장으로 재진술 (예: \"~정보를 요청하셨군요.\")\n",
    "                2) 답변: 사용자의 의도에 대해서 답변을 한다.\n",
    "                3) 한계: 최대한 꾸며내거나 부풀리지 않고 정확하게 답변하려고 노력하여야한다. 그리고 답변이 정확하지 않을 수 있다는 사실을 분명히 한다.\n",
    "\n",
    "                [사용자 질문]\n",
    "                {question}\n",
    "\n",
    "                [결정 사유]\n",
    "                {doc_val_reason}\n",
    "                \n",
    "                [이전 질문]\n",
    "                {prev_user_question}\n",
    "                \"\"\" \n",
    "        prompt = ChatPromptTemplate.from_template(template)\n",
    "        return prompt\n",
    "    \n",
    "    def invoke(self, query:dict, doc_val_reason:str, prev_user_query:str):\n",
    "        return self.chain.invoke({'question':query,\n",
    "                                  'doc_val_reason': doc_val_reason,\n",
    "                                  'prev_user_question': prev_user_query})\n",
    "\n",
    "    def ainoke(self, query:dict, doc_val_reason:str, prev_user_query:str):\n",
    "        return self.chain.ainvoke({'question':query,\n",
    "                                  'doc_val_reason': doc_val_reason,\n",
    "                                  'prev_user_question': prev_user_query})\n",
    "        \n",
    "\n",
    "    \n",
    "    def __str__(self):\n",
    "        return f'{self.__class__.__name__}'\n",
    "\n",
    "    def __repr__(self):\n",
    "        return f'{self.__class__.__name__}'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc56c25d",
   "metadata": {},
   "source": [
    "## GetReportInfo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "770af44e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GetReportInfo(object):\n",
    "    def __init__(self, vectorstore: Chroma, llm=llm):\n",
    "        self.llm = llm\n",
    "        self.prompt = self.__create_prompt()\n",
    "        self.retriever = vectorstore.as_retriever(search_kwargs={\"k\": 1})\n",
    "        \n",
    "        def format_docs(docs: List[Document]) -> str:\n",
    "            return \"\\n\\n\".join(d.page_content for d in docs) if docs else \"(no context)\"\n",
    "        \n",
    "        self.chain = (\n",
    "        RunnablePassthrough.assign(\n",
    "            # 입력 dict -> \"query\"만 뽑아 retriever에 넣고 -> 문자열로 포맷\n",
    "            context = RunnableLambda(itemgetter(\"query\")) | self.retriever | RunnableLambda(format_docs)\n",
    "        )\n",
    "        | self.prompt\n",
    "        | self.llm.with_structured_output(Output.GetReportInfo)\n",
    "        )\n",
    "    def __create_prompt(self):\n",
    "        template = \"\"\"\n",
    "                너는 \"요구사항-계획서 정합성(Alignment) 심사관\"이다.\n",
    "                입력으로 사용자 질문과 벡터DB에서 가져온 계획서 요약/본문이 주어진다.\n",
    "                너의 임무는: \n",
    "                (a) 질문의 구체적 목표(의도/스펙)를 추출하고,\n",
    "                (b) 들고온 계획서가 그 목표를 충족하는지 평가하고, 데이터의 수집 방법론에 대해서는 평가하지않는다.\n",
    "                (c) 사용자의 목표에 구체적인 보고서 작성 대상이 있는지 판단한다.\n",
    "                (d) 최종 라우팅 결정을 JSON으로 반환하는 것이다.\n",
    "                 - JSON형태 : \"doc_val_response\":\"YES|NO\",\"doc_val_reason\":\"한 줄 요약\",\"documents\":\"들고온 문서(그대로)\"\n",
    "                 \n",
    "                사용자 요구사항:\n",
    "                {query}\n",
    "                \n",
    "                들고온 문서:\n",
    "                {context} \n",
    "                \"\"\" \n",
    "                \n",
    "        prompt = ChatPromptTemplate.from_template(template)\n",
    "        return prompt\n",
    "\n",
    "    def invoke(self, query:dict):\n",
    "        answer = self.chain.invoke({'query':query})\n",
    "        return {\n",
    "            \"doc_val_response\": answer.doc_val_response,\n",
    "            \"doc_val_reason\": answer.doc_val_reason,\n",
    "            \"documents\": answer.documents\n",
    "            }\n",
    "        \n",
    "    def ainvoke(self, query:dict):\n",
    "        answer = self.chain.ainvoke({'query':query})\n",
    "        return {\n",
    "            \"doc_val_response\": answer.doc_val_response,\n",
    "            \"doc_val_reason\": answer.doc_val_reason,\n",
    "            \"documents\": answer.documents\n",
    "            }\n",
    "    \n",
    "   \n",
    "    \n",
    "    def __str__(self):\n",
    "        return f'{self.__class__.__name__}'\n",
    "\n",
    "    def __repr__(self):\n",
    "        return f'{self.__class__.__name__}'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b935ce29-09d3-4e98-aa33-e17ec7a5b7e1",
   "metadata": {},
   "source": [
    "# LangGraph"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19586083",
   "metadata": {},
   "source": [
    "## State"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24b9bbb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Turn(BaseModel):\n",
    "    user_query: str=Field(default_factory=list, description='유저 쿼리')      \n",
    "    mode: Literal['task', 'report', 'ect'] = Field(default='', description=\"모드\")\n",
    "    ai_answer: str=Field(default_factory=list, description='답변')                           \n",
    "    ts: datetime=Field(default_factory=datetime.now())\n",
    "\n",
    "class State(BaseModel):\n",
    "    query: str = Field(..., description='사용자가 입력한 쿼리')\n",
    "    query_id: str = Field(default='', description='사용자가 입력한 쿼리 고유 ID')\n",
    "    history: Annotated[list[Turn], add] = Field(default_factory= list, description=' 이전 기록')\n",
    "    goal: str = Field(default='', description='사용자가 입력한 쿼리에서 목표 추출')\n",
    "    report_title: str = Field(default='', description='사용자요청을 기반으로 생성된 보고서 제목')\n",
    "    mode: Literal['task', 'report', 'ect'] = Field(default='', description='사용자 요청 유형')\n",
    "    doc_val_response: Literal[\"YES\",\"NO\"] = Field(default='YES', description='문서 검증 결과')\n",
    "    doc_val_reason:str= Field(default='', description='문서 검증 증거')\n",
    "    documents:str = Field(default='', description='검증에 참조한 문서')\n",
    "    optimized_goal: str = Field(default='', description='최적화된 목표') \n",
    "    #optimized_response: str = Field(default='', description='최적화된 응답 정의')\n",
    "    tasks: list = Field(default_factory=list, description='실행할 테스크 리스트')\n",
    "    current_task_index: int = Field(default=0, description='현재 실행 중인 테스크 변호')\n",
    "    results: list = Field(default_factory=list, description='실행 완료된 테스크 결과 리스트')\n",
    "    final_output: str = Field(default='', description='최종 출력 결과')\n",
    "    save_dir: str = Field(default='', description='프롬프트id별 저장 경로')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27a05e07",
   "metadata": {},
   "source": [
    "## Node"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37645542-2ec4-45c0-b421-2b6ff3581d1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.graph import START, END, StateGraph\n",
    "from functools import wraps\n",
    "\n",
    "def node_logging(func):\n",
    "    @wraps(func)\n",
    "    def wrapper(*args, **kwargs):\n",
    "        print(f\"{func.__name__} 시작\")\n",
    "        result = func(*args, **kwargs)\n",
    "        print(f\"{func.__name__} 완료\")\n",
    "        return result\n",
    "    return wrapper"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81a22618-2024-4401-87c6-81911bc83def",
   "metadata": {},
   "source": [
    "### Node 정의"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "724f7360",
   "metadata": {},
   "outputs": [],
   "source": [
    "@node_logging\n",
    "def get_mode(state:State):\n",
    "    state = state.dict()\n",
    "    query = state['query']\n",
    "    answer = GetMode().invoke(query)\n",
    "    answer.query_id = uuid.uuid1().hex\n",
    "    return {\n",
    "            'mode':answer.mode,\n",
    "            'doc_val_reason':answer.reason,\n",
    "            'query_id': answer.query_id,\n",
    "            'tasks': [],\n",
    "            'results': [],\n",
    "            'current_task_index': 0\n",
    "            }\n",
    "\n",
    "# 리포트\n",
    "@node_logging\n",
    "def get_goal(state:State):\n",
    "    state = state.dict()\n",
    "    query = state['query']\n",
    "    mode = state['mode']\n",
    "    query_id = state['query_id']\n",
    "    answer = PassiveGoalCreator().invoke(query)\n",
    "    return {'goal':answer['goal'],\n",
    "            'report_title': answer['report_title'],\n",
    "            'save_dir': f'./reports/{mode}/{query_id}.docs'\n",
    "            }\n",
    "\n",
    "@node_logging\n",
    "def get_report_info(state:State):\n",
    "    state = state.dict()\n",
    "    query = state['goal']\n",
    "    answer = GetReportInfo(vectorstore=vectorstore).invoke(query)\n",
    "    return {'doc_val_response': answer['doc_val_response'],\n",
    "            \"doc_val_reason\": answer['doc_val_reason'],\n",
    "            \"documents\": answer['documents']}\n",
    "\n",
    "@node_logging\n",
    "def optimize_goal(state:State):\n",
    "    state = state.dict()\n",
    "    query = state['goal']\n",
    "    docs = state['documents']\n",
    "    answer = GoalOptimizer().invoke(query, docs)\n",
    "    \n",
    "    # results, tasks, index 초기화\n",
    "\n",
    "    return {\n",
    "            'optimized_goal':answer\n",
    "            }\n",
    " \n",
    "@node_logging\n",
    "def decompose_tasks(state:State):\n",
    "    state = state.dict()\n",
    "    query = state['optimized_goal']\n",
    "    answer = TaskDecomposer().invoke(query)\n",
    "    return {'tasks': answer}\n",
    "\n",
    "@node_logging\n",
    "def execute_task(state:State):\n",
    "    state = state.dict()\n",
    "    complete_tasks = state['results']\n",
    "    current_task_index = state['current_task_index']\n",
    "    task = state['tasks'][current_task_index]\n",
    "    answer = ExecuteTask(tools=report_tools).invoke(task['contents'])\n",
    "    task['results'] = answer\n",
    "    current_task_index += 1\n",
    "    return {'results': complete_tasks + [task], 'current_task_index':current_task_index}\n",
    "\n",
    "@node_logging\n",
    "def aggregate_result(state:State):\n",
    "    state = state.dict()\n",
    "    results = state['results']\n",
    "    optimized_goal = state['optimized_goal']\n",
    "    #optimized_response = state['optimized_response']\n",
    "    answer = ResultAggregator().invoke(optimized_goal, results)\n",
    "    \n",
    "    history = {\n",
    "        \"user_query\": state['query'],\n",
    "        \"ai_answer\": answer,\n",
    "        \"ts\" : datetime.now()\n",
    "    }\n",
    "    \n",
    "    return {'final_output': answer, \"history\" : [history]}\n",
    "\n",
    "\n",
    "\n",
    "# 단일 태스크\n",
    "\n",
    "\n",
    "@node_logging\n",
    "def single_get_info(state:State):\n",
    "    state = state.dict()\n",
    "    goal = state['goal']\n",
    "    mode = state['mode']\n",
    "    query_id = state['query_id']\n",
    "    answer = SingleGettInfo().invoke(goal)\n",
    "    return {'doc_val_response': answer['doc_val_response'],\n",
    "            'doc_val_reason': answer['doc_val_reason'],\n",
    "            'save_dir': f'./images/{mode}/{query_id}.png'}\n",
    "\n",
    "\n",
    "@node_logging\n",
    "def single_execute_task(state:State):\n",
    "    state = state.dict()\n",
    "    goal = state['goal']\n",
    "    answer = ExecuteTask(tools= task_tools).invoke(goal)\n",
    "    return {'results': [answer]}\n",
    "\n",
    "\n",
    "\n",
    "@node_logging\n",
    "def single_inspect_result(state:State):\n",
    "    state = state.dict()\n",
    "    results = state['results']\n",
    "    goal = state['goal']\n",
    "    answer = SingleResultInspect().invoke(goal, results)\n",
    "    \n",
    "    history = {\n",
    "        \"user_query\": state['query'],\n",
    "        \"ai_answer\": answer,\n",
    "        \"ts\" : datetime.now()\n",
    "    }\n",
    "    \n",
    "    return {'final_output': answer, 'history': [history]}\n",
    "\n",
    "\n",
    "\n",
    "# 챗봇\n",
    "@node_logging\n",
    "def response_customer(state:State):\n",
    "    state = state.dict()\n",
    "    query = state['query']\n",
    "    doc_val_reason = state['doc_val_reason']\n",
    "    \n",
    "    history = state.get('history', [])\n",
    "    if history:\n",
    "        prev_user_query = history[-1]['user_query']\n",
    "    else: \n",
    "        prev_user_query=\"이전 질문 없음\"\n",
    "        \n",
    "    answer = ResponseCustomer().invoke(query = query, doc_val_reason = doc_val_reason, prev_user_query=prev_user_query)\n",
    "    \n",
    "    history = {\n",
    "        \"user_query\": state['query'],\n",
    "        \"ai_answer\": answer,\n",
    "        \"ts\" : datetime.now()\n",
    "    }\n",
    "    \n",
    "    return {'final_output': answer, \"history\" : [history]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17a3a8c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "workflow = StateGraph(State)\n",
    "\n",
    "workflow.add_node('get_mode', get_mode)\n",
    "\n",
    "# 리포트\n",
    "workflow.add_node('get_goal', get_goal)\n",
    "workflow.add_node('get_report_info', get_report_info)\n",
    "workflow.add_node('optimize_goal', optimize_goal)\n",
    "workflow.add_node('decompose_tasks', decompose_tasks)\n",
    "workflow.add_node('report_execute_task', execute_task)\n",
    "workflow.add_node('aggregate_result', aggregate_result)\n",
    "\n",
    "# 단일 태스크\n",
    "workflow.add_node('single_get_goal', get_goal)\n",
    "workflow.add_node('single_get_info', single_get_info)\n",
    "workflow.add_node('single_execute_task', single_execute_task)\n",
    "workflow.add_node('single_inspect_result', single_inspect_result)\n",
    "\n",
    "# 챗봇\n",
    "workflow.add_node('response_customer', response_customer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b588d17c",
   "metadata": {},
   "source": [
    "## Edge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "042102c4-25f4-4374-b1b9-ace60988cd8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "workflow.add_edge(START, 'get_mode')\n",
    "workflow.add_conditional_edges('get_mode', lambda state: state.dict()['mode'], {'task':'single_get_goal', 'report':'get_goal', 'ect':'response_customer'})\n",
    "workflow.add_edge('single_get_goal', 'single_get_info')\n",
    "workflow.add_conditional_edges('single_get_info', lambda state: state.dict()['doc_val_response'], {'YES':'single_execute_task', 'NO': 'response_customer'})\n",
    "workflow.add_edge('single_execute_task', 'single_inspect_result')\n",
    "\n",
    "workflow.add_edge('response_customer', END)\n",
    "\n",
    "workflow.add_edge('get_goal', 'get_report_info')\n",
    "workflow.add_conditional_edges('get_report_info', lambda state: state.dict()['doc_val_response'], {'YES':'optimize_goal', 'NO':'response_customer'})\n",
    "workflow.add_edge('optimize_goal', 'decompose_tasks')\n",
    "workflow.add_edge('decompose_tasks', 'report_execute_task')\n",
    "workflow.add_conditional_edges('report_execute_task', lambda state: state.dict()['current_task_index'] < len(state.dict()['tasks']), {True:'report_execute_task', False:'aggregate_result'})\n",
    "workflow.add_edge('aggregate_result', END)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebf8608e-b652-4f20-86db-7b194ddfe531",
   "metadata": {},
   "source": [
    "## Graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "554e5daf-9b64-48fa-b843-6bf28c1f2023",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.checkpoint.memory import MemorySaver\n",
    "\n",
    "memory = MemorySaver()\n",
    "graph = workflow.compile(checkpointer=memory)\n",
    "conversation_id = \"my-test-session-001\" \n",
    "config = {\"configurable\": {\"thread_id\": conversation_id}}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b7fb8f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "graph"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48453d9f",
   "metadata": {},
   "source": [
    "# 테스트"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1315b827",
   "metadata": {},
   "source": [
    "## 리포트"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d1ff18c",
   "metadata": {},
   "outputs": [],
   "source": [
    "result_ect = graph.invoke({'query':'2024년 ARI팀의 전력분석보고서 작성해줘.'}, config)\n",
    "result_ect['results']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d97f35c",
   "metadata": {},
   "outputs": [],
   "source": [
    "result_ect"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b921775e",
   "metadata": {},
   "source": [
    "## Task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "106ecade",
   "metadata": {},
   "outputs": [],
   "source": [
    "result_task3 = graph.invoke({'query':'2024년 시즌 승률을 빅넘버 차트로 그려줘'}, config)\n",
    "result_task3['final_output']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c401ff1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "result_task3 = graph.invoke({'query':'2024년 시즌 승률을 막대 차트로 그려줘'}, config)\n",
    "result_task3['final_output']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eec254c1",
   "metadata": {},
   "source": [
    "## Chat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb8b8f8a-5762-4761-881a-c826941837d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "result_chat = graph.invoke({'query':'야구에서 WHIP이라는 지표에 대해서 알려줘'}, config)\n",
    "result_chat['final_output']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c1cd3d2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
